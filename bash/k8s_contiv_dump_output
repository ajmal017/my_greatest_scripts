Client Version: version.Info{Major:"1", Minor:"9", GitVersion:"v1.9.2", GitCommit:"5fa2db2bd46ac79e5e00a4e6ed24191080aa463b", GitTreeState:"clean", BuildDate:"2018-01-18T10:09:24Z", GoVersion:"go1.9.2", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"9", GitVersion:"v1.9.2", GitCommit:"5fa2db2bd46ac79e5e00a4e6ed24191080aa463b", GitTreeState:"clean", BuildDate:"2018-01-18T09:42:01Z", GoVersion:"go1.9.2", Compiler:"gc", Platform:"linux/amd64"}
[0;32mKubernetes master[0m is running at [0;33mhttps://192.168.2.10:6443[0m

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
\n================
kubectl get all --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME                  DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR                     AGE       CONTAINERS                                IMAGES                                             SELECTOR                   LABELS
kube-system   ds/contiv-etcd        1         1         1         1            1           node-role.kubernetes.io/master=   16d       contiv-etcd                               quay.io/coreos/etcd:v3.2.4                         k8s-app=contiv-etcd        k8s-app=contiv-etcd
kube-system   ds/contiv-netplugin   4         4         4         4            4           <none>                            16d       contiv-netplugin                          contiv/netplugin:latest                            k8s-app=contiv-netplugin   k8s-app=contiv-netplugin
kube-system   ds/contiv-ovs         4         4         4         4            4           <none>                            16d       contiv-ovsdb-server,contiv-ovs-vswitchd   contiv/ovs:latest,contiv/ovs:latest                k8s-app=contiv-ovs         k8s-app=contiv-ovs
kube-system   ds/kube-proxy         4         4         4         4            4           <none>                            16d       kube-proxy                                gcr.io/google_containers/kube-proxy-amd64:v1.9.2   k8s-app=kube-proxy         k8s-app=kube-proxy

NAMESPACE     NAME                  DESIRED   CURRENT   READY     AGE       CONTAINERS         IMAGES                    SELECTOR                   LABELS
kube-system   rs/contiv-netmaster   1         1         1         16d       contiv-netmaster   contiv/netplugin:latest   k8s-app=contiv-netmaster   k8s-app=contiv-netmaster

NAMESPACE     NAME                  DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR                     AGE       CONTAINERS                                IMAGES                                             SELECTOR                   LABELS
kube-system   ds/contiv-etcd        1         1         1         1            1           node-role.kubernetes.io/master=   16d       contiv-etcd                               quay.io/coreos/etcd:v3.2.4                         k8s-app=contiv-etcd        k8s-app=contiv-etcd
kube-system   ds/contiv-netplugin   4         4         4         4            4           <none>                            16d       contiv-netplugin                          contiv/netplugin:latest                            k8s-app=contiv-netplugin   k8s-app=contiv-netplugin
kube-system   ds/contiv-ovs         4         4         4         4            4           <none>                            16d       contiv-ovsdb-server,contiv-ovs-vswitchd   contiv/ovs:latest,contiv/ovs:latest                k8s-app=contiv-ovs         k8s-app=contiv-ovs
kube-system   ds/kube-proxy         4         4         4         4            4           <none>                            16d       kube-proxy                                gcr.io/google_containers/kube-proxy-amd64:v1.9.2   k8s-app=kube-proxy         k8s-app=kube-proxy

NAMESPACE     NAME                  DESIRED   CURRENT   READY     AGE       CONTAINERS         IMAGES                    SELECTOR                   LABELS
kube-system   rs/contiv-netmaster   1         1         1         16d       contiv-netmaster   contiv/netplugin:latest   k8s-app=contiv-netmaster   k8s-app=contiv-netmaster

NAMESPACE     NAME                                  READY     STATUS    RESTARTS   AGE       IP             NODE        LABELS
kube-system   po/contiv-etcd-6mcxz                  1/1       Running   0          16d       192.168.2.10   k8master    controller-revision-hash=3440706255,k8s-app=contiv-etcd,pod-template-generation=1
kube-system   po/contiv-netmaster-vkc6s             1/1       Running   0          16d       192.168.2.10   k8master    k8s-app=contiv-netmaster
kube-system   po/contiv-netplugin-2d7rp             1/1       Running   0          16d       192.168.2.12   k8node-02   controller-revision-hash=4029632485,k8s-app=contiv-netplugin,pod-template-generation=1
kube-system   po/contiv-netplugin-5pqjs             1/1       Running   0          16d       192.168.2.13   k8node-03   controller-revision-hash=4029632485,k8s-app=contiv-netplugin,pod-template-generation=1
kube-system   po/contiv-netplugin-qwgd5             1/1       Running   0          16d       192.168.2.10   k8master    controller-revision-hash=4029632485,k8s-app=contiv-netplugin,pod-template-generation=1
kube-system   po/contiv-netplugin-xwxkn             1/1       Running   0          16d       192.168.2.11   k8node-01   controller-revision-hash=4029632485,k8s-app=contiv-netplugin,pod-template-generation=1
kube-system   po/contiv-ovs-8mfdn                   2/2       Running   0          16d       192.168.2.12   k8node-02   controller-revision-hash=1824568849,k8s-app=contiv-ovs,pod-template-generation=1
kube-system   po/contiv-ovs-mwfjk                   2/2       Running   0          16d       192.168.2.10   k8master    controller-revision-hash=1824568849,k8s-app=contiv-ovs,pod-template-generation=1
kube-system   po/contiv-ovs-zmk5s                   2/2       Running   0          16d       192.168.2.13   k8node-03   controller-revision-hash=1824568849,k8s-app=contiv-ovs,pod-template-generation=1
kube-system   po/contiv-ovs-zwb9t                   2/2       Running   0          16d       192.168.2.11   k8node-01   controller-revision-hash=1824568849,k8s-app=contiv-ovs,pod-template-generation=1
kube-system   po/etcd-k8master                      1/1       Running   0          16d       192.168.2.10   k8master    component=etcd,tier=control-plane
kube-system   po/kube-apiserver-k8master            1/1       Running   0          16d       192.168.2.10   k8master    component=kube-apiserver,tier=control-plane
kube-system   po/kube-controller-manager-k8master   1/1       Running   0          16d       192.168.2.10   k8master    component=kube-controller-manager,tier=control-plane
kube-system   po/kube-proxy-6j2b4                   1/1       Running   0          16d       192.168.2.13   k8node-03   controller-revision-hash=588621068,k8s-app=kube-proxy,pod-template-generation=1
kube-system   po/kube-proxy-8wx7q                   1/1       Running   0          16d       192.168.2.10   k8master    controller-revision-hash=588621068,k8s-app=kube-proxy,pod-template-generation=1
kube-system   po/kube-proxy-l9msk                   1/1       Running   0          16d       192.168.2.12   k8node-02   controller-revision-hash=588621068,k8s-app=kube-proxy,pod-template-generation=1
kube-system   po/kube-proxy-zg92c                   1/1       Running   0          16d       192.168.2.11   k8node-01   controller-revision-hash=588621068,k8s-app=kube-proxy,pod-template-generation=1
kube-system   po/kube-scheduler-k8master            1/1       Running   0          16d       192.168.2.10   k8master    component=kube-scheduler,tier=control-plane

NAMESPACE     NAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE       SELECTOR              LABELS
default       svc/kubernetes    ClusterIP   10.96.0.1       <none>        443/TCP    16d       <none>                component=apiserver,provider=kubernetes
kube-system   svc/contiv-etcd   ClusterIP   10.96.232.136   <none>        6666/TCP   16d       k8s-app=contiv-etcd   k8s-app=contiv-etcd
\n================
kubectl get certificatesigningrequests --all-namespaces --show-labels -o wide
================\n
NAME                                                   AGE       REQUESTOR                 CONDITION         LABELS
node-csr-NQ3d6g41WV1WWJisOnSa9fS7yJOwNd_lR1Aic4EnvQA   16d       system:bootstrap:d0d1be   Approved,Issued   <none>
node-csr-WebmZ45AIlmmXlhpUOInVWUntDe1z8m2eTN8YwFCm2s   16d       system:bootstrap:d0d1be   Approved,Issued   <none>
node-csr-jtPWYkKUWhh1-OuAIo7wM7YG-RRp3viT2EfJy33wHjI   16d       system:bootstrap:d0d1be   Approved,Issued   <none>
\n================
kubectl get clusterrolebindings --all-namespaces --show-labels -o wide
================\n
NAME                                                   AGE       ROLE                                                                               USERS                            GROUPS                                            SERVICEACCOUNTS                                  LABELS
cluster-admin                                          16d       ClusterRole/cluster-admin                                                                                           system:masters                                                                                     kubernetes.io/bootstrapping=rbac-defaults
contiv-netmaster                                       16d       ClusterRole/contiv-netmaster                                                                                                                                          kube-system/contiv-netmaster                     <none>
contiv-netplugin                                       16d       ClusterRole/contiv-netplugin                                                                                                                                          kube-system/contiv-netplugin                     <none>
kubeadm:kubelet-bootstrap                              16d       ClusterRole/system:node-bootstrapper                                                                                system:bootstrappers:kubeadm:default-node-token                                                    <none>
kubeadm:node-autoapprove-bootstrap                     16d       ClusterRole/system:certificates.k8s.io:certificatesigningrequests:nodeclient                                        system:bootstrappers:kubeadm:default-node-token                                                    <none>
kubeadm:node-autoapprove-certificate-rotation          16d       ClusterRole/system:certificates.k8s.io:certificatesigningrequests:selfnodeclient                                    system:nodes                                                                                       <none>
kubeadm:node-proxier                                   16d       ClusterRole/system:node-proxier                                                                                                                                       kube-system/kube-proxy                           <none>
system:aws-cloud-provider                              16d       ClusterRole/system:aws-cloud-provider                                                                                                                                 kube-system/aws-cloud-provider                   kubernetes.io/bootstrapping=rbac-defaults
system:basic-user                                      16d       ClusterRole/system:basic-user                                                                                       system:authenticated, system:unauthenticated                                                       kubernetes.io/bootstrapping=rbac-defaults
system:controller:attachdetach-controller              16d       ClusterRole/system:controller:attachdetach-controller                                                                                                                 kube-system/attachdetach-controller              kubernetes.io/bootstrapping=rbac-defaults
system:controller:certificate-controller               16d       ClusterRole/system:controller:certificate-controller                                                                                                                  kube-system/certificate-controller               kubernetes.io/bootstrapping=rbac-defaults
system:controller:clusterrole-aggregation-controller   16d       ClusterRole/system:controller:clusterrole-aggregation-controller                                                                                                      kube-system/clusterrole-aggregation-controller   kubernetes.io/bootstrapping=rbac-defaults
system:controller:cronjob-controller                   16d       ClusterRole/system:controller:cronjob-controller                                                                                                                      kube-system/cronjob-controller                   kubernetes.io/bootstrapping=rbac-defaults
system:controller:daemon-set-controller                16d       ClusterRole/system:controller:daemon-set-controller                                                                                                                   kube-system/daemon-set-controller                kubernetes.io/bootstrapping=rbac-defaults
system:controller:deployment-controller                16d       ClusterRole/system:controller:deployment-controller                                                                                                                   kube-system/deployment-controller                kubernetes.io/bootstrapping=rbac-defaults
system:controller:disruption-controller                16d       ClusterRole/system:controller:disruption-controller                                                                                                                   kube-system/disruption-controller                kubernetes.io/bootstrapping=rbac-defaults
system:controller:endpoint-controller                  16d       ClusterRole/system:controller:endpoint-controller                                                                                                                     kube-system/endpoint-controller                  kubernetes.io/bootstrapping=rbac-defaults
system:controller:generic-garbage-collector            16d       ClusterRole/system:controller:generic-garbage-collector                                                                                                               kube-system/generic-garbage-collector            kubernetes.io/bootstrapping=rbac-defaults
system:controller:horizontal-pod-autoscaler            16d       ClusterRole/system:controller:horizontal-pod-autoscaler                                                                                                               kube-system/horizontal-pod-autoscaler            kubernetes.io/bootstrapping=rbac-defaults
system:controller:job-controller                       16d       ClusterRole/system:controller:job-controller                                                                                                                          kube-system/job-controller                       kubernetes.io/bootstrapping=rbac-defaults
system:controller:namespace-controller                 16d       ClusterRole/system:controller:namespace-controller                                                                                                                    kube-system/namespace-controller                 kubernetes.io/bootstrapping=rbac-defaults
system:controller:node-controller                      16d       ClusterRole/system:controller:node-controller                                                                                                                         kube-system/node-controller                      kubernetes.io/bootstrapping=rbac-defaults
system:controller:persistent-volume-binder             16d       ClusterRole/system:controller:persistent-volume-binder                                                                                                                kube-system/persistent-volume-binder             kubernetes.io/bootstrapping=rbac-defaults
system:controller:pod-garbage-collector                16d       ClusterRole/system:controller:pod-garbage-collector                                                                                                                   kube-system/pod-garbage-collector                kubernetes.io/bootstrapping=rbac-defaults
system:controller:replicaset-controller                16d       ClusterRole/system:controller:replicaset-controller                                                                                                                   kube-system/replicaset-controller                kubernetes.io/bootstrapping=rbac-defaults
system:controller:replication-controller               16d       ClusterRole/system:controller:replication-controller                                                                                                                  kube-system/replication-controller               kubernetes.io/bootstrapping=rbac-defaults
system:controller:resourcequota-controller             16d       ClusterRole/system:controller:resourcequota-controller                                                                                                                kube-system/resourcequota-controller             kubernetes.io/bootstrapping=rbac-defaults
system:controller:route-controller                     16d       ClusterRole/system:controller:route-controller                                                                                                                        kube-system/route-controller                     kubernetes.io/bootstrapping=rbac-defaults
system:controller:service-account-controller           16d       ClusterRole/system:controller:service-account-controller                                                                                                              kube-system/service-account-controller           kubernetes.io/bootstrapping=rbac-defaults
system:controller:service-controller                   16d       ClusterRole/system:controller:service-controller                                                                                                                      kube-system/service-controller                   kubernetes.io/bootstrapping=rbac-defaults
system:controller:statefulset-controller               16d       ClusterRole/system:controller:statefulset-controller                                                                                                                  kube-system/statefulset-controller               kubernetes.io/bootstrapping=rbac-defaults
system:controller:ttl-controller                       16d       ClusterRole/system:controller:ttl-controller                                                                                                                          kube-system/ttl-controller                       kubernetes.io/bootstrapping=rbac-defaults
system:discovery                                       16d       ClusterRole/system:discovery                                                                                        system:authenticated, system:unauthenticated                                                       kubernetes.io/bootstrapping=rbac-defaults
system:kube-controller-manager                         16d       ClusterRole/system:kube-controller-manager                                         system:kube-controller-manager                                                                                                      kubernetes.io/bootstrapping=rbac-defaults
system:kube-scheduler                                  16d       ClusterRole/system:kube-scheduler                                                  system:kube-scheduler                                                                                                               kubernetes.io/bootstrapping=rbac-defaults
system:node                                            16d       ClusterRole/system:node                                                                                                                                                                                                kubernetes.io/bootstrapping=rbac-defaults
system:node-proxier                                    16d       ClusterRole/system:node-proxier                                                    system:kube-proxy                                                                                                                   kubernetes.io/bootstrapping=rbac-defaults
\n================
kubectl get clusterroles --all-namespaces --show-labels -o wide
================\n
NAME                                                                   AGE       LABELS
admin                                                                  16d       kubernetes.io/bootstrapping=rbac-defaults
cluster-admin                                                          16d       kubernetes.io/bootstrapping=rbac-defaults
contiv-netmaster                                                       16d       <none>
contiv-netplugin                                                       16d       <none>
edit                                                                   16d       kubernetes.io/bootstrapping=rbac-defaults
system:aggregate-to-admin                                              16d       kubernetes.io/bootstrapping=rbac-defaults,rbac.authorization.k8s.io/aggregate-to-admin=true
system:aggregate-to-edit                                               16d       kubernetes.io/bootstrapping=rbac-defaults,rbac.authorization.k8s.io/aggregate-to-edit=true
system:aggregate-to-view                                               16d       kubernetes.io/bootstrapping=rbac-defaults,rbac.authorization.k8s.io/aggregate-to-view=true
system:auth-delegator                                                  16d       kubernetes.io/bootstrapping=rbac-defaults
system:aws-cloud-provider                                              16d       kubernetes.io/bootstrapping=rbac-defaults
system:basic-user                                                      16d       kubernetes.io/bootstrapping=rbac-defaults
system:certificates.k8s.io:certificatesigningrequests:nodeclient       16d       kubernetes.io/bootstrapping=rbac-defaults
system:certificates.k8s.io:certificatesigningrequests:selfnodeclient   16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:attachdetach-controller                              16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:certificate-controller                               16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:clusterrole-aggregation-controller                   16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:cronjob-controller                                   16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:daemon-set-controller                                16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:deployment-controller                                16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:disruption-controller                                16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:endpoint-controller                                  16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:generic-garbage-collector                            16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:horizontal-pod-autoscaler                            16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:job-controller                                       16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:namespace-controller                                 16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:node-controller                                      16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:persistent-volume-binder                             16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:pod-garbage-collector                                16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:replicaset-controller                                16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:replication-controller                               16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:resourcequota-controller                             16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:route-controller                                     16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:service-account-controller                           16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:service-controller                                   16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:statefulset-controller                               16d       kubernetes.io/bootstrapping=rbac-defaults
system:controller:ttl-controller                                       16d       kubernetes.io/bootstrapping=rbac-defaults
system:discovery                                                       16d       kubernetes.io/bootstrapping=rbac-defaults
system:heapster                                                        16d       kubernetes.io/bootstrapping=rbac-defaults
system:kube-aggregator                                                 16d       kubernetes.io/bootstrapping=rbac-defaults
system:kube-controller-manager                                         16d       kubernetes.io/bootstrapping=rbac-defaults
system:kube-dns                                                        16d       kubernetes.io/bootstrapping=rbac-defaults
system:kube-scheduler                                                  16d       kubernetes.io/bootstrapping=rbac-defaults
system:node                                                            16d       kubernetes.io/bootstrapping=rbac-defaults
system:node-bootstrapper                                               16d       kubernetes.io/bootstrapping=rbac-defaults
system:node-problem-detector                                           16d       kubernetes.io/bootstrapping=rbac-defaults
system:node-proxier                                                    16d       kubernetes.io/bootstrapping=rbac-defaults
system:persistent-volume-provisioner                                   16d       kubernetes.io/bootstrapping=rbac-defaults
view                                                                   16d       kubernetes.io/bootstrapping=rbac-defaults
\n================
kubectl get componentstatuses --all-namespaces --show-labels -o wide
================\n
NAME                 STATUS    MESSAGE              ERROR     LABELS
scheduler            Healthy   ok                             <none>
controller-manager   Healthy   ok                             <none>
etcd-0               Healthy   {"health": "true"}             <none>
\n================
kubectl get configmaps --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME                                 DATA      AGE       LABELS
kube-public   cluster-info                         1         16d       <none>
kube-system   contiv-config                        6         16d       <none>
kube-system   extension-apiserver-authentication   6         16d       <none>
kube-system   kube-proxy                           2         16d       app=kube-proxy
kube-system   kubeadm-config                       1         16d       <none>
\n================
kubectl get controllerrevisions --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME                          CONTROLLER                   REVISION   AGE       LABELS
kube-system   contiv-etcd-7884c4b699        DaemonSet/contiv-etcd        1          16d       controller-revision-hash=3440706255,k8s-app=contiv-etcd
kube-system   contiv-netplugin-846fb768d9   DaemonSet/contiv-netplugin   1          16d       controller-revision-hash=4029632485,k8s-app=contiv-netplugin
kube-system   contiv-ovs-5d689bdd8f         DaemonSet/contiv-ovs         1          16d       controller-revision-hash=1824568849,k8s-app=contiv-ovs
kube-system   kube-proxy-9ddb654bd          DaemonSet/kube-proxy         1          16d       controller-revision-hash=588621068,k8s-app=kube-proxy
\n================
kubectl get cronjobs --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get customresourcedefinition --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get daemonsets --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME               DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR                     AGE       CONTAINERS                                IMAGES                                             SELECTOR                   LABELS
kube-system   contiv-etcd        1         1         1         1            1           node-role.kubernetes.io/master=   16d       contiv-etcd                               quay.io/coreos/etcd:v3.2.4                         k8s-app=contiv-etcd        k8s-app=contiv-etcd
kube-system   contiv-netplugin   4         4         4         4            4           <none>                            16d       contiv-netplugin                          contiv/netplugin:latest                            k8s-app=contiv-netplugin   k8s-app=contiv-netplugin
kube-system   contiv-ovs         4         4         4         4            4           <none>                            16d       contiv-ovsdb-server,contiv-ovs-vswitchd   contiv/ovs:latest,contiv/ovs:latest                k8s-app=contiv-ovs         k8s-app=contiv-ovs
kube-system   kube-proxy         4         4         4         4            4           <none>                            16d       kube-proxy                                gcr.io/google_containers/kube-proxy-amd64:v1.9.2   k8s-app=kube-proxy         k8s-app=kube-proxy
\n================
kubectl get deployments --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get endpoints --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME                      ENDPOINTS           AGE       LABELS
default       kubernetes                192.168.2.10:6443   16d       <none>
kube-system   contiv-etcd               192.168.2.10:6666   16d       k8s-app=contiv-etcd
kube-system   kube-controller-manager   <none>              16d       <none>
kube-system   kube-scheduler            <none>              16d       <none>
\n================
kubectl get events --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get horizontalpodautoscalers --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get ingresses --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get jobs --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get limitranges --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get namespaces --all-namespaces --show-labels -o wide
================\n
NAME          STATUS    AGE       LABELS
default       Active    16d       <none>
kube-public   Active    16d       <none>
kube-system   Active    16d       <none>
\n================
kubectl get networkpolicies --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get nodes --all-namespaces --show-labels -o wide
================\n
NAME        STATUS    ROLES     AGE       VERSION   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION               CONTAINER-RUNTIME   LABELS
k8master    Ready     master    16d       v1.9.2    <none>        CentOS Linux 7 (Core)   3.10.0-514.21.1.el7.x86_64   docker://1.12.6     beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=k8master,node-role.kubernetes.io/master=
k8node-01   Ready     <none>    16d       v1.9.2    <none>        CentOS Linux 7 (Core)   3.10.0-514.21.1.el7.x86_64   docker://1.12.6     beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=k8node-01
k8node-02   Ready     <none>    16d       v1.9.2    <none>        CentOS Linux 7 (Core)   3.10.0-514.21.1.el7.x86_64   docker://1.12.6     beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=k8node-02
k8node-03   Ready     <none>    16d       v1.9.2    <none>        CentOS Linux 7 (Core)   3.10.0-514.21.1.el7.x86_64   docker://1.12.6     beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=k8node-03
\n================
kubectl get persistentvolumeclaims --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get persistentvolumes --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get poddisruptionbudgets --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get podpreset --all-namespaces --show-labels -o wide
================\n
the server doesn't have a resource type "podpreset"
\n================
kubectl get pods --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME                               READY     STATUS    RESTARTS   AGE       IP             NODE        LABELS
kube-system   contiv-etcd-6mcxz                  1/1       Running   0          16d       192.168.2.10   k8master    controller-revision-hash=3440706255,k8s-app=contiv-etcd,pod-template-generation=1
kube-system   contiv-netmaster-vkc6s             1/1       Running   0          16d       192.168.2.10   k8master    k8s-app=contiv-netmaster
kube-system   contiv-netplugin-2d7rp             1/1       Running   0          16d       192.168.2.12   k8node-02   controller-revision-hash=4029632485,k8s-app=contiv-netplugin,pod-template-generation=1
kube-system   contiv-netplugin-5pqjs             1/1       Running   0          16d       192.168.2.13   k8node-03   controller-revision-hash=4029632485,k8s-app=contiv-netplugin,pod-template-generation=1
kube-system   contiv-netplugin-qwgd5             1/1       Running   0          16d       192.168.2.10   k8master    controller-revision-hash=4029632485,k8s-app=contiv-netplugin,pod-template-generation=1
kube-system   contiv-netplugin-xwxkn             1/1       Running   0          16d       192.168.2.11   k8node-01   controller-revision-hash=4029632485,k8s-app=contiv-netplugin,pod-template-generation=1
kube-system   contiv-ovs-8mfdn                   2/2       Running   0          16d       192.168.2.12   k8node-02   controller-revision-hash=1824568849,k8s-app=contiv-ovs,pod-template-generation=1
kube-system   contiv-ovs-mwfjk                   2/2       Running   0          16d       192.168.2.10   k8master    controller-revision-hash=1824568849,k8s-app=contiv-ovs,pod-template-generation=1
kube-system   contiv-ovs-zmk5s                   2/2       Running   0          16d       192.168.2.13   k8node-03   controller-revision-hash=1824568849,k8s-app=contiv-ovs,pod-template-generation=1
kube-system   contiv-ovs-zwb9t                   2/2       Running   0          16d       192.168.2.11   k8node-01   controller-revision-hash=1824568849,k8s-app=contiv-ovs,pod-template-generation=1
kube-system   etcd-k8master                      1/1       Running   0          16d       192.168.2.10   k8master    component=etcd,tier=control-plane
kube-system   kube-apiserver-k8master            1/1       Running   0          16d       192.168.2.10   k8master    component=kube-apiserver,tier=control-plane
kube-system   kube-controller-manager-k8master   1/1       Running   0          16d       192.168.2.10   k8master    component=kube-controller-manager,tier=control-plane
kube-system   kube-proxy-6j2b4                   1/1       Running   0          16d       192.168.2.13   k8node-03   controller-revision-hash=588621068,k8s-app=kube-proxy,pod-template-generation=1
kube-system   kube-proxy-8wx7q                   1/1       Running   0          16d       192.168.2.10   k8master    controller-revision-hash=588621068,k8s-app=kube-proxy,pod-template-generation=1
kube-system   kube-proxy-l9msk                   1/1       Running   0          16d       192.168.2.12   k8node-02   controller-revision-hash=588621068,k8s-app=kube-proxy,pod-template-generation=1
kube-system   kube-proxy-zg92c                   1/1       Running   0          16d       192.168.2.11   k8node-01   controller-revision-hash=588621068,k8s-app=kube-proxy,pod-template-generation=1
kube-system   kube-scheduler-k8master            1/1       Running   0          16d       192.168.2.10   k8master    component=kube-scheduler,tier=control-plane
\n================
kubectl get podsecuritypolicies --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get podtemplates --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get replicasets --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME               DESIRED   CURRENT   READY     AGE       CONTAINERS         IMAGES                    SELECTOR                   LABELS
kube-system   contiv-netmaster   1         1         1         16d       contiv-netmaster   contiv/netplugin:latest   k8s-app=contiv-netmaster   k8s-app=contiv-netmaster
\n================
kubectl get replicationcontrollers --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get resourcequotas --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get rolebindings --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME                                             AGE       ROLE                                                  USERS              GROUPS    SERVICEACCOUNTS                       LABELS
kube-public   kubeadm:bootstrap-signer-clusterinfo             16d       Role/kubeadm:bootstrap-signer-clusterinfo             system:anonymous                                                   <none>
kube-public   system:controller:bootstrap-signer               16d       Role/system:controller:bootstrap-signer                                            kube-system/bootstrap-signer          kubernetes.io/bootstrapping=rbac-defaults
kube-system   system::leader-locking-kube-controller-manager   16d       Role/system::leader-locking-kube-controller-manager                                kube-system/kube-controller-manager   kubernetes.io/bootstrapping=rbac-defaults
kube-system   system::leader-locking-kube-scheduler            16d       Role/system::leader-locking-kube-scheduler                                         kube-system/kube-scheduler            kubernetes.io/bootstrapping=rbac-defaults
kube-system   system:controller:bootstrap-signer               16d       Role/system:controller:bootstrap-signer                                            kube-system/bootstrap-signer          kubernetes.io/bootstrapping=rbac-defaults
kube-system   system:controller:cloud-provider                 16d       Role/system:controller:cloud-provider                                              kube-system/cloud-provider            kubernetes.io/bootstrapping=rbac-defaults
kube-system   system:controller:token-cleaner                  16d       Role/system:controller:token-cleaner                                               kube-system/token-cleaner             kubernetes.io/bootstrapping=rbac-defaults
\n================
kubectl get roles --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME                                             AGE       LABELS
kube-public   kubeadm:bootstrap-signer-clusterinfo             16d       <none>
kube-public   system:controller:bootstrap-signer               16d       kubernetes.io/bootstrapping=rbac-defaults
kube-system   extension-apiserver-authentication-reader        16d       kubernetes.io/bootstrapping=rbac-defaults
kube-system   system::leader-locking-kube-controller-manager   16d       kubernetes.io/bootstrapping=rbac-defaults
kube-system   system::leader-locking-kube-scheduler            16d       kubernetes.io/bootstrapping=rbac-defaults
kube-system   system:controller:bootstrap-signer               16d       kubernetes.io/bootstrapping=rbac-defaults
kube-system   system:controller:cloud-provider                 16d       kubernetes.io/bootstrapping=rbac-defaults
kube-system   system:controller:token-cleaner                  16d       kubernetes.io/bootstrapping=rbac-defaults
\n================
kubectl get secrets --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME                                             TYPE                                  DATA      AGE       LABELS
default       default-token-d5kpb                              kubernetes.io/service-account-token   3         16d       <none>
kube-public   default-token-qhfnm                              kubernetes.io/service-account-token   3         16d       <none>
kube-system   attachdetach-controller-token-76zkt              kubernetes.io/service-account-token   3         16d       <none>
kube-system   bootstrap-signer-token-2pkhf                     kubernetes.io/service-account-token   3         16d       <none>
kube-system   certificate-controller-token-bwh4d               kubernetes.io/service-account-token   3         16d       <none>
kube-system   clusterrole-aggregation-controller-token-tbk9h   kubernetes.io/service-account-token   3         16d       <none>
kube-system   contiv-netmaster-token-47bxd                     kubernetes.io/service-account-token   3         16d       <none>
kube-system   contiv-netplugin-token-xqsb5                     kubernetes.io/service-account-token   3         16d       <none>
kube-system   cronjob-controller-token-brlcv                   kubernetes.io/service-account-token   3         16d       <none>
kube-system   daemon-set-controller-token-hzfb5                kubernetes.io/service-account-token   3         16d       <none>
kube-system   default-token-9ktff                              kubernetes.io/service-account-token   3         16d       <none>
kube-system   deployment-controller-token-fvd4k                kubernetes.io/service-account-token   3         16d       <none>
kube-system   disruption-controller-token-lkrtn                kubernetes.io/service-account-token   3         16d       <none>
kube-system   endpoint-controller-token-gsdzq                  kubernetes.io/service-account-token   3         16d       <none>
kube-system   generic-garbage-collector-token-9tfjt            kubernetes.io/service-account-token   3         16d       <none>
kube-system   horizontal-pod-autoscaler-token-rgs5t            kubernetes.io/service-account-token   3         16d       <none>
kube-system   job-controller-token-l2pqw                       kubernetes.io/service-account-token   3         16d       <none>
kube-system   kube-proxy-token-wmgjk                           kubernetes.io/service-account-token   3         16d       <none>
kube-system   namespace-controller-token-z9r52                 kubernetes.io/service-account-token   3         16d       <none>
kube-system   node-controller-token-7d5zm                      kubernetes.io/service-account-token   3         16d       <none>
kube-system   persistent-volume-binder-token-8tbq2             kubernetes.io/service-account-token   3         16d       <none>
kube-system   pod-garbage-collector-token-7twr4                kubernetes.io/service-account-token   3         16d       <none>
kube-system   replicaset-controller-token-8whxt                kubernetes.io/service-account-token   3         16d       <none>
kube-system   replication-controller-token-dlvxb               kubernetes.io/service-account-token   3         16d       <none>
kube-system   resourcequota-controller-token-blqxz             kubernetes.io/service-account-token   3         16d       <none>
kube-system   service-account-controller-token-pb4fp           kubernetes.io/service-account-token   3         16d       <none>
kube-system   service-controller-token-gfn6t                   kubernetes.io/service-account-token   3         16d       <none>
kube-system   statefulset-controller-token-4zzvr               kubernetes.io/service-account-token   3         16d       <none>
kube-system   token-cleaner-token-n6zmf                        kubernetes.io/service-account-token   3         16d       <none>
kube-system   ttl-controller-token-26zh6                       kubernetes.io/service-account-token   3         16d       <none>
\n================
kubectl get serviceaccounts --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME                                 SECRETS   AGE       LABELS
default       default                              1         16d       <none>
kube-public   default                              1         16d       <none>
kube-system   attachdetach-controller              1         16d       <none>
kube-system   bootstrap-signer                     1         16d       <none>
kube-system   certificate-controller               1         16d       <none>
kube-system   clusterrole-aggregation-controller   1         16d       <none>
kube-system   contiv-netmaster                     1         16d       kubernetes.io/cluster-service=true
kube-system   contiv-netplugin                     1         16d       kubernetes.io/cluster-service=true
kube-system   cronjob-controller                   1         16d       <none>
kube-system   daemon-set-controller                1         16d       <none>
kube-system   default                              1         16d       <none>
kube-system   deployment-controller                1         16d       <none>
kube-system   disruption-controller                1         16d       <none>
kube-system   endpoint-controller                  1         16d       <none>
kube-system   generic-garbage-collector            1         16d       <none>
kube-system   horizontal-pod-autoscaler            1         16d       <none>
kube-system   job-controller                       1         16d       <none>
kube-system   kube-proxy                           1         16d       <none>
kube-system   namespace-controller                 1         16d       <none>
kube-system   node-controller                      1         16d       <none>
kube-system   persistent-volume-binder             1         16d       <none>
kube-system   pod-garbage-collector                1         16d       <none>
kube-system   replicaset-controller                1         16d       <none>
kube-system   replication-controller               1         16d       <none>
kube-system   resourcequota-controller             1         16d       <none>
kube-system   service-account-controller           1         16d       <none>
kube-system   service-controller                   1         16d       <none>
kube-system   statefulset-controller               1         16d       <none>
kube-system   token-cleaner                        1         16d       <none>
kube-system   ttl-controller                       1         16d       <none>
\n================
kubectl get services --all-namespaces --show-labels -o wide
================\n
NAMESPACE     NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE       SELECTOR              LABELS
default       kubernetes    ClusterIP   10.96.0.1       <none>        443/TCP    16d       <none>                component=apiserver,provider=kubernetes
kube-system   contiv-etcd   ClusterIP   10.96.232.136   <none>        6666/TCP   16d       k8s-app=contiv-etcd   k8s-app=contiv-etcd
\n================
kubectl get statefulsets --all-namespaces --show-labels -o wide
================\n
No resources found.
\n================
kubectl get kubectl --all-namespaces --show-labels -o wide && echo ================n && kubectl get kubectl --all-namespaces --show-labels -o wide
\n================
kubectl describe all --all-namespaces
================\n
Name:           contiv-etcd
Selector:       k8s-app=contiv-etcd
Node-Selector:  node-role.kubernetes.io/master=
Labels:         k8s-app=contiv-etcd
Annotations:    kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":...
Desired Number of Nodes Scheduled: 1
Current Number of Nodes Scheduled: 1
Number of Nodes Scheduled with Up-to-date Pods: 1
Number of Nodes Scheduled with Available Pods: 1
Number of Nodes Misscheduled: 0
Pods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:       k8s-app=contiv-etcd
  Annotations:  scheduler.alpha.kubernetes.io/critical-pod=
  Containers:
   contiv-etcd:
    Image:  quay.io/coreos/etcd:v3.2.4
    Port:   <none>
    Command:
      /bin/sh
      -c
    Args:
      ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
    Environment:
      CONTIV_ETCD_IP:            (v1:status.podIP)
      ETCD_NAME:                contiv-etcd
      ETCD_DATA_DIR:            /var/lib/etcd/contiv-data
      ETCD_LISTEN_CLIENT_URLS:  http://0.0.0.0:6666
      ETCD_LISTEN_PEER_URLS:    http://0.0.0.0:6667
    Mounts:
      /var/etcd from var-etcd (rw)
  Volumes:
   var-etcd:
    Type:          HostPath (bare host directory volume)
    Path:          /var/etcd
    HostPathType:  
Events:            <none>


Name:           contiv-netplugin
Selector:       k8s-app=contiv-netplugin
Node-Selector:  <none>
Labels:         k8s-app=contiv-netplugin
Annotations:    kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netplugin"},"name":"contiv-netplugin","n...
Desired Number of Nodes Scheduled: 4
Current Number of Nodes Scheduled: 4
Number of Nodes Scheduled with Up-to-date Pods: 4
Number of Nodes Scheduled with Available Pods: 4
Number of Nodes Misscheduled: 0
Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           k8s-app=contiv-netplugin
  Annotations:      scheduler.alpha.kubernetes.io/critical-pod=
  Service Account:  contiv-netplugin
  Init Containers:
   contiv-netplugin-init:
    Image:  contiv/netplugin-init:latest
    Port:   <none>
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
   contiv-cni:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    Environment:  <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
  Containers:
   contiv-netplugin:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      tail
      -f
      /dev/null
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
  Volumes:
   var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
   var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
   cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
   etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
   contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
   contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
   contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
Events:            <none>


Name:           contiv-ovs
Selector:       k8s-app=contiv-ovs
Node-Selector:  <none>
Labels:         k8s-app=contiv-ovs
Annotations:    kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-ovs"},"name":"contiv-ovs","namespace":"k...
Desired Number of Nodes Scheduled: 4
Current Number of Nodes Scheduled: 4
Number of Nodes Scheduled with Up-to-date Pods: 4
Number of Nodes Scheduled with Available Pods: 4
Number of Nodes Misscheduled: 0
Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:       k8s-app=contiv-ovs
  Annotations:  scheduler.alpha.kubernetes.io/critical-pod=
  Containers:
   contiv-ovsdb-server:
    Image:  contiv/ovs:latest
    Port:   <none>
    Command:
      /scripts/start-ovsdb-server.sh
    Environment:  <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
   contiv-ovs-vswitchd:
    Image:  contiv/ovs:latest
    Port:   <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    Environment:  <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
  Volumes:
   etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
   lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
   var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
Events:            <none>


Name:           kube-proxy
Selector:       k8s-app=kube-proxy
Node-Selector:  <none>
Labels:         k8s-app=kube-proxy
Annotations:    <none>
Desired Number of Nodes Scheduled: 4
Current Number of Nodes Scheduled: 4
Number of Nodes Scheduled with Up-to-date Pods: 4
Number of Nodes Scheduled with Available Pods: 4
Number of Nodes Misscheduled: 0
Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           k8s-app=kube-proxy
  Service Account:  kube-proxy
  Containers:
   kube-proxy:
    Image:  gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Port:   <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    Environment:  <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
  Volumes:
   kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
   xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
   lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
Events:            <none>


Name:         contiv-netmaster
Namespace:    kube-system
Selector:     k8s-app=contiv-netmaster
Labels:       k8s-app=contiv-netmaster
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"ReplicaSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netmaster"},"name":"contiv-netmaster","...
Replicas:     1 current / 1 desired
Pods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           k8s-app=contiv-netmaster
  Annotations:      scheduler.alpha.kubernetes.io/critical-pod=
  Service Account:  contiv-netmaster
  Init Containers:
   contiv-netplugin-init:
    Image:  contiv/netplugin-init:latest
    Port:   <none>
    Environment:
      CONTIV_ROLE:        netmaster
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /var/contiv from var-contiv (rw)
   contiv-netctl:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      cp
      /contiv/bin/netctl
      /usr/local/sbin/netctl
    Environment:  <none>
    Mounts:
      /usr/local/sbin/ from usr-local-sbin (rw)
  Containers:
   contiv-netmaster:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      tail
      -f
      /dev/null
    Environment:
      CONTIV_ROLE:                    netmaster
      CONTIV_NETMASTER_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>     Optional: false
      CONTIV_NETMASTER_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETMASTER_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
  Volumes:
   var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
   usr-local-sbin:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/local/sbin/
    HostPathType:  
   contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
   contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
   contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
Events:            <none>


Name:           contiv-etcd
Selector:       k8s-app=contiv-etcd
Node-Selector:  node-role.kubernetes.io/master=
Labels:         k8s-app=contiv-etcd
Annotations:    kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":...
Desired Number of Nodes Scheduled: 1
Current Number of Nodes Scheduled: 1
Number of Nodes Scheduled with Up-to-date Pods: 1
Number of Nodes Scheduled with Available Pods: 1
Number of Nodes Misscheduled: 0
Pods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:       k8s-app=contiv-etcd
  Annotations:  scheduler.alpha.kubernetes.io/critical-pod=
  Containers:
   contiv-etcd:
    Image:  quay.io/coreos/etcd:v3.2.4
    Port:   <none>
    Command:
      /bin/sh
      -c
    Args:
      ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
    Environment:
      CONTIV_ETCD_IP:            (v1:status.podIP)
      ETCD_NAME:                contiv-etcd
      ETCD_DATA_DIR:            /var/lib/etcd/contiv-data
      ETCD_LISTEN_CLIENT_URLS:  http://0.0.0.0:6666
      ETCD_LISTEN_PEER_URLS:    http://0.0.0.0:6667
    Mounts:
      /var/etcd from var-etcd (rw)
  Volumes:
   var-etcd:
    Type:          HostPath (bare host directory volume)
    Path:          /var/etcd
    HostPathType:  
Events:            <none>


Name:           contiv-netplugin
Selector:       k8s-app=contiv-netplugin
Node-Selector:  <none>
Labels:         k8s-app=contiv-netplugin
Annotations:    kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netplugin"},"name":"contiv-netplugin","n...
Desired Number of Nodes Scheduled: 4
Current Number of Nodes Scheduled: 4
Number of Nodes Scheduled with Up-to-date Pods: 4
Number of Nodes Scheduled with Available Pods: 4
Number of Nodes Misscheduled: 0
Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           k8s-app=contiv-netplugin
  Annotations:      scheduler.alpha.kubernetes.io/critical-pod=
  Service Account:  contiv-netplugin
  Init Containers:
   contiv-netplugin-init:
    Image:  contiv/netplugin-init:latest
    Port:   <none>
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
   contiv-cni:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    Environment:  <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
  Containers:
   contiv-netplugin:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      tail
      -f
      /dev/null
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
  Volumes:
   var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
   var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
   cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
   etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
   contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
   contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
   contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
Events:            <none>


Name:           contiv-ovs
Selector:       k8s-app=contiv-ovs
Node-Selector:  <none>
Labels:         k8s-app=contiv-ovs
Annotations:    kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-ovs"},"name":"contiv-ovs","namespace":"k...
Desired Number of Nodes Scheduled: 4
Current Number of Nodes Scheduled: 4
Number of Nodes Scheduled with Up-to-date Pods: 4
Number of Nodes Scheduled with Available Pods: 4
Number of Nodes Misscheduled: 0
Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:       k8s-app=contiv-ovs
  Annotations:  scheduler.alpha.kubernetes.io/critical-pod=
  Containers:
   contiv-ovsdb-server:
    Image:  contiv/ovs:latest
    Port:   <none>
    Command:
      /scripts/start-ovsdb-server.sh
    Environment:  <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
   contiv-ovs-vswitchd:
    Image:  contiv/ovs:latest
    Port:   <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    Environment:  <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
  Volumes:
   etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
   lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
   var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
Events:            <none>


Name:           kube-proxy
Selector:       k8s-app=kube-proxy
Node-Selector:  <none>
Labels:         k8s-app=kube-proxy
Annotations:    <none>
Desired Number of Nodes Scheduled: 4
Current Number of Nodes Scheduled: 4
Number of Nodes Scheduled with Up-to-date Pods: 4
Number of Nodes Scheduled with Available Pods: 4
Number of Nodes Misscheduled: 0
Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           k8s-app=kube-proxy
  Service Account:  kube-proxy
  Containers:
   kube-proxy:
    Image:  gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Port:   <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    Environment:  <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
  Volumes:
   kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
   xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
   lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
Events:            <none>


Name:         contiv-netmaster
Namespace:    kube-system
Selector:     k8s-app=contiv-netmaster
Labels:       k8s-app=contiv-netmaster
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"ReplicaSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netmaster"},"name":"contiv-netmaster","...
Replicas:     1 current / 1 desired
Pods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           k8s-app=contiv-netmaster
  Annotations:      scheduler.alpha.kubernetes.io/critical-pod=
  Service Account:  contiv-netmaster
  Init Containers:
   contiv-netplugin-init:
    Image:  contiv/netplugin-init:latest
    Port:   <none>
    Environment:
      CONTIV_ROLE:        netmaster
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /var/contiv from var-contiv (rw)
   contiv-netctl:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      cp
      /contiv/bin/netctl
      /usr/local/sbin/netctl
    Environment:  <none>
    Mounts:
      /usr/local/sbin/ from usr-local-sbin (rw)
  Containers:
   contiv-netmaster:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      tail
      -f
      /dev/null
    Environment:
      CONTIV_ROLE:                    netmaster
      CONTIV_NETMASTER_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>     Optional: false
      CONTIV_NETMASTER_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETMASTER_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
  Volumes:
   var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
   usr-local-sbin:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/local/sbin/
    HostPathType:  
   contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
   contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
   contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
Events:            <none>


Name:           contiv-etcd-6mcxz
Namespace:      kube-system
Node:           k8master/192.168.2.10
Start Time:     Sat, 03 Feb 2018 22:37:53 +0000
Labels:         controller-revision-hash=3440706255
                k8s-app=contiv-etcd
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.10
Controlled By:  DaemonSet/contiv-etcd
Containers:
  contiv-etcd:
    Container ID:  docker://c584086fab59c85c04c80b189f2b74361d8249d629812f1f12062311d6329732
    Image:         quay.io/coreos/etcd:v3.2.4
    Image ID:      docker-pullable://quay.io/coreos/etcd@sha256:0a582c6ca6d32f1bed74c51bb1e33a215b301e0f28683777ec6af0c2e3925588
    Port:          <none>
    Command:
      /bin/sh
      -c
    Args:
      ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
    State:          Running
      Started:      Sat, 03 Feb 2018 22:40:57 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ETCD_IP:            (v1:status.podIP)
      ETCD_NAME:                contiv-etcd
      ETCD_DATA_DIR:            /var/lib/etcd/contiv-data
      ETCD_LISTEN_CLIENT_URLS:  http://0.0.0.0:6666
      ETCD_LISTEN_PEER_URLS:    http://0.0.0.0:6667
    Mounts:
      /var/etcd from var-etcd (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-etcd:
    Type:          HostPath (bare host directory volume)
    Path:          /var/etcd
    HostPathType:  
  default-token-9ktff:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-9ktff
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  node-role.kubernetes.io/master=
Tolerations:     CriticalAddonsOnly
                 node-role.kubernetes.io/master:NoSchedule
                 node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-netmaster-vkc6s
Namespace:      kube-system
Node:           k8master/192.168.2.10
Start Time:     Sat, 03 Feb 2018 22:40:22 +0000
Labels:         k8s-app=contiv-netmaster
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.10
Controlled By:  ReplicaSet/contiv-netmaster
Init Containers:
  contiv-netplugin-init:
    Container ID:   docker://e1993b2b63c42729f6d24eaac6e4805e3509e39d08ff3078e27e5a52f8a2d74a
    Image:          contiv/netplugin-init:latest
    Image ID:       docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
    Port:           <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 22:44:46 +0000
      Finished:     Sat, 03 Feb 2018 22:44:49 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:        netmaster
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /var/contiv from var-contiv (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netmaster-token-47bxd (ro)
  contiv-netctl:
    Container ID:  docker://0c9a499dd9a3f027c6aafa2fadac4820d4977eb6a6e036638ac8f3f32c636834
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      cp
      /contiv/bin/netctl
      /usr/local/sbin/netctl
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 22:45:07 +0000
      Finished:     Sat, 03 Feb 2018 22:45:07 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /usr/local/sbin/ from usr-local-sbin (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netmaster-token-47bxd (ro)
Containers:
  contiv-netmaster:
    Container ID:  docker://dd9e75217cfb963e0806de0d573fe10d28e9f71ff7e8fc560825e2e753903661
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      tail
      -f
      /dev/null
    State:          Running
      Started:      Sat, 03 Feb 2018 22:45:18 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:                    netmaster
      CONTIV_NETMASTER_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>     Optional: false
      CONTIV_NETMASTER_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETMASTER_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netmaster-token-47bxd (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
  usr-local-sbin:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/local/sbin/
    HostPathType:  
  contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
  contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
  contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
  contiv-netmaster-token-47bxd:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  contiv-netmaster-token-47bxd
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  node-role.kubernetes.io/master=
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:          <none>


Name:           contiv-netplugin-2d7rp
Namespace:      kube-system
Node:           k8node-02/192.168.2.12
Start Time:     Sat, 03 Feb 2018 22:55:38 +0000
Labels:         controller-revision-hash=4029632485
                k8s-app=contiv-netplugin
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.12
Controlled By:  DaemonSet/contiv-netplugin
Init Containers:
  contiv-netplugin-init:
    Container ID:   docker://92bb1a18866c331d3273f8c89b77e922ae6370346d8ca90e077419edede9193c
    Image:          contiv/netplugin-init:latest
    Image ID:       docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
    Port:           <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 23:00:52 +0000
      Finished:     Sat, 03 Feb 2018 23:00:52 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
  contiv-cni:
    Container ID:  docker://26a9d7ca4ecda56afd9b216076f091466ee1a40b7a81f30907af18446d947064
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 23:06:16 +0000
      Finished:     Sat, 03 Feb 2018 23:06:16 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Containers:
  contiv-netplugin:
    Container ID:  docker://d87a66a8c2913d4ec5daecfadf73b64e38872b00b37a1e58021b4c465654ef72
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      tail
      -f
      /dev/null
    State:          Running
      Started:      Sat, 03 Feb 2018 23:08:19 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
  cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
  etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
  contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
  contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
  contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
  contiv-netplugin-token-xqsb5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  contiv-netplugin-token-xqsb5
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-netplugin-5pqjs
Namespace:      kube-system
Node:           k8node-03/192.168.2.13
Start Time:     Sat, 03 Feb 2018 23:06:39 +0000
Labels:         controller-revision-hash=4029632485
                k8s-app=contiv-netplugin
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.13
Controlled By:  DaemonSet/contiv-netplugin
Init Containers:
  contiv-netplugin-init:
    Container ID:   docker://d3d3cae725515e434b8fffe529d9255b15a9a7772812aa604997b727ecae8933
    Image:          contiv/netplugin-init:latest
    Image ID:       docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
    Port:           <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 23:09:07 +0000
      Finished:     Sat, 03 Feb 2018 23:09:07 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
  contiv-cni:
    Container ID:  docker://80fe8f20c15247503588028d51f9595ed406561b1d940c1e47e1b473b70ff967
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 23:13:07 +0000
      Finished:     Sat, 03 Feb 2018 23:13:07 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Containers:
  contiv-netplugin:
    Container ID:  docker://71658aba1dea2b49ad888b5d6880c5313dc5635945df76491a5f51d33da5d857
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      tail
      -f
      /dev/null
    State:          Running
      Started:      Sat, 03 Feb 2018 23:13:14 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
  cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
  etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
  contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
  contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
  contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
  contiv-netplugin-token-xqsb5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  contiv-netplugin-token-xqsb5
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-netplugin-qwgd5
Namespace:      kube-system
Node:           k8master/192.168.2.10
Start Time:     Sat, 03 Feb 2018 22:37:53 +0000
Labels:         controller-revision-hash=4029632485
                k8s-app=contiv-netplugin
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.10
Controlled By:  DaemonSet/contiv-netplugin
Init Containers:
  contiv-netplugin-init:
    Container ID:   docker://04bc313a43b9a37cb93d161cdcb4e002824307b5c7db2b0ea664a577e879dd19
    Image:          contiv/netplugin-init:latest
    Image ID:       docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
    Port:           <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 22:40:07 +0000
      Finished:     Sat, 03 Feb 2018 22:40:12 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
  contiv-cni:
    Container ID:  docker://1e9df8ab383baf7e9890712058863f523b437a26acb84659006ede9551d3e533
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 22:44:39 +0000
      Finished:     Sat, 03 Feb 2018 22:44:39 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Containers:
  contiv-netplugin:
    Container ID:  docker://a4137c814f9832676d7df279495ab131f77f1119ad666633ee0cae9c8d6f4c1b
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      tail
      -f
      /dev/null
    State:          Running
      Started:      Sat, 03 Feb 2018 22:45:09 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
  cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
  etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
  contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
  contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
  contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
  contiv-netplugin-token-xqsb5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  contiv-netplugin-token-xqsb5
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-netplugin-xwxkn
Namespace:      kube-system
Node:           k8node-01/192.168.2.11
Start Time:     Sat, 03 Feb 2018 22:47:46 +0000
Labels:         controller-revision-hash=4029632485
                k8s-app=contiv-netplugin
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.11
Controlled By:  DaemonSet/contiv-netplugin
Init Containers:
  contiv-netplugin-init:
    Container ID:   docker://d1526ce58adecc381edae40be851e718f64e6055678245513dc1cca02567c455
    Image:          contiv/netplugin-init:latest
    Image ID:       docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
    Port:           <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 22:48:51 +0000
      Finished:     Sat, 03 Feb 2018 22:48:51 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
  contiv-cni:
    Container ID:  docker://d47429eb736387693dcf5a8c9befea3aaec5353b18870a1ff084c2fbb7a4ef03
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 23:02:59 +0000
      Finished:     Sat, 03 Feb 2018 23:03:00 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Containers:
  contiv-netplugin:
    Container ID:  docker://9aaa1c9cb44a3e36a18bec6f9cf00f1c82e7c319ecbcd73cb78b208f7bcd5a44
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      tail
      -f
      /dev/null
    State:          Running
      Started:      Sat, 03 Feb 2018 23:03:18 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
  cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
  etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
  contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
  contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
  contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
  contiv-netplugin-token-xqsb5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  contiv-netplugin-token-xqsb5
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-ovs-8mfdn
Namespace:      kube-system
Node:           k8node-02/192.168.2.12
Start Time:     Sat, 03 Feb 2018 22:55:38 +0000
Labels:         controller-revision-hash=1824568849
                k8s-app=contiv-ovs
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.12
Controlled By:  DaemonSet/contiv-ovs
Containers:
  contiv-ovsdb-server:
    Container ID:  docker://9cb6eb87e5781c179ce895e55b02f926f3a7abcaf7a23c35a67dfcfe1a3c561d
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovsdb-server.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 23:01:06 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
  contiv-ovs-vswitchd:
    Container ID:  docker://5d3a3a03ca28ba31d3193f5c24367d5df59e620d5ef4b4012648498f54b37464
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 23:06:21 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  default-token-9ktff:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-9ktff
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-ovs-mwfjk
Namespace:      kube-system
Node:           k8master/192.168.2.10
Start Time:     Sat, 03 Feb 2018 22:37:53 +0000
Labels:         controller-revision-hash=1824568849
                k8s-app=contiv-ovs
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.10
Controlled By:  DaemonSet/contiv-ovs
Containers:
  contiv-ovsdb-server:
    Container ID:  docker://39e7cc6199270908b8fd259c1ff09e21af4cf64c5714d3525923ec8566555232
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovsdb-server.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 22:41:33 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
  contiv-ovs-vswitchd:
    Container ID:  docker://e32264562935b103bb84aa237add0c06ab70136ff288263bc78c03a3f0475553
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 22:44:51 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  default-token-9ktff:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-9ktff
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-ovs-zmk5s
Namespace:      kube-system
Node:           k8node-03/192.168.2.13
Start Time:     Sat, 03 Feb 2018 23:06:39 +0000
Labels:         controller-revision-hash=1824568849
                k8s-app=contiv-ovs
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.13
Controlled By:  DaemonSet/contiv-ovs
Containers:
  contiv-ovsdb-server:
    Container ID:  docker://dc98559482d862433e27244ecd0ee36fce64027dfb6ce1798ef6f633b6ae3e35
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovsdb-server.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 23:09:37 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
  contiv-ovs-vswitchd:
    Container ID:  docker://364a2a0e04c9e14f0ca1c85e40986f3d09b4643c45c5df03df4bbc06f26c456c
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 23:13:08 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  default-token-9ktff:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-9ktff
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-ovs-zwb9t
Namespace:      kube-system
Node:           k8node-01/192.168.2.11
Start Time:     Sat, 03 Feb 2018 22:47:46 +0000
Labels:         controller-revision-hash=1824568849
                k8s-app=contiv-ovs
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.11
Controlled By:  DaemonSet/contiv-ovs
Containers:
  contiv-ovsdb-server:
    Container ID:  docker://abfd1933ea861649f13510742edc983ea29e56c8c7f0002bc8515e1763423157
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovsdb-server.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 22:51:27 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
  contiv-ovs-vswitchd:
    Container ID:  docker://9fc9fad02f6bb178f3e63e4d2023e34c7f93abc1a350e61630c3360acc770902
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 22:53:33 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  default-token-9ktff:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-9ktff
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:         etcd-k8master
Namespace:    kube-system
Node:         k8master/192.168.2.10
Start Time:   Sat, 03 Feb 2018 22:31:55 +0000
Labels:       component=etcd
              tier=control-plane
Annotations:  kubernetes.io/config.hash=7278f85057e8bf5cb81c9f96d3b25320
              kubernetes.io/config.mirror=7278f85057e8bf5cb81c9f96d3b25320
              kubernetes.io/config.seen=2018-02-03T22:31:50.423856543Z
              kubernetes.io/config.source=file
              scheduler.alpha.kubernetes.io/critical-pod=
Status:       Running
IP:           192.168.2.10
Containers:
  etcd:
    Container ID:  docker://eab796c7ae3cc778244b6175dc7a8e081f57b4dd79bfc77346b5e12e1e87460e
    Image:         gcr.io/google_containers/etcd-amd64:3.1.11
    Image ID:      docker-pullable://gcr.io/google_containers/etcd-amd64@sha256:54889c08665d241e321ca5ce976b2df0f766794b698d53faf6b7dacb95316680
    Port:          <none>
    Command:
      etcd
      --listen-client-urls=http://127.0.0.1:2379
      --advertise-client-urls=http://127.0.0.1:2379
      --data-dir=/var/lib/etcd
    State:          Running
      Started:      Sat, 03 Feb 2018 22:35:31 +0000
    Ready:          True
    Restart Count:  0
    Liveness:       http-get http://127.0.0.1:2379/health delay=15s timeout=15s period=10s #success=1 #failure=8
    Environment:    <none>
    Mounts:
      /var/lib/etcd from etcd (rw)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  etcd:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/etcd
    HostPathType:  DirectoryOrCreate
QoS Class:         BestEffort
Node-Selectors:    <none>
Tolerations:       :NoExecute
Events:            <none>


Name:         kube-apiserver-k8master
Namespace:    kube-system
Node:         k8master/192.168.2.10
Start Time:   Sat, 03 Feb 2018 22:31:55 +0000
Labels:       component=kube-apiserver
              tier=control-plane
Annotations:  kubernetes.io/config.hash=8269013687f7c93ae98df858c8ca8f73
              kubernetes.io/config.mirror=8269013687f7c93ae98df858c8ca8f73
              kubernetes.io/config.seen=2018-02-03T22:31:50.423866266Z
              kubernetes.io/config.source=file
              scheduler.alpha.kubernetes.io/critical-pod=
Status:       Running
IP:           192.168.2.10
Containers:
  kube-apiserver:
    Container ID:  docker://cd38db17a5b2870dc43318f687d04a037c731188efee8818dde853cfc5c52535
    Image:         gcr.io/google_containers/kube-apiserver-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-apiserver-amd64@sha256:eec4329de0892f4a960b7f1202272f93880d3071a9b40d8407585125b37d527d
    Port:          <none>
    Command:
      kube-apiserver
      --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      --secure-port=6443
      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      --requestheader-allowed-names=front-proxy-client
      --service-cluster-ip-range=10.96.0.0/12
      --service-account-key-file=/etc/kubernetes/pki/sa.pub
      --allow-privileged=true
      --requestheader-group-headers=X-Remote-Group
      --advertise-address=192.168.2.10
      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      --insecure-port=0
      --admission-control=Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota
      --enable-bootstrap-token-auth=true
      --client-ca-file=/etc/kubernetes/pki/ca.crt
      --requestheader-username-headers=X-Remote-User
      --requestheader-extra-headers-prefix=X-Remote-Extra-
      --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      --authorization-mode=Node,RBAC
      --etcd-servers=http://127.0.0.1:2379
    State:          Running
      Started:      Sat, 03 Feb 2018 22:37:21 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:     250m
    Liveness:  http-get https://192.168.2.10:6443/healthz delay=15s timeout=15s period=10s #success=1 #failure=8
    Environment:
      no_proxy:  k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
    Mounts:
      /etc/kubernetes/pki from k8s-certs (ro)
      /etc/pki from ca-certs-etc-pki (ro)
      /etc/ssl/certs from ca-certs (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  k8s-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/pki
    HostPathType:  DirectoryOrCreate
  ca-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ssl/certs
    HostPathType:  DirectoryOrCreate
  ca-certs-etc-pki:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/pki
    HostPathType:  DirectoryOrCreate
QoS Class:         Burstable
Node-Selectors:    <none>
Tolerations:       :NoExecute
Events:            <none>


Name:         kube-controller-manager-k8master
Namespace:    kube-system
Node:         k8master/192.168.2.10
Start Time:   Sat, 03 Feb 2018 22:31:55 +0000
Labels:       component=kube-controller-manager
              tier=control-plane
Annotations:  kubernetes.io/config.hash=3e62d6d6684d8169bc7a1ad3c99997bc
              kubernetes.io/config.mirror=3e62d6d6684d8169bc7a1ad3c99997bc
              kubernetes.io/config.seen=2018-02-03T22:31:50.423869393Z
              kubernetes.io/config.source=file
              scheduler.alpha.kubernetes.io/critical-pod=
Status:       Running
IP:           192.168.2.10
Containers:
  kube-controller-manager:
    Container ID:  docker://409aa1bbfd5ace3dc4891da1aa7b841aa7b43a075c19dd1cc832ce67e8a31058
    Image:         gcr.io/google_containers/kube-controller-manager-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-controller-manager-amd64@sha256:10daf65c6e8d0ff032323931f3869cd30af23feab90345265ea405b6104a41c7
    Port:          <none>
    Command:
      kube-controller-manager
      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      --address=127.0.0.1
      --use-service-account-credentials=true
      --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      --root-ca-file=/etc/kubernetes/pki/ca.crt
      --leader-elect=true
      --controllers=*,bootstrapsigner,tokencleaner
      --kubeconfig=/etc/kubernetes/controller-manager.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 22:33:16 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:     200m
    Liveness:  http-get http://127.0.0.1:10252/healthz delay=15s timeout=15s period=10s #success=1 #failure=8
    Environment:
      no_proxy:  k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
    Mounts:
      /etc/kubernetes/controller-manager.conf from kubeconfig (ro)
      /etc/kubernetes/pki from k8s-certs (ro)
      /etc/pki from ca-certs-etc-pki (ro)
      /etc/ssl/certs from ca-certs (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  k8s-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/pki
    HostPathType:  DirectoryOrCreate
  ca-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ssl/certs
    HostPathType:  DirectoryOrCreate
  kubeconfig:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/controller-manager.conf
    HostPathType:  FileOrCreate
  ca-certs-etc-pki:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/pki
    HostPathType:  DirectoryOrCreate
QoS Class:         Burstable
Node-Selectors:    <none>
Tolerations:       :NoExecute
Events:            <none>


Name:           kube-proxy-6j2b4
Namespace:      kube-system
Node:           k8node-03/192.168.2.13
Start Time:     Sat, 03 Feb 2018 23:06:39 +0000
Labels:         controller-revision-hash=588621068
                k8s-app=kube-proxy
                pod-template-generation=1
Annotations:    <none>
Status:         Running
IP:             192.168.2.13
Controlled By:  DaemonSet/kube-proxy
Containers:
  kube-proxy:
    Container ID:  docker://6a1d4fb9c76c4750bbf134fd7baa1d5462cca42342e1d47cfc4c967048126c7a
    Image:         gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
    Port:          <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 23:10:53 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-proxy-token-wmgjk (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
  xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  kube-proxy-token-wmgjk:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  kube-proxy-token-wmgjk
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           kube-proxy-8wx7q
Namespace:      kube-system
Node:           k8master/192.168.2.10
Start Time:     Sat, 03 Feb 2018 22:37:43 +0000
Labels:         controller-revision-hash=588621068
                k8s-app=kube-proxy
                pod-template-generation=1
Annotations:    <none>
Status:         Running
IP:             192.168.2.10
Controlled By:  DaemonSet/kube-proxy
Containers:
  kube-proxy:
    Container ID:  docker://b893576cd9a52e57bc66c2d9572c8d677f3c8a619702f911146d09d5ecd5204f
    Image:         gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
    Port:          <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 22:39:37 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-proxy-token-wmgjk (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
  xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  kube-proxy-token-wmgjk:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  kube-proxy-token-wmgjk
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           kube-proxy-l9msk
Namespace:      kube-system
Node:           k8node-02/192.168.2.12
Start Time:     Sat, 03 Feb 2018 22:55:38 +0000
Labels:         controller-revision-hash=588621068
                k8s-app=kube-proxy
                pod-template-generation=1
Annotations:    <none>
Status:         Running
IP:             192.168.2.12
Controlled By:  DaemonSet/kube-proxy
Containers:
  kube-proxy:
    Container ID:  docker://cac2484e758141295b0cabaf20a15c6d9bac8b8b22a91d7f6362bc23985ff510
    Image:         gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
    Port:          <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 23:08:19 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-proxy-token-wmgjk (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
  xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  kube-proxy-token-wmgjk:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  kube-proxy-token-wmgjk
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           kube-proxy-zg92c
Namespace:      kube-system
Node:           k8node-01/192.168.2.11
Start Time:     Sat, 03 Feb 2018 22:47:46 +0000
Labels:         controller-revision-hash=588621068
                k8s-app=kube-proxy
                pod-template-generation=1
Annotations:    <none>
Status:         Running
IP:             192.168.2.11
Controlled By:  DaemonSet/kube-proxy
Containers:
  kube-proxy:
    Container ID:  docker://c33c70f5a692eb4786b50bc8b136745b04d0ac94529a537bbd35bfdee88f2b5f
    Image:         gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
    Port:          <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 22:50:53 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-proxy-token-wmgjk (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
  xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  kube-proxy-token-wmgjk:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  kube-proxy-token-wmgjk
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:         kube-scheduler-k8master
Namespace:    kube-system
Node:         k8master/192.168.2.10
Start Time:   Sat, 03 Feb 2018 22:31:55 +0000
Labels:       component=kube-scheduler
              tier=control-plane
Annotations:  kubernetes.io/config.hash=419e9c2b7c2d4889af65758618bbed88
              kubernetes.io/config.mirror=419e9c2b7c2d4889af65758618bbed88
              kubernetes.io/config.seen=2018-02-03T22:31:50.423881438Z
              kubernetes.io/config.source=file
              scheduler.alpha.kubernetes.io/critical-pod=
Status:       Running
IP:           192.168.2.10
Containers:
  kube-scheduler:
    Container ID:  docker://75dfd82dae23666b4c39b3d32221913e7e4181323a13b711fdf6121d6d6c672e
    Image:         gcr.io/google_containers/kube-scheduler-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-scheduler-amd64@sha256:082520e24e697f3228046ca13cddf46e4e01ae2982685b4ccc7df8f8e9145abc
    Port:          <none>
    Command:
      kube-scheduler
      --address=127.0.0.1
      --leader-elect=true
      --kubeconfig=/etc/kubernetes/scheduler.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 22:33:45 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:     100m
    Liveness:  http-get http://127.0.0.1:10251/healthz delay=15s timeout=15s period=10s #success=1 #failure=8
    Environment:
      no_proxy:  k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
    Mounts:
      /etc/kubernetes/scheduler.conf from kubeconfig (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  kubeconfig:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/scheduler.conf
    HostPathType:  FileOrCreate
QoS Class:         Burstable
Node-Selectors:    <none>
Tolerations:       :NoExecute
Events:            <none>


Name:              kubernetes
Namespace:         default
Labels:            component=apiserver
                   provider=kubernetes
Annotations:       <none>
Selector:          <none>
Type:              ClusterIP
IP:                10.96.0.1
Port:              https  443/TCP
TargetPort:        6443/TCP
Endpoints:         192.168.2.10:6443
Session Affinity:  ClientIP
Events:            <none>


Name:              contiv-etcd
Namespace:         kube-system
Labels:            k8s-app=contiv-etcd
Annotations:       kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":"kube-system"},"sp...
Selector:          k8s-app=contiv-etcd
Type:              ClusterIP
IP:                10.96.232.136
Port:              <unset>  6666/TCP
TargetPort:        6666/TCP
Endpoints:         192.168.2.10:6666
Session Affinity:  None
Events:            <none>
\n================
kubectl describe certificatesigningrequests --all-namespaces
================\n
Name:               node-csr-NQ3d6g41WV1WWJisOnSa9fS7yJOwNd_lR1Aic4EnvQA
Labels:             <none>
Annotations:        <none>
CreationTimestamp:  Sat, 03 Feb 2018 23:06:35 +0000
Requesting User:    system:bootstrap:d0d1be
Status:             Approved,Issued
Subject:
         Common Name:    system:node:k8node-03
         Serial Number:  
         Organization:   system:nodes
Events:  <none>


Name:               node-csr-WebmZ45AIlmmXlhpUOInVWUntDe1z8m2eTN8YwFCm2s
Labels:             <none>
Annotations:        <none>
CreationTimestamp:  Sat, 03 Feb 2018 22:46:44 +0000
Requesting User:    system:bootstrap:d0d1be
Status:             Approved,Issued
Subject:
         Common Name:    system:node:k8node-01
         Serial Number:  
         Organization:   system:nodes
Events:  <none>


Name:               node-csr-jtPWYkKUWhh1-OuAIo7wM7YG-RRp3viT2EfJy33wHjI
Labels:             <none>
Annotations:        <none>
CreationTimestamp:  Sat, 03 Feb 2018 22:55:34 +0000
Requesting User:    system:bootstrap:d0d1be
Status:             Approved,Issued
Subject:
         Common Name:    system:node:k8node-02
         Serial Number:  
         Organization:   system:nodes
Events:  <none>
\n================
kubectl describe clusterrolebindings --all-namespaces
================\n
Name:         cluster-admin
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  cluster-admin
Subjects:
  Kind   Name            Namespace
  ----   ----            ---------
  Group  system:masters  


Name:         contiv-netmaster
Labels:       <none>
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"rbac.authorization.k8s.io/v1beta1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"name":"contiv-netmaster","namespace":""},"r...
Role:
  Kind:  ClusterRole
  Name:  contiv-netmaster
Subjects:
  Kind            Name              Namespace
  ----            ----              ---------
  ServiceAccount  contiv-netmaster  kube-system


Name:         contiv-netplugin
Labels:       <none>
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"rbac.authorization.k8s.io/v1beta1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"name":"contiv-netplugin","namespace":""},"r...
Role:
  Kind:  ClusterRole
  Name:  contiv-netplugin
Subjects:
  Kind            Name              Namespace
  ----            ----              ---------
  ServiceAccount  contiv-netplugin  kube-system


Name:         kubeadm:kubelet-bootstrap
Labels:       <none>
Annotations:  <none>
Role:
  Kind:  ClusterRole
  Name:  system:node-bootstrapper
Subjects:
  Kind   Name                                             Namespace
  ----   ----                                             ---------
  Group  system:bootstrappers:kubeadm:default-node-token  


Name:         kubeadm:node-autoapprove-bootstrap
Labels:       <none>
Annotations:  <none>
Role:
  Kind:  ClusterRole
  Name:  system:certificates.k8s.io:certificatesigningrequests:nodeclient
Subjects:
  Kind   Name                                             Namespace
  ----   ----                                             ---------
  Group  system:bootstrappers:kubeadm:default-node-token  


Name:         kubeadm:node-autoapprove-certificate-rotation
Labels:       <none>
Annotations:  <none>
Role:
  Kind:  ClusterRole
  Name:  system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
Subjects:
  Kind   Name          Namespace
  ----   ----          ---------
  Group  system:nodes  


Name:         kubeadm:node-proxier
Labels:       <none>
Annotations:  <none>
Role:
  Kind:  ClusterRole
  Name:  system:node-proxier
Subjects:
  Kind            Name        Namespace
  ----            ----        ---------
  ServiceAccount  kube-proxy  kube-system


Name:         system:aws-cloud-provider
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:aws-cloud-provider
Subjects:
  Kind            Name                Namespace
  ----            ----                ---------
  ServiceAccount  aws-cloud-provider  kube-system


Name:         system:basic-user
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:basic-user
Subjects:
  Kind   Name                    Namespace
  ----   ----                    ---------
  Group  system:authenticated    
  Group  system:unauthenticated  


Name:         system:controller:attachdetach-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:attachdetach-controller
Subjects:
  Kind            Name                     Namespace
  ----            ----                     ---------
  ServiceAccount  attachdetach-controller  kube-system


Name:         system:controller:certificate-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:certificate-controller
Subjects:
  Kind            Name                    Namespace
  ----            ----                    ---------
  ServiceAccount  certificate-controller  kube-system


Name:         system:controller:clusterrole-aggregation-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:clusterrole-aggregation-controller
Subjects:
  Kind            Name                                Namespace
  ----            ----                                ---------
  ServiceAccount  clusterrole-aggregation-controller  kube-system


Name:         system:controller:cronjob-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:cronjob-controller
Subjects:
  Kind            Name                Namespace
  ----            ----                ---------
  ServiceAccount  cronjob-controller  kube-system


Name:         system:controller:daemon-set-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:daemon-set-controller
Subjects:
  Kind            Name                   Namespace
  ----            ----                   ---------
  ServiceAccount  daemon-set-controller  kube-system


Name:         system:controller:deployment-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:deployment-controller
Subjects:
  Kind            Name                   Namespace
  ----            ----                   ---------
  ServiceAccount  deployment-controller  kube-system


Name:         system:controller:disruption-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:disruption-controller
Subjects:
  Kind            Name                   Namespace
  ----            ----                   ---------
  ServiceAccount  disruption-controller  kube-system


Name:         system:controller:endpoint-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:endpoint-controller
Subjects:
  Kind            Name                 Namespace
  ----            ----                 ---------
  ServiceAccount  endpoint-controller  kube-system


Name:         system:controller:generic-garbage-collector
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:generic-garbage-collector
Subjects:
  Kind            Name                       Namespace
  ----            ----                       ---------
  ServiceAccount  generic-garbage-collector  kube-system


Name:         system:controller:horizontal-pod-autoscaler
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:horizontal-pod-autoscaler
Subjects:
  Kind            Name                       Namespace
  ----            ----                       ---------
  ServiceAccount  horizontal-pod-autoscaler  kube-system


Name:         system:controller:job-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:job-controller
Subjects:
  Kind            Name            Namespace
  ----            ----            ---------
  ServiceAccount  job-controller  kube-system


Name:         system:controller:namespace-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:namespace-controller
Subjects:
  Kind            Name                  Namespace
  ----            ----                  ---------
  ServiceAccount  namespace-controller  kube-system


Name:         system:controller:node-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:node-controller
Subjects:
  Kind            Name             Namespace
  ----            ----             ---------
  ServiceAccount  node-controller  kube-system


Name:         system:controller:persistent-volume-binder
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:persistent-volume-binder
Subjects:
  Kind            Name                      Namespace
  ----            ----                      ---------
  ServiceAccount  persistent-volume-binder  kube-system


Name:         system:controller:pod-garbage-collector
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:pod-garbage-collector
Subjects:
  Kind            Name                   Namespace
  ----            ----                   ---------
  ServiceAccount  pod-garbage-collector  kube-system


Name:         system:controller:replicaset-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:replicaset-controller
Subjects:
  Kind            Name                   Namespace
  ----            ----                   ---------
  ServiceAccount  replicaset-controller  kube-system


Name:         system:controller:replication-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:replication-controller
Subjects:
  Kind            Name                    Namespace
  ----            ----                    ---------
  ServiceAccount  replication-controller  kube-system


Name:         system:controller:resourcequota-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:resourcequota-controller
Subjects:
  Kind            Name                      Namespace
  ----            ----                      ---------
  ServiceAccount  resourcequota-controller  kube-system


Name:         system:controller:route-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:route-controller
Subjects:
  Kind            Name              Namespace
  ----            ----              ---------
  ServiceAccount  route-controller  kube-system


Name:         system:controller:service-account-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:service-account-controller
Subjects:
  Kind            Name                        Namespace
  ----            ----                        ---------
  ServiceAccount  service-account-controller  kube-system


Name:         system:controller:service-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:service-controller
Subjects:
  Kind            Name                Namespace
  ----            ----                ---------
  ServiceAccount  service-controller  kube-system


Name:         system:controller:statefulset-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:statefulset-controller
Subjects:
  Kind            Name                    Namespace
  ----            ----                    ---------
  ServiceAccount  statefulset-controller  kube-system


Name:         system:controller:ttl-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:controller:ttl-controller
Subjects:
  Kind            Name            Namespace
  ----            ----            ---------
  ServiceAccount  ttl-controller  kube-system


Name:         system:discovery
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:discovery
Subjects:
  Kind   Name                    Namespace
  ----   ----                    ---------
  Group  system:authenticated    
  Group  system:unauthenticated  


Name:         system:kube-controller-manager
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:kube-controller-manager
Subjects:
  Kind  Name                            Namespace
  ----  ----                            ---------
  User  system:kube-controller-manager  


Name:         system:kube-scheduler
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:kube-scheduler
Subjects:
  Kind  Name                   Namespace
  ----  ----                   ---------
  User  system:kube-scheduler  


Name:         system:node
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:node
Subjects:
  Kind  Name  Namespace
  ----  ----  ---------


Name:         system:node-proxier
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  ClusterRole
  Name:  system:node-proxier
Subjects:
  Kind  Name               Namespace
  ----  ----               ---------
  User  system:kube-proxy  
\n================
kubectl describe clusterroles --all-namespaces
================\n
Name:         admin
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                       Non-Resource URLs  Resource Names  Verbs
  ---------                                       -----------------  --------------  -----
  bindings                                        []                 []              [get list watch]
  configmaps                                      []                 []              [create delete deletecollection get list patch update watch]
  cronjobs.batch                                  []                 []              [create delete deletecollection get list patch update watch]
  daemonsets.apps                                 []                 []              [create delete deletecollection get list patch update watch]
  daemonsets.extensions                           []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps                                []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions                          []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps/rollback                       []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions/rollback                 []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps/scale                          []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions/scale                    []                 []              [create delete deletecollection get list patch update watch]
  endpoints                                       []                 []              [create delete deletecollection get list patch update watch]
  events                                          []                 []              [get list watch]
  horizontalpodautoscalers.autoscaling            []                 []              [create delete deletecollection get list patch update watch]
  ingresses.extensions                            []                 []              [create delete deletecollection get list patch update watch]
  jobs.batch                                      []                 []              [create delete deletecollection get list patch update watch]
  limitranges                                     []                 []              [get list watch]
  localsubjectaccessreviews.authorization.k8s.io  []                 []              [create]
  namespaces                                      []                 []              [get list watch]
  namespaces/status                               []                 []              [get list watch]
  persistentvolumeclaims                          []                 []              [create delete deletecollection get list patch update watch]
  poddisruptionbudgets.policy                     []                 []              [create delete deletecollection get list patch update watch]
  pods                                            []                 []              [create delete deletecollection get list patch update watch]
  pods/attach                                     []                 []              [create delete deletecollection get list patch update watch]
  pods/exec                                       []                 []              [create delete deletecollection get list patch update watch]
  pods/log                                        []                 []              [get list watch]
  pods/portforward                                []                 []              [create delete deletecollection get list patch update watch]
  pods/proxy                                      []                 []              [create delete deletecollection get list patch update watch]
  pods/status                                     []                 []              [get list watch]
  replicasets.apps                                []                 []              [create delete deletecollection get list patch update watch]
  replicasets.extensions                          []                 []              [create delete deletecollection get list patch update watch]
  replicasets.apps/scale                          []                 []              [create delete deletecollection get list patch update watch]
  replicasets.extensions/scale                    []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers                          []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers/scale                    []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers.extensions/scale         []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers/status                   []                 []              [get list watch]
  resourcequotas                                  []                 []              [get list watch]
  resourcequotas/status                           []                 []              [get list watch]
  rolebindings.rbac.authorization.k8s.io          []                 []              [create delete deletecollection get list patch update watch]
  roles.rbac.authorization.k8s.io                 []                 []              [create delete deletecollection get list patch update watch]
  secrets                                         []                 []              [create delete deletecollection get list patch update watch]
  serviceaccounts                                 []                 []              [create delete deletecollection get list patch update watch impersonate]
  services                                        []                 []              [create delete deletecollection get list patch update watch]
  services/proxy                                  []                 []              [create delete deletecollection get list patch update watch]
  statefulsets.apps                               []                 []              [create delete deletecollection get list patch update watch]


Name:         cluster-admin
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
             [*]                []              [*]
  *.*        []                 []              [*]


Name:         contiv-netmaster
Labels:       <none>
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"rbac.authorization.k8s.io/v1beta1","kind":"ClusterRole","metadata":{"annotations":{},"name":"contiv-netmaster","namespace":""},"rules":[...
PolicyRule:
  Resources                   Non-Resource URLs  Resource Names  Verbs
  ---------                   -----------------  --------------  -----
  namespaces                  []                 []              [get watch list update]
  namespaces.extensions       []                 []              [get watch list update]
  networkpolicies             []                 []              [get watch list update]
  networkpolicies.extensions  []                 []              [get watch list update]
  nodes                       []                 []              [get watch list update]
  nodes.extensions            []                 []              [get watch list update]
  pods                        []                 []              [get watch list update]
  pods.extensions             []                 []              [get watch list update]


Name:         contiv-netplugin
Labels:       <none>
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"rbac.authorization.k8s.io/v1beta1","kind":"ClusterRole","metadata":{"annotations":{},"name":"contiv-netplugin","namespace":""},"rules":[...
PolicyRule:
  Resources                   Non-Resource URLs  Resource Names  Verbs
  ---------                   -----------------  --------------  -----
  endpoints                   []                 []              [watch list update get]
  endpoints.extensions        []                 []              [watch list update get]
  namespaces                  []                 []              [watch list update get]
  namespaces.extensions       []                 []              [watch list update get]
  networkpolicies             []                 []              [watch list update get]
  networkpolicies.extensions  []                 []              [watch list update get]
  nodes                       []                 []              [watch list update get]
  nodes.extensions            []                 []              [watch list update get]
  pods                        []                 []              [watch list update get]
  pods.extensions             []                 []              [watch list update get]
  services                    []                 []              [watch list update get]
  services.extensions         []                 []              [watch list update get]


Name:         edit
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                Non-Resource URLs  Resource Names  Verbs
  ---------                                -----------------  --------------  -----
  bindings                                 []                 []              [get list watch]
  configmaps                               []                 []              [create delete deletecollection get list patch update watch]
  cronjobs.batch                           []                 []              [create delete deletecollection get list patch update watch]
  daemonsets.apps                          []                 []              [create delete deletecollection get list patch update watch]
  daemonsets.extensions                    []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps                         []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions                   []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps/rollback                []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions/rollback          []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps/scale                   []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions/scale             []                 []              [create delete deletecollection get list patch update watch]
  endpoints                                []                 []              [create delete deletecollection get list patch update watch]
  events                                   []                 []              [get list watch]
  horizontalpodautoscalers.autoscaling     []                 []              [create delete deletecollection get list patch update watch]
  ingresses.extensions                     []                 []              [create delete deletecollection get list patch update watch]
  jobs.batch                               []                 []              [create delete deletecollection get list patch update watch]
  limitranges                              []                 []              [get list watch]
  namespaces                               []                 []              [get list watch]
  namespaces/status                        []                 []              [get list watch]
  persistentvolumeclaims                   []                 []              [create delete deletecollection get list patch update watch]
  poddisruptionbudgets.policy              []                 []              [create delete deletecollection get list patch update watch]
  pods                                     []                 []              [create delete deletecollection get list patch update watch]
  pods/attach                              []                 []              [create delete deletecollection get list patch update watch]
  pods/exec                                []                 []              [create delete deletecollection get list patch update watch]
  pods/log                                 []                 []              [get list watch]
  pods/portforward                         []                 []              [create delete deletecollection get list patch update watch]
  pods/proxy                               []                 []              [create delete deletecollection get list patch update watch]
  pods/status                              []                 []              [get list watch]
  replicasets.apps                         []                 []              [create delete deletecollection get list patch update watch]
  replicasets.extensions                   []                 []              [create delete deletecollection get list patch update watch]
  replicasets.apps/scale                   []                 []              [create delete deletecollection get list patch update watch]
  replicasets.extensions/scale             []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers                   []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers/scale             []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers.extensions/scale  []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers/status            []                 []              [get list watch]
  resourcequotas                           []                 []              [get list watch]
  resourcequotas/status                    []                 []              [get list watch]
  secrets                                  []                 []              [create delete deletecollection get list patch update watch]
  serviceaccounts                          []                 []              [create delete deletecollection get list patch update watch impersonate]
  services                                 []                 []              [create delete deletecollection get list patch update watch]
  services/proxy                           []                 []              [create delete deletecollection get list patch update watch]
  statefulsets.apps                        []                 []              [create delete deletecollection get list patch update watch]


Name:         system:aggregate-to-admin
Labels:       kubernetes.io/bootstrapping=rbac-defaults
              rbac.authorization.k8s.io/aggregate-to-admin=true
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                       Non-Resource URLs  Resource Names  Verbs
  ---------                                       -----------------  --------------  -----
  bindings                                        []                 []              [get list watch]
  configmaps                                      []                 []              [create delete deletecollection get list patch update watch]
  cronjobs.batch                                  []                 []              [create delete deletecollection get list patch update watch]
  daemonsets.apps                                 []                 []              [create delete deletecollection get list patch update watch]
  daemonsets.extensions                           []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps                                []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions                          []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps/rollback                       []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions/rollback                 []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps/scale                          []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions/scale                    []                 []              [create delete deletecollection get list patch update watch]
  endpoints                                       []                 []              [create delete deletecollection get list patch update watch]
  events                                          []                 []              [get list watch]
  horizontalpodautoscalers.autoscaling            []                 []              [create delete deletecollection get list patch update watch]
  ingresses.extensions                            []                 []              [create delete deletecollection get list patch update watch]
  jobs.batch                                      []                 []              [create delete deletecollection get list patch update watch]
  limitranges                                     []                 []              [get list watch]
  localsubjectaccessreviews.authorization.k8s.io  []                 []              [create]
  namespaces                                      []                 []              [get list watch]
  namespaces/status                               []                 []              [get list watch]
  persistentvolumeclaims                          []                 []              [create delete deletecollection get list patch update watch]
  poddisruptionbudgets.policy                     []                 []              [create delete deletecollection get list patch update watch]
  pods                                            []                 []              [create delete deletecollection get list patch update watch]
  pods/attach                                     []                 []              [create delete deletecollection get list patch update watch]
  pods/exec                                       []                 []              [create delete deletecollection get list patch update watch]
  pods/log                                        []                 []              [get list watch]
  pods/portforward                                []                 []              [create delete deletecollection get list patch update watch]
  pods/proxy                                      []                 []              [create delete deletecollection get list patch update watch]
  pods/status                                     []                 []              [get list watch]
  replicasets.apps                                []                 []              [create delete deletecollection get list patch update watch]
  replicasets.extensions                          []                 []              [create delete deletecollection get list patch update watch]
  replicasets.apps/scale                          []                 []              [create delete deletecollection get list patch update watch]
  replicasets.extensions/scale                    []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers                          []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers/scale                    []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers.extensions/scale         []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers/status                   []                 []              [get list watch]
  resourcequotas                                  []                 []              [get list watch]
  resourcequotas/status                           []                 []              [get list watch]
  rolebindings.rbac.authorization.k8s.io          []                 []              [create delete deletecollection get list patch update watch]
  roles.rbac.authorization.k8s.io                 []                 []              [create delete deletecollection get list patch update watch]
  secrets                                         []                 []              [create delete deletecollection get list patch update watch]
  serviceaccounts                                 []                 []              [create delete deletecollection get list patch update watch impersonate]
  services                                        []                 []              [create delete deletecollection get list patch update watch]
  services/proxy                                  []                 []              [create delete deletecollection get list patch update watch]
  statefulsets.apps                               []                 []              [create delete deletecollection get list patch update watch]


Name:         system:aggregate-to-edit
Labels:       kubernetes.io/bootstrapping=rbac-defaults
              rbac.authorization.k8s.io/aggregate-to-edit=true
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                Non-Resource URLs  Resource Names  Verbs
  ---------                                -----------------  --------------  -----
  bindings                                 []                 []              [get list watch]
  configmaps                               []                 []              [create delete deletecollection get list patch update watch]
  cronjobs.batch                           []                 []              [create delete deletecollection get list patch update watch]
  daemonsets.apps                          []                 []              [create delete deletecollection get list patch update watch]
  daemonsets.extensions                    []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps                         []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions                   []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps/rollback                []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions/rollback          []                 []              [create delete deletecollection get list patch update watch]
  deployments.apps/scale                   []                 []              [create delete deletecollection get list patch update watch]
  deployments.extensions/scale             []                 []              [create delete deletecollection get list patch update watch]
  endpoints                                []                 []              [create delete deletecollection get list patch update watch]
  events                                   []                 []              [get list watch]
  horizontalpodautoscalers.autoscaling     []                 []              [create delete deletecollection get list patch update watch]
  ingresses.extensions                     []                 []              [create delete deletecollection get list patch update watch]
  jobs.batch                               []                 []              [create delete deletecollection get list patch update watch]
  limitranges                              []                 []              [get list watch]
  namespaces                               []                 []              [get list watch]
  namespaces/status                        []                 []              [get list watch]
  persistentvolumeclaims                   []                 []              [create delete deletecollection get list patch update watch]
  poddisruptionbudgets.policy              []                 []              [create delete deletecollection get list patch update watch]
  pods                                     []                 []              [create delete deletecollection get list patch update watch]
  pods/attach                              []                 []              [create delete deletecollection get list patch update watch]
  pods/exec                                []                 []              [create delete deletecollection get list patch update watch]
  pods/log                                 []                 []              [get list watch]
  pods/portforward                         []                 []              [create delete deletecollection get list patch update watch]
  pods/proxy                               []                 []              [create delete deletecollection get list patch update watch]
  pods/status                              []                 []              [get list watch]
  replicasets.apps                         []                 []              [create delete deletecollection get list patch update watch]
  replicasets.extensions                   []                 []              [create delete deletecollection get list patch update watch]
  replicasets.apps/scale                   []                 []              [create delete deletecollection get list patch update watch]
  replicasets.extensions/scale             []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers                   []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers/scale             []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers.extensions/scale  []                 []              [create delete deletecollection get list patch update watch]
  replicationcontrollers/status            []                 []              [get list watch]
  resourcequotas                           []                 []              [get list watch]
  resourcequotas/status                    []                 []              [get list watch]
  secrets                                  []                 []              [create delete deletecollection get list patch update watch]
  serviceaccounts                          []                 []              [create delete deletecollection get list patch update watch impersonate]
  services                                 []                 []              [create delete deletecollection get list patch update watch]
  services/proxy                           []                 []              [create delete deletecollection get list patch update watch]
  statefulsets.apps                        []                 []              [create delete deletecollection get list patch update watch]


Name:         system:aggregate-to-view
Labels:       kubernetes.io/bootstrapping=rbac-defaults
              rbac.authorization.k8s.io/aggregate-to-view=true
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                Non-Resource URLs  Resource Names  Verbs
  ---------                                -----------------  --------------  -----
  bindings                                 []                 []              [get list watch]
  configmaps                               []                 []              [get list watch]
  cronjobs.batch                           []                 []              [get list watch]
  daemonsets.apps                          []                 []              [get list watch]
  daemonsets.extensions                    []                 []              [get list watch]
  deployments.apps                         []                 []              [get list watch]
  deployments.extensions                   []                 []              [get list watch]
  deployments.apps/scale                   []                 []              [get list watch]
  deployments.extensions/scale             []                 []              [get list watch]
  endpoints                                []                 []              [get list watch]
  events                                   []                 []              [get list watch]
  horizontalpodautoscalers.autoscaling     []                 []              [get list watch]
  ingresses.extensions                     []                 []              [get list watch]
  jobs.batch                               []                 []              [get list watch]
  limitranges                              []                 []              [get list watch]
  namespaces                               []                 []              [get list watch]
  namespaces/status                        []                 []              [get list watch]
  persistentvolumeclaims                   []                 []              [get list watch]
  poddisruptionbudgets.policy              []                 []              [get list watch]
  pods                                     []                 []              [get list watch]
  pods/log                                 []                 []              [get list watch]
  pods/status                              []                 []              [get list watch]
  replicasets.apps                         []                 []              [get list watch]
  replicasets.extensions                   []                 []              [get list watch]
  replicasets.apps/scale                   []                 []              [get list watch]
  replicasets.extensions/scale             []                 []              [get list watch]
  replicationcontrollers                   []                 []              [get list watch]
  replicationcontrollers/scale             []                 []              [get list watch]
  replicationcontrollers.extensions/scale  []                 []              [get list watch]
  replicationcontrollers/status            []                 []              [get list watch]
  resourcequotas                           []                 []              [get list watch]
  resourcequotas/status                    []                 []              [get list watch]
  serviceaccounts                          []                 []              [get list watch]
  services                                 []                 []              [get list watch]
  statefulsets.apps                        []                 []              [get list watch]


Name:         system:auth-delegator
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                  Non-Resource URLs  Resource Names  Verbs
  ---------                                  -----------------  --------------  -----
  subjectaccessreviews.authorization.k8s.io  []                 []              [create]
  tokenreviews.authentication.k8s.io         []                 []              [create]


Name:         system:aws-cloud-provider
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
  events     []                 []              [create patch update]
  nodes      []                 []              [get patch]


Name:         system:basic-user
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                      Non-Resource URLs  Resource Names  Verbs
  ---------                                      -----------------  --------------  -----
  selfsubjectaccessreviews.authorization.k8s.io  []                 []              [create]
  selfsubjectrulesreviews.authorization.k8s.io   []                 []              [create]


Name:         system:certificates.k8s.io:certificatesigningrequests:nodeclient
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                                  Non-Resource URLs  Resource Names  Verbs
  ---------                                                  -----------------  --------------  -----
  certificatesigningrequests.certificates.k8s.io/nodeclient  []                 []              [create]


Name:         system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                                      Non-Resource URLs  Resource Names  Verbs
  ---------                                                      -----------------  --------------  -----
  certificatesigningrequests.certificates.k8s.io/selfnodeclient  []                 []              [create]


Name:         system:controller:attachdetach-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources               Non-Resource URLs  Resource Names  Verbs
  ---------               -----------------  --------------  -----
  events                  []                 []              [create patch update]
  nodes                   []                 []              [get list watch]
  nodes/status            []                 []              [patch update]
  persistentvolumeclaims  []                 []              [list watch]
  persistentvolumes       []                 []              [list watch]
  pods                    []                 []              [list watch]


Name:         system:controller:certificate-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                                Non-Resource URLs  Resource Names  Verbs
  ---------                                                -----------------  --------------  -----
  certificatesigningrequests.certificates.k8s.io           []                 []              [get list watch]
  certificatesigningrequests.certificates.k8s.io/approval  []                 []              [update]
  certificatesigningrequests.certificates.k8s.io/status    []                 []              [update]
  events                                                   []                 []              [create patch update]
  subjectaccessreviews.authorization.k8s.io                []                 []              [create]


Name:         system:controller:clusterrole-aggregation-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
             [*]                []              [*]
  *.*        []                 []              [*]


Name:         system:controller:cronjob-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                  Non-Resource URLs  Resource Names  Verbs
  ---------                  -----------------  --------------  -----
  cronjobs.batch             []                 []              [get list update watch]
  cronjobs.batch/finalizers  []                 []              [update]
  cronjobs.batch/status      []                 []              [update]
  events                     []                 []              [create patch update]
  jobs.batch                 []                 []              [create delete get list patch update watch]
  pods                       []                 []              [delete list]


Name:         system:controller:daemon-set-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                         Non-Resource URLs  Resource Names  Verbs
  ---------                         -----------------  --------------  -----
  controllerrevisions.apps          []                 []              [create delete list patch update watch]
  daemonsets.apps                   []                 []              [get list watch]
  daemonsets.extensions             []                 []              [get list watch]
  daemonsets.apps/finalizers        []                 []              [update]
  daemonsets.extensions/finalizers  []                 []              [update]
  daemonsets.apps/status            []                 []              [update]
  daemonsets.extensions/status      []                 []              [update]
  events                            []                 []              [create patch update]
  nodes                             []                 []              [list watch]
  pods                              []                 []              [create delete list patch watch]
  pods/binding                      []                 []              [create]


Name:         system:controller:deployment-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                          Non-Resource URLs  Resource Names  Verbs
  ---------                          -----------------  --------------  -----
  deployments.apps                   []                 []              [get list update watch]
  deployments.extensions             []                 []              [get list update watch]
  deployments.apps/finalizers        []                 []              [update]
  deployments.extensions/finalizers  []                 []              [update]
  deployments.apps/status            []                 []              [update]
  deployments.extensions/status      []                 []              [update]
  events                             []                 []              [create patch update]
  pods                               []                 []              [get list update watch]
  replicasets.apps                   []                 []              [create delete get list patch update watch]
  replicasets.extensions             []                 []              [create delete get list patch update watch]


Name:         system:controller:disruption-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                           Non-Resource URLs  Resource Names  Verbs
  ---------                           -----------------  --------------  -----
  deployments.apps                    []                 []              [get list watch]
  deployments.extensions              []                 []              [get list watch]
  events                              []                 []              [create patch update]
  poddisruptionbudgets.policy         []                 []              [get list watch]
  poddisruptionbudgets.policy/status  []                 []              [update]
  replicasets.apps                    []                 []              [get list watch]
  replicasets.extensions              []                 []              [get list watch]
  replicationcontrollers              []                 []              [get list watch]
  statefulsets.apps                   []                 []              [get list watch]


Name:         system:controller:endpoint-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources             Non-Resource URLs  Resource Names  Verbs
  ---------             -----------------  --------------  -----
  endpoints             []                 []              [create delete get list update]
  endpoints/restricted  []                 []              [create]
  events                []                 []              [create patch update]
  pods                  []                 []              [get list watch]
  services              []                 []              [get list watch]


Name:         system:controller:generic-garbage-collector
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
  *.*        []                 []              [delete get list patch update watch]
  events     []                 []              [create patch update]


Name:         system:controller:horizontal-pod-autoscaler
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                    Non-Resource URLs  Resource Names     Verbs
  ---------                                    -----------------  --------------     -----
  *.custom.metrics.k8s.io                      []                 []                 [get list]
  *.*/scale                                    []                 []                 [get update]
  events                                       []                 []                 [create patch update]
  horizontalpodautoscalers.autoscaling         []                 []                 [get list watch]
  horizontalpodautoscalers.autoscaling/status  []                 []                 [update]
  pods                                         []                 []                 [list]
  pods.metrics.k8s.io                          []                 []                 [list]
  services/proxy                               []                 [http:heapster:]   [get]
  services/proxy                               []                 [https:heapster:]  [get]


Name:         system:controller:job-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources              Non-Resource URLs  Resource Names  Verbs
  ---------              -----------------  --------------  -----
  events                 []                 []              [create patch update]
  jobs.batch             []                 []              [get list update watch]
  jobs.batch/finalizers  []                 []              [update]
  jobs.batch/status      []                 []              [update]
  pods                   []                 []              [create delete list patch watch]


Name:         system:controller:namespace-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources            Non-Resource URLs  Resource Names  Verbs
  ---------            -----------------  --------------  -----
  *.*                  []                 []              [delete deletecollection get list]
  namespaces           []                 []              [delete get list watch]
  namespaces/finalize  []                 []              [update]
  namespaces/status    []                 []              [update]


Name:         system:controller:node-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources     Non-Resource URLs  Resource Names  Verbs
  ---------     -----------------  --------------  -----
  events        []                 []              [create patch update]
  nodes         []                 []              [delete get list patch update]
  nodes/status  []                 []              [patch update]
  pods          []                 []              [delete list]
  pods/status   []                 []              [update]


Name:         system:controller:persistent-volume-binder
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                      Non-Resource URLs  Resource Names  Verbs
  ---------                      -----------------  --------------  -----
  endpoints                      []                 []              [create delete get]
  events                         []                 []              [watch create patch update]
  nodes                          []                 []              [get list]
  persistentvolumeclaims         []                 []              [get list update watch]
  persistentvolumeclaims/status  []                 []              [update]
  persistentvolumes              []                 []              [create delete get list update watch]
  persistentvolumes/status       []                 []              [update]
  pods                           []                 []              [create delete get list watch]
  secrets                        []                 []              [get]
  services                       []                 []              [create delete get]
  storageclasses.storage.k8s.io  []                 []              [get list watch]


Name:         system:controller:pod-garbage-collector
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
  nodes      []                 []              [list]
  pods       []                 []              [delete list watch]


Name:         system:controller:replicaset-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                          Non-Resource URLs  Resource Names  Verbs
  ---------                          -----------------  --------------  -----
  events                             []                 []              [create patch update]
  pods                               []                 []              [create delete list patch watch]
  replicasets.apps                   []                 []              [get list update watch]
  replicasets.extensions             []                 []              [get list update watch]
  replicasets.apps/finalizers        []                 []              [update]
  replicasets.extensions/finalizers  []                 []              [update]
  replicasets.apps/status            []                 []              [update]
  replicasets.extensions/status      []                 []              [update]


Name:         system:controller:replication-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                          Non-Resource URLs  Resource Names  Verbs
  ---------                          -----------------  --------------  -----
  events                             []                 []              [create patch update]
  pods                               []                 []              [create delete list patch watch]
  replicationcontrollers             []                 []              [get list update watch]
  replicationcontrollers/finalizers  []                 []              [update]
  replicationcontrollers/status      []                 []              [update]


Name:         system:controller:resourcequota-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources              Non-Resource URLs  Resource Names  Verbs
  ---------              -----------------  --------------  -----
  *.*                    []                 []              [list watch]
  events                 []                 []              [create patch update]
  resourcequotas/status  []                 []              [update]


Name:         system:controller:route-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources     Non-Resource URLs  Resource Names  Verbs
  ---------     -----------------  --------------  -----
  events        []                 []              [create patch update]
  nodes         []                 []              [list watch]
  nodes/status  []                 []              [patch]


Name:         system:controller:service-account-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources        Non-Resource URLs  Resource Names  Verbs
  ---------        -----------------  --------------  -----
  events           []                 []              [create patch update]
  serviceaccounts  []                 []              [create]


Name:         system:controller:service-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources        Non-Resource URLs  Resource Names  Verbs
  ---------        -----------------  --------------  -----
  events           []                 []              [create patch update]
  nodes            []                 []              [list watch]
  services         []                 []              [get list watch]
  services/status  []                 []              [update]


Name:         system:controller:statefulset-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                     Non-Resource URLs  Resource Names  Verbs
  ---------                     -----------------  --------------  -----
  controllerrevisions.apps      []                 []              [create delete get list patch update watch]
  events                        []                 []              [create patch update]
  persistentvolumeclaims        []                 []              [create get]
  pods                          []                 []              [list watch create delete get patch update]
  statefulsets.apps             []                 []              [get list watch]
  statefulsets.apps/finalizers  []                 []              [update]
  statefulsets.apps/status      []                 []              [update]


Name:         system:controller:ttl-controller
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
  events     []                 []              [create patch update]
  nodes      []                 []              [list patch update watch]


Name:         system:discovery
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs       Resource Names  Verbs
  ---------  -----------------       --------------  -----
             [/api]                  []              [get]
             [/api/*]                []              [get]
             [/apis]                 []              [get]
             [/apis/*]               []              [get]
             [/healthz]              []              [get]
             [/swagger-2.0.0.pb-v1]  []              [get]
             [/swagger.json]         []              [get]
             [/swaggerapi]           []              [get]
             [/swaggerapi/*]         []              [get]
             [/version]              []              [get]


Name:         system:heapster
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources               Non-Resource URLs  Resource Names  Verbs
  ---------               -----------------  --------------  -----
  deployments.extensions  []                 []              [get list watch]
  events                  []                 []              [get list watch]
  namespaces              []                 []              [get list watch]
  nodes                   []                 []              [get list watch]
  pods                    []                 []              [get list watch]


Name:         system:kube-aggregator
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
  endpoints  []                 []              [get list watch]
  services   []                 []              [get list watch]


Name:         system:kube-controller-manager
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                           Non-Resource URLs  Resource Names  Verbs
  ---------                           -----------------  --------------  -----
  *.*                                 []                 []              [list watch]
  endpoints                           []                 []              [create get update]
  events                              []                 []              [create patch update]
  namespaces                          []                 []              [get]
  secrets                             []                 []              [create delete get update]
  serviceaccounts                     []                 []              [create get update]
  tokenreviews.authentication.k8s.io  []                 []              [create]


Name:         system:kube-dns
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
  endpoints  []                 []              [list watch]
  services   []                 []              [list watch]


Name:         system:kube-scheduler
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                    Non-Resource URLs  Resource Names    Verbs
  ---------                    -----------------  --------------    -----
  bindings                     []                 []                [create]
  endpoints                    []                 []                [create]
  endpoints                    []                 [kube-scheduler]  [delete get patch update]
  events                       []                 []                [create patch update]
  nodes                        []                 []                [get list watch]
  persistentvolumeclaims       []                 []                [get list watch]
  persistentvolumes            []                 []                [get list watch]
  poddisruptionbudgets.policy  []                 []                [get list watch]
  pods                         []                 []                [delete get list watch]
  pods/binding                 []                 []                [create]
  pods/status                  []                 []                [patch update]
  replicasets.apps             []                 []                [get list watch]
  replicasets.extensions       []                 []                [get list watch]
  replicationcontrollers       []                 []                [get list watch]
  services                     []                 []                [get list watch]
  statefulsets.apps            []                 []                [get list watch]


Name:         system:node
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                       Non-Resource URLs  Resource Names  Verbs
  ---------                                       -----------------  --------------  -----
  certificatesigningrequests.certificates.k8s.io  []                 []              [create get list watch]
  configmaps                                      []                 []              [get]
  endpoints                                       []                 []              [get]
  events                                          []                 []              [create patch update]
  localsubjectaccessreviews.authorization.k8s.io  []                 []              [create]
  nodes                                           []                 []              [create get list watch delete patch update]
  nodes/status                                    []                 []              [patch update]
  persistentvolumeclaims                          []                 []              [get]
  persistentvolumes                               []                 []              [get]
  pods                                            []                 []              [get list watch create delete]
  pods/eviction                                   []                 []              [create]
  pods/status                                     []                 []              [update]
  secrets                                         []                 []              [get]
  services                                        []                 []              [get list watch]
  subjectaccessreviews.authorization.k8s.io       []                 []              [create]
  tokenreviews.authentication.k8s.io              []                 []              [create]


Name:         system:node-bootstrapper
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                       Non-Resource URLs  Resource Names  Verbs
  ---------                                       -----------------  --------------  -----
  certificatesigningrequests.certificates.k8s.io  []                 []              [create get list watch]


Name:         system:node-problem-detector
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources     Non-Resource URLs  Resource Names  Verbs
  ---------     -----------------  --------------  -----
  events        []                 []              [create patch update]
  nodes         []                 []              [get]
  nodes/status  []                 []              [patch]


Name:         system:node-proxier
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
  endpoints  []                 []              [list watch]
  events     []                 []              [create patch update]
  nodes      []                 []              [get]
  services   []                 []              [list watch]


Name:         system:persistent-volume-provisioner
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                      Non-Resource URLs  Resource Names  Verbs
  ---------                      -----------------  --------------  -----
  events                         []                 []              [watch create patch update]
  persistentvolumeclaims         []                 []              [get list update watch]
  persistentvolumes              []                 []              [create delete get list watch]
  storageclasses.storage.k8s.io  []                 []              [get list watch]


Name:         view
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources                                Non-Resource URLs  Resource Names  Verbs
  ---------                                -----------------  --------------  -----
  bindings                                 []                 []              [get list watch]
  configmaps                               []                 []              [get list watch]
  cronjobs.batch                           []                 []              [get list watch]
  daemonsets.apps                          []                 []              [get list watch]
  daemonsets.extensions                    []                 []              [get list watch]
  deployments.apps                         []                 []              [get list watch]
  deployments.extensions                   []                 []              [get list watch]
  deployments.apps/scale                   []                 []              [get list watch]
  deployments.extensions/scale             []                 []              [get list watch]
  endpoints                                []                 []              [get list watch]
  events                                   []                 []              [get list watch]
  horizontalpodautoscalers.autoscaling     []                 []              [get list watch]
  ingresses.extensions                     []                 []              [get list watch]
  jobs.batch                               []                 []              [get list watch]
  limitranges                              []                 []              [get list watch]
  namespaces                               []                 []              [get list watch]
  namespaces/status                        []                 []              [get list watch]
  persistentvolumeclaims                   []                 []              [get list watch]
  poddisruptionbudgets.policy              []                 []              [get list watch]
  pods                                     []                 []              [get list watch]
  pods/log                                 []                 []              [get list watch]
  pods/status                              []                 []              [get list watch]
  replicasets.apps                         []                 []              [get list watch]
  replicasets.extensions                   []                 []              [get list watch]
  replicasets.apps/scale                   []                 []              [get list watch]
  replicasets.extensions/scale             []                 []              [get list watch]
  replicationcontrollers                   []                 []              [get list watch]
  replicationcontrollers/scale             []                 []              [get list watch]
  replicationcontrollers.extensions/scale  []                 []              [get list watch]
  replicationcontrollers/status            []                 []              [get list watch]
  resourcequotas                           []                 []              [get list watch]
  resourcequotas/status                    []                 []              [get list watch]
  serviceaccounts                          []                 []              [get list watch]
  services                                 []                 []              [get list watch]
  statefulsets.apps                        []                 []              [get list watch]
\n================
kubectl describe componentstatuses --all-namespaces
================\n
Name:         controller-manager
Namespace:    
Labels:       <none>
Annotations:  <none>
API Version:  v1
Conditions:
  Message:  ok
  Status:   True
  Type:     Healthy
Kind:       ComponentStatus
Metadata:
  Creation Timestamp:  <nil>
  Self Link:           /api/v1/componentstatuses/controller-manager
Events:                <none>


Name:         scheduler
Namespace:    
Labels:       <none>
Annotations:  <none>
API Version:  v1
Conditions:
  Message:  ok
  Status:   True
  Type:     Healthy
Kind:       ComponentStatus
Metadata:
  Creation Timestamp:  <nil>
  Self Link:           /api/v1/componentstatuses/scheduler
Events:                <none>


Name:         etcd-0
Namespace:    
Labels:       <none>
Annotations:  <none>
API Version:  v1
Conditions:
  Message:  {"health": "true"}
  Status:   True
  Type:     Healthy
Kind:       ComponentStatus
Metadata:
  Creation Timestamp:  <nil>
  Self Link:           /api/v1/componentstatuses/etcd-0
Events:                <none>
\n================
kubectl describe configmaps --all-namespaces
================\n
Name:         cluster-info
Namespace:    kube-public
Labels:       <none>
Annotations:  <none>

Data
====
kubeconfig:
----
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    server: https://192.168.2.10:6443
  name: ""
contexts: []
current-context: ""
kind: Config
preferences: {}
users: []

Events:  <none>


Name:         contiv-config
Namespace:    kube-system
Labels:       <none>
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"v1","data":{"contiv_cni_config":"{\n  \"cniVersion\": \"0.3.1\",\n  \"name\": \"contiv-net\",\n  \"type\": \"contivk8s\"\n}","contiv_etc...

Data
====
contiv_cni_config:
----
{
  "cniVersion": "0.3.1",
  "name": "contiv-net",
  "type": "contivk8s"
}
contiv_etcd:
----
http://192.168.2.10:6666
contiv_fwdmode:
----
routing
contiv_k8s_config:
----
{
   "K8S_API_SERVER": "https://192.168.2.10:6443",
   "K8S_CA": "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt",
   "K8S_KEY": "",
   "K8S_CERT": "",
   "K8S_TOKEN": "",
   "SVC_SUBNET": "10.96.0.0/12"
}
contiv_mode:
----
kubernetes
contiv_netmode:
----
vxlan
Events:  <none>


Name:         extension-apiserver-authentication
Namespace:    kube-system
Labels:       <none>
Annotations:  <none>

Data
====
client-ca-file:
----
-----BEGIN CERTIFICATE-----
MIICyDCCAbCgAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl
cm5ldGVzMB4XDTE4MDIwMzIyMzEzOFoXDTI4MDIwMTIyMzEzOFowFTETMBEGA1UE
AxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAKQW
CCyzeAi6/vmatCdyIA778+K68ArOVzmMfjVqW6FlQZR9tq4C+KngMdK1raNVSl9g
uJZXLvpO45ZgPYgrDpSbDOCLKOrIHsvjLMZWNUO9GXfObmlIDZcojrqMT8wFWa3u
FeJ7ESpuf8EuopM3FdLytkQVz8DoW9rOSzVtmUMg6vuiTDYLFw/JYhCLvmVbIRxQ
seAYaub+TPTFt6GYK/tvMnY2k9E+CaNxeDtZWmXzyAjkHVGL5aYh/K+h7c9mPczd
+LjvDLI03RxphwJ97ldFPSruYUsXgGcz23z8pm+ifws0UVDgIm++0MASWiSuGaXc
AUmEBsI3ICJBjCksRkECAwEAAaMjMCEwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB
/wQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAGtxnHBxP6hEkFxW2895oTBqmY4j
WUEb8GkxzORiuSExjkDxe5C94XZaF+CjL3gd7OBWrAVZS5rjbWJBPTOuFLwD9pLO
yRUJCJ5czR50p/FsnPdyt5yzpdRrFYnrjYvotewzbIXsNpz3wKgG4YEdCPjV3QgX
E2TJxPF+GYZXr8KWd7jK92rn4lqRjrVJHN/jL+xYwi1tdhCI9A0KjJYvsdMvnuVl
3QJnLIlc4EQGJjicDmjSIwGXD4CmjNPWwJr5dfjULq4IIGMNH5EghcZlhc3Gr/G4
5ErcjSiBiDEdULDQ4WXvIA4pUhf8wm2pCADO8L/fYsL9jxnTuCX0OObxs14=
-----END CERTIFICATE-----

requestheader-allowed-names:
----
["front-proxy-client"]
requestheader-client-ca-file:
----
-----BEGIN CERTIFICATE-----
MIICyDCCAbCgAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl
cm5ldGVzMB4XDTE4MDIwMzIyMzEzOVoXDTI4MDIwMTIyMzEzOVowFTETMBEGA1UE
AxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBANnN
gpVUT0uGvxe+klT0zIkomVsqDh8oltNNiJJJG9yJ3qay+VEXko8BEOaLiKKC6h3/
jpQGSnM1/EQZYmkXckhxcviZ+/9rdr7a5AMVW2xvnpdX2ATbvKjjOU1rfr66r+cw
CHdcPvsJcD1+tXLl5KRWgLB/+LsoiulNT3r1hDDBi39rl6Aw+YN3nXFLd41ZLLcc
fIWFCwVEzpHKwGU0gfVqQlBZmbzxcOW7UgPFZp7gP3hWbEDS28gBh3dd9O52ryL6
nzLDJa0bOZBdrguIWa4t/EhNwQIuE85LO/6VJkDhLMjnwNxCvZEbnDeoTDT/vFUJ
ShtyXcNzQpHKRRQWeZMCAwEAAaMjMCEwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB
/wQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAJYlXje8uvd1FVkDrHOYUCPHhIOp
Jzwbp2DlqoXdXp8wV7FaT6f/Cu0ZWaYCnqMPFeF3BKT47ENTq1b2PkemJf9/AiE3
1j9tVFsiIQrn0Eij9rGekqj/ok2/HEnKHPvX5ANenvX3M/XxIsWryTMfN7cA62lW
ZtbFWVZFxN+atPMIU8hDlMopGRqo5vvobAHSHqdNukyHNuGolIqcv4Hso5zeWNsB
ggz+/xnbNdVfyZ1XJwh6Meo97PoER0EkUDH+bWy1bd4nczOU+eTsuZOCGASUsPCo
KeBqblUAgiTiCEuMhMyDvQcnB+Wl7qbyBkLthfoHJrS/I5FE9e6m9TnXH4g=
-----END CERTIFICATE-----

requestheader-extra-headers-prefix:
----
["X-Remote-Extra-"]
requestheader-group-headers:
----
["X-Remote-Group"]
requestheader-username-headers:
----
["X-Remote-User"]
Events:  <none>


Name:         kube-proxy
Namespace:    kube-system
Labels:       app=kube-proxy
Annotations:  <none>

Data
====
config.conf:
----
apiVersion: kubeproxy.config.k8s.io/v1alpha1
bindAddress: 0.0.0.0
clientConnection:
  acceptContentTypes: ""
  burst: 10
  contentType: application/vnd.kubernetes.protobuf
  kubeconfig: /var/lib/kube-proxy/kubeconfig.conf
  qps: 5
clusterCIDR: ""
configSyncPeriod: 15m0s
conntrack:
  max: null
  maxPerCore: 32768
  min: 131072
  tcpCloseWaitTimeout: 1h0m0s
  tcpEstablishedTimeout: 24h0m0s
enableProfiling: false
featureGates: ""
healthzBindAddress: 0.0.0.0:10256
hostnameOverride: ""
iptables:
  masqueradeAll: false
  masqueradeBit: 14
  minSyncPeriod: 0s
  syncPeriod: 30s
ipvs:
  minSyncPeriod: 0s
  scheduler: ""
  syncPeriod: 30s
kind: KubeProxyConfiguration
metricsBindAddress: 127.0.0.1:10249
mode: ""
oomScoreAdj: -999
portRange: ""
resourceContainer: /kube-proxy
udpTimeoutMilliseconds: 250ms
kubeconfig.conf:
----
apiVersion: v1
kind: Config
clusters:
- cluster:
    certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    server: https://192.168.2.10:6443
  name: default
contexts:
- context:
    cluster: default
    namespace: default
    user: default
  name: default
current-context: default
users:
- name: default
  user:
    tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
Events:  <none>


Name:         kubeadm-config
Namespace:    kube-system
Labels:       <none>
Annotations:  <none>

Data
====
MasterConfiguration:
----
api:
  advertiseAddress: 192.168.2.10
  bindPort: 6443
authorizationModes:
- Node
- RBAC
certificatesDir: /etc/kubernetes/pki
cloudProvider: ""
etcd:
  caFile: ""
  certFile: ""
  dataDir: /var/lib/etcd
  endpoints: null
  image: ""
  keyFile: ""
imageRepository: gcr.io/google_containers
kubeProxy:
  config:
    bindAddress: 0.0.0.0
    clientConnection:
      acceptContentTypes: ""
      burst: 10
      contentType: application/vnd.kubernetes.protobuf
      kubeconfig: /var/lib/kube-proxy/kubeconfig.conf
      qps: 5
    clusterCIDR: ""
    configSyncPeriod: 15m0s
    conntrack:
      max: null
      maxPerCore: 32768
      min: 131072
      tcpCloseWaitTimeout: 1h0m0s
      tcpEstablishedTimeout: 24h0m0s
    enableProfiling: false
    featureGates: ""
    healthzBindAddress: 0.0.0.0:10256
    hostnameOverride: ""
    iptables:
      masqueradeAll: false
      masqueradeBit: 14
      minSyncPeriod: 0s
      syncPeriod: 30s
    ipvs:
      minSyncPeriod: 0s
      scheduler: ""
      syncPeriod: 30s
    metricsBindAddress: 127.0.0.1:10249
    mode: ""
    oomScoreAdj: -999
    portRange: ""
    resourceContainer: /kube-proxy
    udpTimeoutMilliseconds: 250ms
kubeletConfiguration: {}
kubernetesVersion: v1.9.2
networking:
  dnsDomain: cluster.local
  podSubnet: ""
  serviceSubnet: 10.96.0.0/12
nodeName: k8master
token: ""
tokenTTL: 24h0m0s
unifiedControlPlaneImage: ""

Events:  <none>
\n================
kubectl describe controllerrevisions --all-namespaces
================\n
Name:         contiv-etcd-7884c4b699
Namespace:    kube-system
Labels:       controller-revision-hash=3440706255
              k8s-app=contiv-etcd
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":...
API Version:  apps/v1
Data:
  Spec:
    Template:
      $ Patch:  replace
      Metadata:
        Annotations:
          Scheduler . Alpha . Kubernetes . Io / Critical - Pod:  
        Creation Timestamp:                                      <nil>
        Labels:
          K 8 S - App:  contiv-etcd
      Spec:
        Containers:
          Args:
            ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
          Command:
            /bin/sh
            -c
          Env:
            Name:  CONTIV_ETCD_IP
            Value From:
              Field Ref:
                API Version:  v1
                Field Path:   status.podIP
            Name:             ETCD_NAME
            Value:            contiv-etcd
            Name:             ETCD_DATA_DIR
            Value:            /var/lib/etcd/contiv-data
            Name:             ETCD_LISTEN_CLIENT_URLS
            Value:            http://0.0.0.0:6666
            Name:             ETCD_LISTEN_PEER_URLS
            Value:            http://0.0.0.0:6667
          Image:              quay.io/coreos/etcd:v3.2.4
          Image Pull Policy:  IfNotPresent
          Name:               contiv-etcd
          Resources:
          Termination Message Path:    /dev/termination-log
          Termination Message Policy:  File
          Volume Mounts:
            Mount Path:  /var/etcd
            Name:        var-etcd
        Dns Policy:      ClusterFirst
        Host Network:    true
        Node Selector:
          Node - Role . Kubernetes . Io / Master:  
        Restart Policy:                            Always
        Scheduler Name:                            default-scheduler
        Security Context:
        Termination Grace Period Seconds:  30
        Tolerations:
          Effect:    NoSchedule
          Key:       node.cloudprovider.kubernetes.io/uninitialized
          Value:     true
          Effect:    NoSchedule
          Key:       node-role.kubernetes.io/master
          Key:       CriticalAddonsOnly
          Operator:  Exists
        Volumes:
          Host Path:
            Path:  /var/etcd
            Type:  
          Name:    var-etcd
Kind:              ControllerRevision
Metadata:
  Creation Timestamp:  2018-02-03T22:37:53Z
  Owner References:
    API Version:           extensions/v1beta1
    Block Owner Deletion:  true
    Controller:            true
    Kind:                  DaemonSet
    Name:                  contiv-etcd
    UID:                   df32d0df-0932-11e8-9940-0800277561f7
  Resource Version:        360
  Self Link:               /apis/apps/v1/namespaces/kube-system/controllerrevisions/contiv-etcd-7884c4b699
  UID:                     df37e2f3-0932-11e8-9940-0800277561f7
Revision:                  1
Events:                    <none>


Name:         contiv-netplugin-846fb768d9
Namespace:    kube-system
Labels:       controller-revision-hash=4029632485
              k8s-app=contiv-netplugin
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netplugin"},"name":"contiv-netplugin","n...
API Version:  apps/v1
Data:
  Spec:
    Template:
      $ Patch:  replace
      Metadata:
        Annotations:
          Scheduler . Alpha . Kubernetes . Io / Critical - Pod:  
        Creation Timestamp:                                      <nil>
        Labels:
          K 8 S - App:  contiv-netplugin
      Spec:
        Containers:
          Command:
            tail
            -f
            /dev/null
          Env:
            Name:   CONTIV_ROLE
            Value:  netplugin
            Name:   CONTIV_NETPLUGIN_MODE
            Value From:
              Config Map Key Ref:
                Key:   contiv_mode
                Name:  contiv-config
            Name:      CONTIV_NETPLUGIN_VTEP_IP
            Value From:
              Field Ref:
                API Version:  v1
                Field Path:   status.podIP
            Name:             CONTIV_NETPLUGIN_FORWARD_MODE
            Value From:
              Config Map Key Ref:
                Key:   contiv_fwdmode
                Name:  contiv-config
            Name:      CONTIV_NETPLUGIN_NET_MODE
            Value From:
              Config Map Key Ref:
                Key:          contiv_netmode
                Name:         contiv-config
          Image:              contiv/netplugin:latest
          Image Pull Policy:  Always
          Name:               contiv-netplugin
          Resources:
            Requests:
              Cpu:  250m
          Security Context:
            Privileged:                true
          Termination Message Path:    /dev/termination-log
          Termination Message Policy:  File
          Volume Mounts:
            Mount Path:  /var/run
            Name:        var-run
            Mount Path:  /var/contiv
            Name:        var-contiv
            Mount Path:  /contiv/bin
            Name:        contiv-bin-dir
            Read Only:   true
            Mount Path:  /contiv/scripts/
            Name:        contiv-scripts-dir
            Read Only:   true
            Mount Path:  /var/log/contiv
            Name:        contiv-log-dir
        Dns Policy:      ClusterFirst
        Host Network:    true
        Host PID:        true
        Init Containers:
          Env:
            Name:   CONTIV_ROLE
            Value:  netplugin
            Name:   CONTIV_MODE
            Value From:
              Config Map Key Ref:
                Key:   contiv_mode
                Name:  contiv-config
            Name:      CONTIV_K8S_CONFIG
            Value From:
              Config Map Key Ref:
                Key:   contiv_k8s_config
                Name:  contiv-config
            Name:      CONTIV_CNI_CONFIG
            Value From:
              Config Map Key Ref:
                Key:          contiv_cni_config
                Name:         contiv-config
          Image:              contiv/netplugin-init:latest
          Image Pull Policy:  Always
          Name:               contiv-netplugin-init
          Resources:
          Termination Message Path:    /dev/termination-log
          Termination Message Policy:  File
          Volume Mounts:
            Mount Path:  /var/contiv
            Name:        var-contiv
            Mount Path:  /etc/cni/net.d/
            Name:        etc-cni-dir
          Command:
            cp
            /contiv/bin/contivk8s
            /opt/cni/bin/contivk8s
          Image:              contiv/netplugin:latest
          Image Pull Policy:  Always
          Name:               contiv-cni
          Resources:
          Termination Message Path:    /dev/termination-log
          Termination Message Policy:  File
          Volume Mounts:
            Mount Path:  /opt/cni/bin
            Name:        cni-bin-dir
        Restart Policy:  Always
        Scheduler Name:  default-scheduler
        Security Context:
        Service Account:                   contiv-netplugin
        Service Account Name:              contiv-netplugin
        Termination Grace Period Seconds:  30
        Tolerations:
          Effect:  NoSchedule
          Key:     node-role.kubernetes.io/master
        Volumes:
          Host Path:
            Path:  /var/run
            Type:  
          Name:    var-run
          Host Path:
            Path:  /var/contiv
            Type:  
          Name:    var-contiv
          Host Path:
            Path:  /opt/cni/bin
            Type:  
          Name:    cni-bin-dir
          Host Path:
            Path:  /etc/cni/net.d/
            Type:  
          Name:    etc-cni-dir
          Host Path:
            Path:  /opt/gopath/bin
            Type:  
          Name:    contiv-bin-dir
          Host Path:
            Path:  /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
            Type:  
          Name:    contiv-scripts-dir
          Host Path:
            Path:  /var/log/contiv
            Type:  
          Name:    contiv-log-dir
Kind:              ControllerRevision
Metadata:
  Creation Timestamp:  2018-02-03T22:37:53Z
  Owner References:
    API Version:           extensions/v1beta1
    Block Owner Deletion:  true
    Controller:            true
    Kind:                  DaemonSet
    Name:                  contiv-netplugin
    UID:                   defd0ade-0932-11e8-9940-0800277561f7
  Resource Version:        351
  Self Link:               /apis/apps/v1/namespaces/kube-system/controllerrevisions/contiv-netplugin-846fb768d9
  UID:                     df12ad29-0932-11e8-9940-0800277561f7
Revision:                  1
Events:                    <none>


Name:         contiv-ovs-5d689bdd8f
Namespace:    kube-system
Labels:       controller-revision-hash=1824568849
              k8s-app=contiv-ovs
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-ovs"},"name":"contiv-ovs","namespace":"k...
API Version:  apps/v1
Data:
  Spec:
    Template:
      $ Patch:  replace
      Metadata:
        Annotations:
          Scheduler . Alpha . Kubernetes . Io / Critical - Pod:  
        Creation Timestamp:                                      <nil>
        Labels:
          K 8 S - App:  contiv-ovs
      Spec:
        Containers:
          Command:
            /scripts/start-ovsdb-server.sh
          Image:              contiv/ovs:latest
          Image Pull Policy:  Always
          Name:               contiv-ovsdb-server
          Resources:
          Security Context:
            Privileged:                false
          Termination Message Path:    /dev/termination-log
          Termination Message Policy:  File
          Volume Mounts:
            Mount Path:  /etc/openvswitch
            Name:        etc-openvswitch
            Mount Path:  /var/run
            Name:        var-run
          Command:
            /scripts/start-ovs-vswitchd.sh
          Image:              contiv/ovs:latest
          Image Pull Policy:  Always
          Name:               contiv-ovs-vswitchd
          Resources:
          Security Context:
            Privileged:                true
          Termination Message Path:    /dev/termination-log
          Termination Message Policy:  File
          Volume Mounts:
            Mount Path:  /etc/openvswitch
            Name:        etc-openvswitch
            Mount Path:  /lib/modules
            Name:        lib-modules
            Read Only:   true
            Mount Path:  /var/run
            Name:        var-run
        Dns Policy:      ClusterFirst
        Host Network:    true
        Host PID:        true
        Restart Policy:  Always
        Scheduler Name:  default-scheduler
        Security Context:
        Termination Grace Period Seconds:  30
        Tolerations:
          Effect:  NoSchedule
          Key:     node-role.kubernetes.io/master
        Volumes:
          Host Path:
            Path:  /etc/openvswitch
            Type:  
          Name:    etc-openvswitch
          Host Path:
            Path:  /lib/modules
            Type:  
          Name:    lib-modules
          Host Path:
            Path:  /var/run
            Type:  
          Name:    var-run
Kind:              ControllerRevision
Metadata:
  Creation Timestamp:  2018-02-03T22:37:53Z
  Owner References:
    API Version:           extensions/v1beta1
    Block Owner Deletion:  true
    Controller:            true
    Kind:                  DaemonSet
    Name:                  contiv-ovs
    UID:                   df7106fa-0932-11e8-9940-0800277561f7
  Resource Version:        381
  Self Link:               /apis/apps/v1/namespaces/kube-system/controllerrevisions/contiv-ovs-5d689bdd8f
  UID:                     df7a005d-0932-11e8-9940-0800277561f7
Revision:                  1
Events:                    <none>


Name:         kube-proxy-9ddb654bd
Namespace:    kube-system
Labels:       controller-revision-hash=588621068
              k8s-app=kube-proxy
Annotations:  <none>
API Version:  apps/v1
Data:
  Spec:
    Template:
      $ Patch:  replace
      Metadata:
        Creation Timestamp:  <nil>
        Labels:
          K 8 S - App:  kube-proxy
      Spec:
        Containers:
          Command:
            /usr/local/bin/kube-proxy
            --config=/var/lib/kube-proxy/config.conf
          Image:              gcr.io/google_containers/kube-proxy-amd64:v1.9.2
          Image Pull Policy:  IfNotPresent
          Name:               kube-proxy
          Resources:
          Security Context:
            Privileged:                true
          Termination Message Path:    /dev/termination-log
          Termination Message Policy:  File
          Volume Mounts:
            Mount Path:  /var/lib/kube-proxy
            Name:        kube-proxy
            Mount Path:  /run/xtables.lock
            Name:        xtables-lock
            Mount Path:  /lib/modules
            Name:        lib-modules
            Read Only:   true
        Dns Policy:      ClusterFirst
        Host Network:    true
        Restart Policy:  Always
        Scheduler Name:  default-scheduler
        Security Context:
        Service Account:                   kube-proxy
        Service Account Name:              kube-proxy
        Termination Grace Period Seconds:  30
        Tolerations:
          Effect:  NoSchedule
          Key:     node-role.kubernetes.io/master
          Effect:  NoSchedule
          Key:     node.cloudprovider.kubernetes.io/uninitialized
          Value:   true
        Volumes:
          Config Map:
            Default Mode:  420
            Name:          kube-proxy
          Name:            kube-proxy
          Host Path:
            Path:  /run/xtables.lock
            Type:  FileOrCreate
          Name:    xtables-lock
          Host Path:
            Path:  /lib/modules
            Type:  
          Name:    lib-modules
Kind:              ControllerRevision
Metadata:
  Creation Timestamp:  2018-02-03T22:37:43Z
  Owner References:
    API Version:           extensions/v1beta1
    Block Owner Deletion:  true
    Controller:            true
    Kind:                  DaemonSet
    Name:                  kube-proxy
    UID:                   d61ef82d-0932-11e8-9940-0800277561f7
  Resource Version:        300
  Self Link:               /apis/apps/v1/namespaces/kube-system/controllerrevisions/kube-proxy-9ddb654bd
  UID:                     d93bd875-0932-11e8-9940-0800277561f7
Revision:                  1
Events:                    <none>
\n================
kubectl describe cronjobs --all-namespaces
================\n
\n================
kubectl describe customresourcedefinition --all-namespaces
================\n
\n================
kubectl describe daemonsets --all-namespaces
================\n
Name:           contiv-etcd
Selector:       k8s-app=contiv-etcd
Node-Selector:  node-role.kubernetes.io/master=
Labels:         k8s-app=contiv-etcd
Annotations:    kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":...
Desired Number of Nodes Scheduled: 1
Current Number of Nodes Scheduled: 1
Number of Nodes Scheduled with Up-to-date Pods: 1
Number of Nodes Scheduled with Available Pods: 1
Number of Nodes Misscheduled: 0
Pods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:       k8s-app=contiv-etcd
  Annotations:  scheduler.alpha.kubernetes.io/critical-pod=
  Containers:
   contiv-etcd:
    Image:  quay.io/coreos/etcd:v3.2.4
    Port:   <none>
    Command:
      /bin/sh
      -c
    Args:
      ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
    Environment:
      CONTIV_ETCD_IP:            (v1:status.podIP)
      ETCD_NAME:                contiv-etcd
      ETCD_DATA_DIR:            /var/lib/etcd/contiv-data
      ETCD_LISTEN_CLIENT_URLS:  http://0.0.0.0:6666
      ETCD_LISTEN_PEER_URLS:    http://0.0.0.0:6667
    Mounts:
      /var/etcd from var-etcd (rw)
  Volumes:
   var-etcd:
    Type:          HostPath (bare host directory volume)
    Path:          /var/etcd
    HostPathType:  
Events:            <none>


Name:           contiv-netplugin
Selector:       k8s-app=contiv-netplugin
Node-Selector:  <none>
Labels:         k8s-app=contiv-netplugin
Annotations:    kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netplugin"},"name":"contiv-netplugin","n...
Desired Number of Nodes Scheduled: 4
Current Number of Nodes Scheduled: 4
Number of Nodes Scheduled with Up-to-date Pods: 4
Number of Nodes Scheduled with Available Pods: 4
Number of Nodes Misscheduled: 0
Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           k8s-app=contiv-netplugin
  Annotations:      scheduler.alpha.kubernetes.io/critical-pod=
  Service Account:  contiv-netplugin
  Init Containers:
   contiv-netplugin-init:
    Image:  contiv/netplugin-init:latest
    Port:   <none>
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
   contiv-cni:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    Environment:  <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
  Containers:
   contiv-netplugin:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      tail
      -f
      /dev/null
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
  Volumes:
   var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
   var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
   cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
   etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
   contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
   contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
   contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
Events:            <none>


Name:           contiv-ovs
Selector:       k8s-app=contiv-ovs
Node-Selector:  <none>
Labels:         k8s-app=contiv-ovs
Annotations:    kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-ovs"},"name":"contiv-ovs","namespace":"k...
Desired Number of Nodes Scheduled: 4
Current Number of Nodes Scheduled: 4
Number of Nodes Scheduled with Up-to-date Pods: 4
Number of Nodes Scheduled with Available Pods: 4
Number of Nodes Misscheduled: 0
Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:       k8s-app=contiv-ovs
  Annotations:  scheduler.alpha.kubernetes.io/critical-pod=
  Containers:
   contiv-ovsdb-server:
    Image:  contiv/ovs:latest
    Port:   <none>
    Command:
      /scripts/start-ovsdb-server.sh
    Environment:  <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
   contiv-ovs-vswitchd:
    Image:  contiv/ovs:latest
    Port:   <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    Environment:  <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
  Volumes:
   etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
   lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
   var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
Events:            <none>


Name:           kube-proxy
Selector:       k8s-app=kube-proxy
Node-Selector:  <none>
Labels:         k8s-app=kube-proxy
Annotations:    <none>
Desired Number of Nodes Scheduled: 4
Current Number of Nodes Scheduled: 4
Number of Nodes Scheduled with Up-to-date Pods: 4
Number of Nodes Scheduled with Available Pods: 4
Number of Nodes Misscheduled: 0
Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           k8s-app=kube-proxy
  Service Account:  kube-proxy
  Containers:
   kube-proxy:
    Image:  gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Port:   <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    Environment:  <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
  Volumes:
   kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
   xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
   lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
Events:            <none>
\n================
kubectl describe deployments --all-namespaces
================\n
\n================
kubectl describe endpoints --all-namespaces
================\n
Name:         kubernetes
Namespace:    default
Labels:       <none>
Annotations:  <none>
Subsets:
  Addresses:          192.168.2.10
  NotReadyAddresses:  <none>
  Ports:
    Name   Port  Protocol
    ----   ----  --------
    https  6443  TCP

Events:  <none>


Name:         contiv-etcd
Namespace:    kube-system
Labels:       k8s-app=contiv-etcd
Annotations:  <none>
Subsets:
  Addresses:          192.168.2.10
  NotReadyAddresses:  <none>
  Ports:
    Name     Port  Protocol
    ----     ----  --------
    <unset>  6666  TCP

Events:  <none>


Name:         kube-controller-manager
Namespace:    kube-system
Labels:       <none>
Annotations:  control-plane.alpha.kubernetes.io/leader={"holderIdentity":"k8master","leaseDurationSeconds":15,"acquireTime":"2018-02-03T22:37:34Z","renewTime":"2018-02-20T17:17:46Z","leaderTransitions":0}
Subsets:
Events:  <none>


Name:         kube-scheduler
Namespace:    kube-system
Labels:       <none>
Annotations:  control-plane.alpha.kubernetes.io/leader={"holderIdentity":"k8master","leaseDurationSeconds":15,"acquireTime":"2018-02-03T22:37:35Z","renewTime":"2018-02-20T17:17:46Z","leaderTransitions":0}
Subsets:
Events:  <none>
\n================
kubectl describe events --all-namespaces
================\n
\n================
kubectl describe horizontalpodautoscalers --all-namespaces
================\n
\n================
kubectl describe ingresses --all-namespaces
================\n
\n================
kubectl describe jobs --all-namespaces
================\n
\n================
kubectl describe limitranges --all-namespaces
================\n
\n================
kubectl describe namespaces --all-namespaces
================\n
Name:         default
Labels:       <none>
Annotations:  <none>
Status:       Active

No resource quota.

No resource limits.


Name:         kube-public
Labels:       <none>
Annotations:  <none>
Status:       Active

No resource quota.

No resource limits.


Name:         kube-system
Labels:       <none>
Annotations:  <none>
Status:       Active

No resource quota.

No resource limits.
\n================
kubectl describe networkpolicies --all-namespaces
================\n
\n================
kubectl describe nodes --all-namespaces
================\n
Name:               k8master
Roles:              master
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/hostname=k8master
                    node-role.kubernetes.io/master=
Annotations:        node.alpha.kubernetes.io/ttl=0
                    volumes.kubernetes.io/controller-managed-attach-detach=true
Taints:             node-role.kubernetes.io/master:NoSchedule
CreationTimestamp:  Sat, 03 Feb 2018 22:37:31 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  OutOfDisk        False   Tue, 20 Feb 2018 17:17:44 +0000   Sat, 03 Feb 2018 22:37:26 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available
  MemoryPressure   False   Tue, 20 Feb 2018 17:17:44 +0000   Sat, 03 Feb 2018 22:37:26 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Tue, 20 Feb 2018 17:17:44 +0000   Sat, 03 Feb 2018 22:37:26 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  Ready            True    Tue, 20 Feb 2018 17:17:44 +0000   Sat, 03 Feb 2018 22:40:09 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.2.10
  Hostname:    k8master
Capacity:
 cpu:     8
 memory:  3881184Ki
 pods:    110
Allocatable:
 cpu:     8
 memory:  3778784Ki
 pods:    110
System Info:
 Machine ID:                 1b74045253ca4eeb9b2954f6d03bbc8d
 System UUID:                635EC630-A4AA-44EC-BACA-F00D8977743C
 Boot ID:                    2f1b43cc-19ef-4889-8565-4a3aa97005fc
 Kernel Version:             3.10.0-514.21.1.el7.x86_64
 OS Image:                   CentOS Linux 7 (Core)
 Operating System:           linux
 Architecture:               amd64
 Container Runtime Version:  docker://1.12.6
 Kubelet Version:            v1.9.2
 Kube-Proxy Version:         v1.9.2
ExternalID:                  k8master
Non-terminated Pods:         (9 in total)
  Namespace                  Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits
  ---------                  ----                                ------------  ----------  ---------------  -------------
  kube-system                contiv-etcd-6mcxz                   0 (0%)        0 (0%)      0 (0%)           0 (0%)
  kube-system                contiv-netmaster-vkc6s              0 (0%)        0 (0%)      0 (0%)           0 (0%)
  kube-system                contiv-netplugin-qwgd5              250m (3%)     0 (0%)      0 (0%)           0 (0%)
  kube-system                contiv-ovs-mwfjk                    0 (0%)        0 (0%)      0 (0%)           0 (0%)
  kube-system                etcd-k8master                       0 (0%)        0 (0%)      0 (0%)           0 (0%)
  kube-system                kube-apiserver-k8master             250m (3%)     0 (0%)      0 (0%)           0 (0%)
  kube-system                kube-controller-manager-k8master    200m (2%)     0 (0%)      0 (0%)           0 (0%)
  kube-system                kube-proxy-8wx7q                    0 (0%)        0 (0%)      0 (0%)           0 (0%)
  kube-system                kube-scheduler-k8master             100m (1%)     0 (0%)      0 (0%)           0 (0%)
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  CPU Requests  CPU Limits  Memory Requests  Memory Limits
  ------------  ----------  ---------------  -------------
  800m (10%)    0 (0%)      0 (0%)           0 (0%)
Events:         <none>


Name:               k8node-01
Roles:              <none>
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/hostname=k8node-01
Annotations:        node.alpha.kubernetes.io/ttl=0
                    volumes.kubernetes.io/controller-managed-attach-detach=true
Taints:             <none>
CreationTimestamp:  Sat, 03 Feb 2018 22:47:42 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  OutOfDisk        False   Tue, 20 Feb 2018 17:17:47 +0000   Sat, 03 Feb 2018 22:47:41 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available
  MemoryPressure   False   Tue, 20 Feb 2018 17:17:47 +0000   Sat, 03 Feb 2018 22:47:41 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Tue, 20 Feb 2018 17:17:47 +0000   Sat, 03 Feb 2018 22:47:41 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  Ready            True    Tue, 20 Feb 2018 17:17:47 +0000   Sat, 03 Feb 2018 22:49:02 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.2.11
  Hostname:    k8node-01
Capacity:
 cpu:     4
 memory:  1883392Ki
 pods:    110
Allocatable:
 cpu:     4
 memory:  1780992Ki
 pods:    110
System Info:
 Machine ID:                 1b74045253ca4eeb9b2954f6d03bbc8d
 System UUID:                EC0AB437-FE8A-418F-997F-E581C1E5BB2D
 Boot ID:                    22bd2342-b740-4952-8aae-5cf224bdc04f
 Kernel Version:             3.10.0-514.21.1.el7.x86_64
 OS Image:                   CentOS Linux 7 (Core)
 Operating System:           linux
 Architecture:               amd64
 Container Runtime Version:  docker://1.12.6
 Kubelet Version:            v1.9.2
 Kube-Proxy Version:         v1.9.2
ExternalID:                  k8node-01
Non-terminated Pods:         (3 in total)
  Namespace                  Name                      CPU Requests  CPU Limits  Memory Requests  Memory Limits
  ---------                  ----                      ------------  ----------  ---------------  -------------
  kube-system                contiv-netplugin-xwxkn    250m (6%)     0 (0%)      0 (0%)           0 (0%)
  kube-system                contiv-ovs-zwb9t          0 (0%)        0 (0%)      0 (0%)           0 (0%)
  kube-system                kube-proxy-zg92c          0 (0%)        0 (0%)      0 (0%)           0 (0%)
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  CPU Requests  CPU Limits  Memory Requests  Memory Limits
  ------------  ----------  ---------------  -------------
  250m (6%)     0 (0%)      0 (0%)           0 (0%)
Events:         <none>


Name:               k8node-02
Roles:              <none>
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/hostname=k8node-02
Annotations:        node.alpha.kubernetes.io/ttl=0
                    volumes.kubernetes.io/controller-managed-attach-detach=true
Taints:             <none>
CreationTimestamp:  Sat, 03 Feb 2018 22:55:35 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  OutOfDisk        False   Tue, 20 Feb 2018 17:17:46 +0000   Sat, 03 Feb 2018 22:55:33 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available
  MemoryPressure   False   Tue, 20 Feb 2018 17:17:46 +0000   Sat, 03 Feb 2018 22:55:33 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Tue, 20 Feb 2018 17:17:46 +0000   Sat, 03 Feb 2018 22:55:33 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  Ready            True    Tue, 20 Feb 2018 17:17:46 +0000   Sat, 03 Feb 2018 23:01:06 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.2.12
  Hostname:    k8node-02
Capacity:
 cpu:     4
 memory:  1883392Ki
 pods:    110
Allocatable:
 cpu:     4
 memory:  1780992Ki
 pods:    110
System Info:
 Machine ID:                 1b74045253ca4eeb9b2954f6d03bbc8d
 System UUID:                4179196B-7C4A-465F-AD70-9CBA1074CB4A
 Boot ID:                    308ca593-5afe-4cef-9a2b-45c73951cfee
 Kernel Version:             3.10.0-514.21.1.el7.x86_64
 OS Image:                   CentOS Linux 7 (Core)
 Operating System:           linux
 Architecture:               amd64
 Container Runtime Version:  docker://1.12.6
 Kubelet Version:            v1.9.2
 Kube-Proxy Version:         v1.9.2
ExternalID:                  k8node-02
Non-terminated Pods:         (3 in total)
  Namespace                  Name                      CPU Requests  CPU Limits  Memory Requests  Memory Limits
  ---------                  ----                      ------------  ----------  ---------------  -------------
  kube-system                contiv-netplugin-2d7rp    250m (6%)     0 (0%)      0 (0%)           0 (0%)
  kube-system                contiv-ovs-8mfdn          0 (0%)        0 (0%)      0 (0%)           0 (0%)
  kube-system                kube-proxy-l9msk          0 (0%)        0 (0%)      0 (0%)           0 (0%)
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  CPU Requests  CPU Limits  Memory Requests  Memory Limits
  ------------  ----------  ---------------  -------------
  250m (6%)     0 (0%)      0 (0%)           0 (0%)
Events:         <none>


Name:               k8node-03
Roles:              <none>
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/hostname=k8node-03
Annotations:        node.alpha.kubernetes.io/ttl=0
                    volumes.kubernetes.io/controller-managed-attach-detach=true
Taints:             <none>
CreationTimestamp:  Sat, 03 Feb 2018 23:06:36 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  OutOfDisk        False   Tue, 20 Feb 2018 17:17:42 +0000   Sat, 03 Feb 2018 23:06:35 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available
  MemoryPressure   False   Tue, 20 Feb 2018 17:17:42 +0000   Sat, 03 Feb 2018 23:06:35 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Tue, 20 Feb 2018 17:17:42 +0000   Sat, 03 Feb 2018 23:06:35 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  Ready            True    Tue, 20 Feb 2018 17:17:42 +0000   Sat, 03 Feb 2018 23:09:16 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.2.13
  Hostname:    k8node-03
Capacity:
 cpu:     4
 memory:  1883392Ki
 pods:    110
Allocatable:
 cpu:     4
 memory:  1780992Ki
 pods:    110
System Info:
 Machine ID:                 1b74045253ca4eeb9b2954f6d03bbc8d
 System UUID:                CC5E8550-8042-48BD-BAC3-778F77B2C6E8
 Boot ID:                    f9a6e775-b559-423e-91e1-10e300dbdc9e
 Kernel Version:             3.10.0-514.21.1.el7.x86_64
 OS Image:                   CentOS Linux 7 (Core)
 Operating System:           linux
 Architecture:               amd64
 Container Runtime Version:  docker://1.12.6
 Kubelet Version:            v1.9.2
 Kube-Proxy Version:         v1.9.2
ExternalID:                  k8node-03
Non-terminated Pods:         (3 in total)
  Namespace                  Name                      CPU Requests  CPU Limits  Memory Requests  Memory Limits
  ---------                  ----                      ------------  ----------  ---------------  -------------
  kube-system                contiv-netplugin-5pqjs    250m (6%)     0 (0%)      0 (0%)           0 (0%)
  kube-system                contiv-ovs-zmk5s          0 (0%)        0 (0%)      0 (0%)           0 (0%)
  kube-system                kube-proxy-6j2b4          0 (0%)        0 (0%)      0 (0%)           0 (0%)
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  CPU Requests  CPU Limits  Memory Requests  Memory Limits
  ------------  ----------  ---------------  -------------
  250m (6%)     0 (0%)      0 (0%)           0 (0%)
Events:         <none>
\n================
kubectl describe persistentvolumeclaims --all-namespaces
================\n
\n================
kubectl describe persistentvolumes --all-namespaces
================\n
\n================
kubectl describe poddisruptionbudgets --all-namespaces
================\n
\n================
kubectl describe podpreset --all-namespaces
================\n
the server doesn't have a resource type "podpreset"
\n================
kubectl describe pods --all-namespaces
================\n
Name:           contiv-etcd-6mcxz
Namespace:      kube-system
Node:           k8master/192.168.2.10
Start Time:     Sat, 03 Feb 2018 22:37:53 +0000
Labels:         controller-revision-hash=3440706255
                k8s-app=contiv-etcd
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.10
Controlled By:  DaemonSet/contiv-etcd
Containers:
  contiv-etcd:
    Container ID:  docker://c584086fab59c85c04c80b189f2b74361d8249d629812f1f12062311d6329732
    Image:         quay.io/coreos/etcd:v3.2.4
    Image ID:      docker-pullable://quay.io/coreos/etcd@sha256:0a582c6ca6d32f1bed74c51bb1e33a215b301e0f28683777ec6af0c2e3925588
    Port:          <none>
    Command:
      /bin/sh
      -c
    Args:
      ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
    State:          Running
      Started:      Sat, 03 Feb 2018 22:40:57 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ETCD_IP:            (v1:status.podIP)
      ETCD_NAME:                contiv-etcd
      ETCD_DATA_DIR:            /var/lib/etcd/contiv-data
      ETCD_LISTEN_CLIENT_URLS:  http://0.0.0.0:6666
      ETCD_LISTEN_PEER_URLS:    http://0.0.0.0:6667
    Mounts:
      /var/etcd from var-etcd (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-etcd:
    Type:          HostPath (bare host directory volume)
    Path:          /var/etcd
    HostPathType:  
  default-token-9ktff:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-9ktff
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  node-role.kubernetes.io/master=
Tolerations:     CriticalAddonsOnly
                 node-role.kubernetes.io/master:NoSchedule
                 node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-netmaster-vkc6s
Namespace:      kube-system
Node:           k8master/192.168.2.10
Start Time:     Sat, 03 Feb 2018 22:40:22 +0000
Labels:         k8s-app=contiv-netmaster
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.10
Controlled By:  ReplicaSet/contiv-netmaster
Init Containers:
  contiv-netplugin-init:
    Container ID:   docker://e1993b2b63c42729f6d24eaac6e4805e3509e39d08ff3078e27e5a52f8a2d74a
    Image:          contiv/netplugin-init:latest
    Image ID:       docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
    Port:           <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 22:44:46 +0000
      Finished:     Sat, 03 Feb 2018 22:44:49 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:        netmaster
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /var/contiv from var-contiv (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netmaster-token-47bxd (ro)
  contiv-netctl:
    Container ID:  docker://0c9a499dd9a3f027c6aafa2fadac4820d4977eb6a6e036638ac8f3f32c636834
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      cp
      /contiv/bin/netctl
      /usr/local/sbin/netctl
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 22:45:07 +0000
      Finished:     Sat, 03 Feb 2018 22:45:07 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /usr/local/sbin/ from usr-local-sbin (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netmaster-token-47bxd (ro)
Containers:
  contiv-netmaster:
    Container ID:  docker://dd9e75217cfb963e0806de0d573fe10d28e9f71ff7e8fc560825e2e753903661
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      tail
      -f
      /dev/null
    State:          Running
      Started:      Sat, 03 Feb 2018 22:45:18 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:                    netmaster
      CONTIV_NETMASTER_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>     Optional: false
      CONTIV_NETMASTER_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETMASTER_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netmaster-token-47bxd (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
  usr-local-sbin:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/local/sbin/
    HostPathType:  
  contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
  contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
  contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
  contiv-netmaster-token-47bxd:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  contiv-netmaster-token-47bxd
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  node-role.kubernetes.io/master=
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:          <none>


Name:           contiv-netplugin-2d7rp
Namespace:      kube-system
Node:           k8node-02/192.168.2.12
Start Time:     Sat, 03 Feb 2018 22:55:38 +0000
Labels:         controller-revision-hash=4029632485
                k8s-app=contiv-netplugin
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.12
Controlled By:  DaemonSet/contiv-netplugin
Init Containers:
  contiv-netplugin-init:
    Container ID:   docker://92bb1a18866c331d3273f8c89b77e922ae6370346d8ca90e077419edede9193c
    Image:          contiv/netplugin-init:latest
    Image ID:       docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
    Port:           <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 23:00:52 +0000
      Finished:     Sat, 03 Feb 2018 23:00:52 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
  contiv-cni:
    Container ID:  docker://26a9d7ca4ecda56afd9b216076f091466ee1a40b7a81f30907af18446d947064
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 23:06:16 +0000
      Finished:     Sat, 03 Feb 2018 23:06:16 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Containers:
  contiv-netplugin:
    Container ID:  docker://d87a66a8c2913d4ec5daecfadf73b64e38872b00b37a1e58021b4c465654ef72
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      tail
      -f
      /dev/null
    State:          Running
      Started:      Sat, 03 Feb 2018 23:08:19 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
  cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
  etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
  contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
  contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
  contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
  contiv-netplugin-token-xqsb5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  contiv-netplugin-token-xqsb5
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-netplugin-5pqjs
Namespace:      kube-system
Node:           k8node-03/192.168.2.13
Start Time:     Sat, 03 Feb 2018 23:06:39 +0000
Labels:         controller-revision-hash=4029632485
                k8s-app=contiv-netplugin
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.13
Controlled By:  DaemonSet/contiv-netplugin
Init Containers:
  contiv-netplugin-init:
    Container ID:   docker://d3d3cae725515e434b8fffe529d9255b15a9a7772812aa604997b727ecae8933
    Image:          contiv/netplugin-init:latest
    Image ID:       docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
    Port:           <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 23:09:07 +0000
      Finished:     Sat, 03 Feb 2018 23:09:07 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
  contiv-cni:
    Container ID:  docker://80fe8f20c15247503588028d51f9595ed406561b1d940c1e47e1b473b70ff967
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 23:13:07 +0000
      Finished:     Sat, 03 Feb 2018 23:13:07 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Containers:
  contiv-netplugin:
    Container ID:  docker://71658aba1dea2b49ad888b5d6880c5313dc5635945df76491a5f51d33da5d857
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      tail
      -f
      /dev/null
    State:          Running
      Started:      Sat, 03 Feb 2018 23:13:14 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
  cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
  etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
  contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
  contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
  contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
  contiv-netplugin-token-xqsb5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  contiv-netplugin-token-xqsb5
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-netplugin-qwgd5
Namespace:      kube-system
Node:           k8master/192.168.2.10
Start Time:     Sat, 03 Feb 2018 22:37:53 +0000
Labels:         controller-revision-hash=4029632485
                k8s-app=contiv-netplugin
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.10
Controlled By:  DaemonSet/contiv-netplugin
Init Containers:
  contiv-netplugin-init:
    Container ID:   docker://04bc313a43b9a37cb93d161cdcb4e002824307b5c7db2b0ea664a577e879dd19
    Image:          contiv/netplugin-init:latest
    Image ID:       docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
    Port:           <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 22:40:07 +0000
      Finished:     Sat, 03 Feb 2018 22:40:12 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
  contiv-cni:
    Container ID:  docker://1e9df8ab383baf7e9890712058863f523b437a26acb84659006ede9551d3e533
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 22:44:39 +0000
      Finished:     Sat, 03 Feb 2018 22:44:39 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Containers:
  contiv-netplugin:
    Container ID:  docker://a4137c814f9832676d7df279495ab131f77f1119ad666633ee0cae9c8d6f4c1b
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      tail
      -f
      /dev/null
    State:          Running
      Started:      Sat, 03 Feb 2018 22:45:09 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
  cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
  etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
  contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
  contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
  contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
  contiv-netplugin-token-xqsb5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  contiv-netplugin-token-xqsb5
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-netplugin-xwxkn
Namespace:      kube-system
Node:           k8node-01/192.168.2.11
Start Time:     Sat, 03 Feb 2018 22:47:46 +0000
Labels:         controller-revision-hash=4029632485
                k8s-app=contiv-netplugin
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.11
Controlled By:  DaemonSet/contiv-netplugin
Init Containers:
  contiv-netplugin-init:
    Container ID:   docker://d1526ce58adecc381edae40be851e718f64e6055678245513dc1cca02567c455
    Image:          contiv/netplugin-init:latest
    Image ID:       docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
    Port:           <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 22:48:51 +0000
      Finished:     Sat, 03 Feb 2018 22:48:51 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      CONTIV_ROLE:        netplugin
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /etc/cni/net.d/ from etc-cni-dir (rw)
      /var/contiv from var-contiv (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
  contiv-cni:
    Container ID:  docker://d47429eb736387693dcf5a8c9befea3aaec5353b18870a1ff084c2fbb7a4ef03
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      cp
      /contiv/bin/contivk8s
      /opt/cni/bin/contivk8s
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 03 Feb 2018 23:02:59 +0000
      Finished:     Sat, 03 Feb 2018 23:03:00 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /opt/cni/bin from cni-bin-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Containers:
  contiv-netplugin:
    Container ID:  docker://9aaa1c9cb44a3e36a18bec6f9cf00f1c82e7c319ecbcd73cb78b208f7bcd5a44
    Image:         contiv/netplugin:latest
    Image ID:      docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
    Port:          <none>
    Command:
      tail
      -f
      /dev/null
    State:          Running
      Started:      Sat, 03 Feb 2018 23:03:18 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:  250m
    Environment:
      CONTIV_ROLE:                    netplugin
      CONTIV_NETPLUGIN_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_VTEP_IP:        (v1:status.podIP)
      CONTIV_NETPLUGIN_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETPLUGIN_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from contiv-netplugin-token-xqsb5 (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
  cni-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
  etc-cni-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d/
    HostPathType:  
  contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
  contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
  contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
  contiv-netplugin-token-xqsb5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  contiv-netplugin-token-xqsb5
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-ovs-8mfdn
Namespace:      kube-system
Node:           k8node-02/192.168.2.12
Start Time:     Sat, 03 Feb 2018 22:55:38 +0000
Labels:         controller-revision-hash=1824568849
                k8s-app=contiv-ovs
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.12
Controlled By:  DaemonSet/contiv-ovs
Containers:
  contiv-ovsdb-server:
    Container ID:  docker://9cb6eb87e5781c179ce895e55b02f926f3a7abcaf7a23c35a67dfcfe1a3c561d
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovsdb-server.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 23:01:06 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
  contiv-ovs-vswitchd:
    Container ID:  docker://5d3a3a03ca28ba31d3193f5c24367d5df59e620d5ef4b4012648498f54b37464
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 23:06:21 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  default-token-9ktff:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-9ktff
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-ovs-mwfjk
Namespace:      kube-system
Node:           k8master/192.168.2.10
Start Time:     Sat, 03 Feb 2018 22:37:53 +0000
Labels:         controller-revision-hash=1824568849
                k8s-app=contiv-ovs
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.10
Controlled By:  DaemonSet/contiv-ovs
Containers:
  contiv-ovsdb-server:
    Container ID:  docker://39e7cc6199270908b8fd259c1ff09e21af4cf64c5714d3525923ec8566555232
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovsdb-server.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 22:41:33 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
  contiv-ovs-vswitchd:
    Container ID:  docker://e32264562935b103bb84aa237add0c06ab70136ff288263bc78c03a3f0475553
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 22:44:51 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  default-token-9ktff:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-9ktff
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-ovs-zmk5s
Namespace:      kube-system
Node:           k8node-03/192.168.2.13
Start Time:     Sat, 03 Feb 2018 23:06:39 +0000
Labels:         controller-revision-hash=1824568849
                k8s-app=contiv-ovs
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.13
Controlled By:  DaemonSet/contiv-ovs
Containers:
  contiv-ovsdb-server:
    Container ID:  docker://dc98559482d862433e27244ecd0ee36fce64027dfb6ce1798ef6f633b6ae3e35
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovsdb-server.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 23:09:37 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
  contiv-ovs-vswitchd:
    Container ID:  docker://364a2a0e04c9e14f0ca1c85e40986f3d09b4643c45c5df03df4bbc06f26c456c
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 23:13:08 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  default-token-9ktff:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-9ktff
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           contiv-ovs-zwb9t
Namespace:      kube-system
Node:           k8node-01/192.168.2.11
Start Time:     Sat, 03 Feb 2018 22:47:46 +0000
Labels:         controller-revision-hash=1824568849
                k8s-app=contiv-ovs
                pod-template-generation=1
Annotations:    scheduler.alpha.kubernetes.io/critical-pod=
Status:         Running
IP:             192.168.2.11
Controlled By:  DaemonSet/contiv-ovs
Containers:
  contiv-ovsdb-server:
    Container ID:  docker://abfd1933ea861649f13510742edc983ea29e56c8c7f0002bc8515e1763423157
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovsdb-server.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 22:51:27 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
  contiv-ovs-vswitchd:
    Container ID:  docker://9fc9fad02f6bb178f3e63e4d2023e34c7f93abc1a350e61630c3360acc770902
    Image:         contiv/ovs:latest
    Image ID:      docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
    Port:          <none>
    Command:
      /scripts/start-ovs-vswitchd.sh
    State:          Running
      Started:      Sat, 03 Feb 2018 22:53:33 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/openvswitch from etc-openvswitch (rw)
      /lib/modules from lib-modules (ro)
      /var/run from var-run (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9ktff (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  etc-openvswitch:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/openvswitch
    HostPathType:  
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  var-run:
    Type:          HostPath (bare host directory volume)
    Path:          /var/run
    HostPathType:  
  default-token-9ktff:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-9ktff
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:         etcd-k8master
Namespace:    kube-system
Node:         k8master/192.168.2.10
Start Time:   Sat, 03 Feb 2018 22:31:55 +0000
Labels:       component=etcd
              tier=control-plane
Annotations:  kubernetes.io/config.hash=7278f85057e8bf5cb81c9f96d3b25320
              kubernetes.io/config.mirror=7278f85057e8bf5cb81c9f96d3b25320
              kubernetes.io/config.seen=2018-02-03T22:31:50.423856543Z
              kubernetes.io/config.source=file
              scheduler.alpha.kubernetes.io/critical-pod=
Status:       Running
IP:           192.168.2.10
Containers:
  etcd:
    Container ID:  docker://eab796c7ae3cc778244b6175dc7a8e081f57b4dd79bfc77346b5e12e1e87460e
    Image:         gcr.io/google_containers/etcd-amd64:3.1.11
    Image ID:      docker-pullable://gcr.io/google_containers/etcd-amd64@sha256:54889c08665d241e321ca5ce976b2df0f766794b698d53faf6b7dacb95316680
    Port:          <none>
    Command:
      etcd
      --listen-client-urls=http://127.0.0.1:2379
      --advertise-client-urls=http://127.0.0.1:2379
      --data-dir=/var/lib/etcd
    State:          Running
      Started:      Sat, 03 Feb 2018 22:35:31 +0000
    Ready:          True
    Restart Count:  0
    Liveness:       http-get http://127.0.0.1:2379/health delay=15s timeout=15s period=10s #success=1 #failure=8
    Environment:    <none>
    Mounts:
      /var/lib/etcd from etcd (rw)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  etcd:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/etcd
    HostPathType:  DirectoryOrCreate
QoS Class:         BestEffort
Node-Selectors:    <none>
Tolerations:       :NoExecute
Events:            <none>


Name:         kube-apiserver-k8master
Namespace:    kube-system
Node:         k8master/192.168.2.10
Start Time:   Sat, 03 Feb 2018 22:31:55 +0000
Labels:       component=kube-apiserver
              tier=control-plane
Annotations:  kubernetes.io/config.hash=8269013687f7c93ae98df858c8ca8f73
              kubernetes.io/config.mirror=8269013687f7c93ae98df858c8ca8f73
              kubernetes.io/config.seen=2018-02-03T22:31:50.423866266Z
              kubernetes.io/config.source=file
              scheduler.alpha.kubernetes.io/critical-pod=
Status:       Running
IP:           192.168.2.10
Containers:
  kube-apiserver:
    Container ID:  docker://cd38db17a5b2870dc43318f687d04a037c731188efee8818dde853cfc5c52535
    Image:         gcr.io/google_containers/kube-apiserver-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-apiserver-amd64@sha256:eec4329de0892f4a960b7f1202272f93880d3071a9b40d8407585125b37d527d
    Port:          <none>
    Command:
      kube-apiserver
      --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      --secure-port=6443
      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      --requestheader-allowed-names=front-proxy-client
      --service-cluster-ip-range=10.96.0.0/12
      --service-account-key-file=/etc/kubernetes/pki/sa.pub
      --allow-privileged=true
      --requestheader-group-headers=X-Remote-Group
      --advertise-address=192.168.2.10
      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      --insecure-port=0
      --admission-control=Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota
      --enable-bootstrap-token-auth=true
      --client-ca-file=/etc/kubernetes/pki/ca.crt
      --requestheader-username-headers=X-Remote-User
      --requestheader-extra-headers-prefix=X-Remote-Extra-
      --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      --authorization-mode=Node,RBAC
      --etcd-servers=http://127.0.0.1:2379
    State:          Running
      Started:      Sat, 03 Feb 2018 22:37:21 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:     250m
    Liveness:  http-get https://192.168.2.10:6443/healthz delay=15s timeout=15s period=10s #success=1 #failure=8
    Environment:
      no_proxy:  k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
    Mounts:
      /etc/kubernetes/pki from k8s-certs (ro)
      /etc/pki from ca-certs-etc-pki (ro)
      /etc/ssl/certs from ca-certs (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  k8s-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/pki
    HostPathType:  DirectoryOrCreate
  ca-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ssl/certs
    HostPathType:  DirectoryOrCreate
  ca-certs-etc-pki:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/pki
    HostPathType:  DirectoryOrCreate
QoS Class:         Burstable
Node-Selectors:    <none>
Tolerations:       :NoExecute
Events:            <none>


Name:         kube-controller-manager-k8master
Namespace:    kube-system
Node:         k8master/192.168.2.10
Start Time:   Sat, 03 Feb 2018 22:31:55 +0000
Labels:       component=kube-controller-manager
              tier=control-plane
Annotations:  kubernetes.io/config.hash=3e62d6d6684d8169bc7a1ad3c99997bc
              kubernetes.io/config.mirror=3e62d6d6684d8169bc7a1ad3c99997bc
              kubernetes.io/config.seen=2018-02-03T22:31:50.423869393Z
              kubernetes.io/config.source=file
              scheduler.alpha.kubernetes.io/critical-pod=
Status:       Running
IP:           192.168.2.10
Containers:
  kube-controller-manager:
    Container ID:  docker://409aa1bbfd5ace3dc4891da1aa7b841aa7b43a075c19dd1cc832ce67e8a31058
    Image:         gcr.io/google_containers/kube-controller-manager-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-controller-manager-amd64@sha256:10daf65c6e8d0ff032323931f3869cd30af23feab90345265ea405b6104a41c7
    Port:          <none>
    Command:
      kube-controller-manager
      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      --address=127.0.0.1
      --use-service-account-credentials=true
      --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      --root-ca-file=/etc/kubernetes/pki/ca.crt
      --leader-elect=true
      --controllers=*,bootstrapsigner,tokencleaner
      --kubeconfig=/etc/kubernetes/controller-manager.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 22:33:16 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:     200m
    Liveness:  http-get http://127.0.0.1:10252/healthz delay=15s timeout=15s period=10s #success=1 #failure=8
    Environment:
      no_proxy:  k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
    Mounts:
      /etc/kubernetes/controller-manager.conf from kubeconfig (ro)
      /etc/kubernetes/pki from k8s-certs (ro)
      /etc/pki from ca-certs-etc-pki (ro)
      /etc/ssl/certs from ca-certs (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  k8s-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/pki
    HostPathType:  DirectoryOrCreate
  ca-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ssl/certs
    HostPathType:  DirectoryOrCreate
  kubeconfig:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/controller-manager.conf
    HostPathType:  FileOrCreate
  ca-certs-etc-pki:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/pki
    HostPathType:  DirectoryOrCreate
QoS Class:         Burstable
Node-Selectors:    <none>
Tolerations:       :NoExecute
Events:            <none>


Name:           kube-proxy-6j2b4
Namespace:      kube-system
Node:           k8node-03/192.168.2.13
Start Time:     Sat, 03 Feb 2018 23:06:39 +0000
Labels:         controller-revision-hash=588621068
                k8s-app=kube-proxy
                pod-template-generation=1
Annotations:    <none>
Status:         Running
IP:             192.168.2.13
Controlled By:  DaemonSet/kube-proxy
Containers:
  kube-proxy:
    Container ID:  docker://6a1d4fb9c76c4750bbf134fd7baa1d5462cca42342e1d47cfc4c967048126c7a
    Image:         gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
    Port:          <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 23:10:53 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-proxy-token-wmgjk (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
  xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  kube-proxy-token-wmgjk:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  kube-proxy-token-wmgjk
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           kube-proxy-8wx7q
Namespace:      kube-system
Node:           k8master/192.168.2.10
Start Time:     Sat, 03 Feb 2018 22:37:43 +0000
Labels:         controller-revision-hash=588621068
                k8s-app=kube-proxy
                pod-template-generation=1
Annotations:    <none>
Status:         Running
IP:             192.168.2.10
Controlled By:  DaemonSet/kube-proxy
Containers:
  kube-proxy:
    Container ID:  docker://b893576cd9a52e57bc66c2d9572c8d677f3c8a619702f911146d09d5ecd5204f
    Image:         gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
    Port:          <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 22:39:37 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-proxy-token-wmgjk (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
  xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  kube-proxy-token-wmgjk:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  kube-proxy-token-wmgjk
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           kube-proxy-l9msk
Namespace:      kube-system
Node:           k8node-02/192.168.2.12
Start Time:     Sat, 03 Feb 2018 22:55:38 +0000
Labels:         controller-revision-hash=588621068
                k8s-app=kube-proxy
                pod-template-generation=1
Annotations:    <none>
Status:         Running
IP:             192.168.2.12
Controlled By:  DaemonSet/kube-proxy
Containers:
  kube-proxy:
    Container ID:  docker://cac2484e758141295b0cabaf20a15c6d9bac8b8b22a91d7f6362bc23985ff510
    Image:         gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
    Port:          <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 23:08:19 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-proxy-token-wmgjk (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
  xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  kube-proxy-token-wmgjk:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  kube-proxy-token-wmgjk
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:           kube-proxy-zg92c
Namespace:      kube-system
Node:           k8node-01/192.168.2.11
Start Time:     Sat, 03 Feb 2018 22:47:46 +0000
Labels:         controller-revision-hash=588621068
                k8s-app=kube-proxy
                pod-template-generation=1
Annotations:    <none>
Status:         Running
IP:             192.168.2.11
Controlled By:  DaemonSet/kube-proxy
Containers:
  kube-proxy:
    Container ID:  docker://c33c70f5a692eb4786b50bc8b136745b04d0ac94529a537bbd35bfdee88f2b5f
    Image:         gcr.io/google_containers/kube-proxy-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
    Port:          <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 22:50:53 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-proxy-token-wmgjk (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
  xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
  lib-modules:
    Type:          HostPath (bare host directory volume)
    Path:          /lib/modules
    HostPathType:  
  kube-proxy-token-wmgjk:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  kube-proxy-token-wmgjk
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node-role.kubernetes.io/master:NoSchedule
                 node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
                 node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/unreachable:NoExecute
Events:          <none>


Name:         kube-scheduler-k8master
Namespace:    kube-system
Node:         k8master/192.168.2.10
Start Time:   Sat, 03 Feb 2018 22:31:55 +0000
Labels:       component=kube-scheduler
              tier=control-plane
Annotations:  kubernetes.io/config.hash=419e9c2b7c2d4889af65758618bbed88
              kubernetes.io/config.mirror=419e9c2b7c2d4889af65758618bbed88
              kubernetes.io/config.seen=2018-02-03T22:31:50.423881438Z
              kubernetes.io/config.source=file
              scheduler.alpha.kubernetes.io/critical-pod=
Status:       Running
IP:           192.168.2.10
Containers:
  kube-scheduler:
    Container ID:  docker://75dfd82dae23666b4c39b3d32221913e7e4181323a13b711fdf6121d6d6c672e
    Image:         gcr.io/google_containers/kube-scheduler-amd64:v1.9.2
    Image ID:      docker-pullable://gcr.io/google_containers/kube-scheduler-amd64@sha256:082520e24e697f3228046ca13cddf46e4e01ae2982685b4ccc7df8f8e9145abc
    Port:          <none>
    Command:
      kube-scheduler
      --address=127.0.0.1
      --leader-elect=true
      --kubeconfig=/etc/kubernetes/scheduler.conf
    State:          Running
      Started:      Sat, 03 Feb 2018 22:33:45 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:     100m
    Liveness:  http-get http://127.0.0.1:10251/healthz delay=15s timeout=15s period=10s #success=1 #failure=8
    Environment:
      no_proxy:  k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
    Mounts:
      /etc/kubernetes/scheduler.conf from kubeconfig (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  kubeconfig:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/scheduler.conf
    HostPathType:  FileOrCreate
QoS Class:         Burstable
Node-Selectors:    <none>
Tolerations:       :NoExecute
Events:            <none>
\n================
kubectl describe podsecuritypolicies --all-namespaces
================\n
\n================
kubectl describe podtemplates --all-namespaces
================\n
\n================
kubectl describe replicasets --all-namespaces
================\n
Name:         contiv-netmaster
Namespace:    kube-system
Selector:     k8s-app=contiv-netmaster
Labels:       k8s-app=contiv-netmaster
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"extensions/v1beta1","kind":"ReplicaSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netmaster"},"name":"contiv-netmaster","...
Replicas:     1 current / 1 desired
Pods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           k8s-app=contiv-netmaster
  Annotations:      scheduler.alpha.kubernetes.io/critical-pod=
  Service Account:  contiv-netmaster
  Init Containers:
   contiv-netplugin-init:
    Image:  contiv/netplugin-init:latest
    Port:   <none>
    Environment:
      CONTIV_ROLE:        netmaster
      CONTIV_MODE:        <set to the key 'contiv_mode' of config map 'contiv-config'>        Optional: false
      CONTIV_K8S_CONFIG:  <set to the key 'contiv_k8s_config' of config map 'contiv-config'>  Optional: false
      CONTIV_CNI_CONFIG:  <set to the key 'contiv_cni_config' of config map 'contiv-config'>  Optional: false
    Mounts:
      /var/contiv from var-contiv (rw)
   contiv-netctl:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      cp
      /contiv/bin/netctl
      /usr/local/sbin/netctl
    Environment:  <none>
    Mounts:
      /usr/local/sbin/ from usr-local-sbin (rw)
  Containers:
   contiv-netmaster:
    Image:  contiv/netplugin:latest
    Port:   <none>
    Command:
      tail
      -f
      /dev/null
    Environment:
      CONTIV_ROLE:                    netmaster
      CONTIV_NETMASTER_MODE:          <set to the key 'contiv_mode' of config map 'contiv-config'>     Optional: false
      CONTIV_NETMASTER_FORWARD_MODE:  <set to the key 'contiv_fwdmode' of config map 'contiv-config'>  Optional: false
      CONTIV_NETMASTER_NET_MODE:      <set to the key 'contiv_netmode' of config map 'contiv-config'>  Optional: false
    Mounts:
      /contiv/bin from contiv-bin-dir (ro)
      /contiv/scripts/ from contiv-scripts-dir (ro)
      /var/contiv from var-contiv (rw)
      /var/log/contiv from contiv-log-dir (rw)
  Volumes:
   var-contiv:
    Type:          HostPath (bare host directory volume)
    Path:          /var/contiv
    HostPathType:  
   usr-local-sbin:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/local/sbin/
    HostPathType:  
   contiv-bin-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/bin
    HostPathType:  
   contiv-scripts-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
    HostPathType:  
   contiv-log-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/log/contiv
    HostPathType:  
Events:            <none>
\n================
kubectl describe replicationcontrollers --all-namespaces
================\n
\n================
kubectl describe resourcequotas --all-namespaces
================\n
\n================
kubectl describe rolebindings --all-namespaces
================\n
Name:         kubeadm:bootstrap-signer-clusterinfo
Labels:       <none>
Annotations:  <none>
Role:
  Kind:  Role
  Name:  kubeadm:bootstrap-signer-clusterinfo
Subjects:
  Kind  Name              Namespace
  ----  ----              ---------
  User  system:anonymous  


Name:         system:controller:bootstrap-signer
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  Role
  Name:  system:controller:bootstrap-signer
Subjects:
  Kind            Name              Namespace
  ----            ----              ---------
  ServiceAccount  bootstrap-signer  kube-system


Name:         system::leader-locking-kube-controller-manager
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  Role
  Name:  system::leader-locking-kube-controller-manager
Subjects:
  Kind            Name                     Namespace
  ----            ----                     ---------
  ServiceAccount  kube-controller-manager  kube-system


Name:         system::leader-locking-kube-scheduler
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  Role
  Name:  system::leader-locking-kube-scheduler
Subjects:
  Kind            Name            Namespace
  ----            ----            ---------
  ServiceAccount  kube-scheduler  kube-system


Name:         system:controller:bootstrap-signer
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  Role
  Name:  system:controller:bootstrap-signer
Subjects:
  Kind            Name              Namespace
  ----            ----              ---------
  ServiceAccount  bootstrap-signer  kube-system


Name:         system:controller:cloud-provider
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  Role
  Name:  system:controller:cloud-provider
Subjects:
  Kind            Name            Namespace
  ----            ----            ---------
  ServiceAccount  cloud-provider  kube-system


Name:         system:controller:token-cleaner
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:  Role
  Name:  system:controller:token-cleaner
Subjects:
  Kind            Name           Namespace
  ----            ----           ---------
  ServiceAccount  token-cleaner  kube-system
\n================
kubectl describe roles --all-namespaces
================\n
Name:         kubeadm:bootstrap-signer-clusterinfo
Labels:       <none>
Annotations:  <none>
PolicyRule:
  Resources   Non-Resource URLs  Resource Names  Verbs
  ---------   -----------------  --------------  -----
  configmaps  []                 [cluster-info]  [get]


Name:         system:controller:bootstrap-signer
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources   Non-Resource URLs  Resource Names  Verbs
  ---------   -----------------  --------------  -----
  configmaps  []                 []              [get list watch]
  configmaps  []                 [cluster-info]  [update]
  events      []                 []              [create patch update]


Name:         extension-apiserver-authentication-reader
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources   Non-Resource URLs  Resource Names                        Verbs
  ---------   -----------------  --------------                        -----
  configmaps  []                 [extension-apiserver-authentication]  [get]


Name:         system::leader-locking-kube-controller-manager
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources   Non-Resource URLs  Resource Names             Verbs
  ---------   -----------------  --------------             -----
  configmaps  []                 []                         [watch]
  configmaps  []                 [kube-controller-manager]  [get update]


Name:         system::leader-locking-kube-scheduler
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources   Non-Resource URLs  Resource Names    Verbs
  ---------   -----------------  --------------    -----
  configmaps  []                 []                [watch]
  configmaps  []                 [kube-scheduler]  [get update]


Name:         system:controller:bootstrap-signer
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
  secrets    []                 []              [get list watch]


Name:         system:controller:cloud-provider
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources   Non-Resource URLs  Resource Names  Verbs
  ---------   -----------------  --------------  -----
  configmaps  []                 []              [create get list watch]


Name:         system:controller:token-cleaner
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate=true
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
  events     []                 []              [create patch update]
  secrets    []                 []              [delete get list watch]
\n================
kubectl describe secrets --all-namespaces
================\n
Name:         default-token-d5kpb
Namespace:    default
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=default
              kubernetes.io/service-account.uid=d92c5316-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  7 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImRlZmF1bHQtdG9rZW4tZDVrcGIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVmYXVsdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImQ5MmM1MzE2LTA5MzItMTFlOC05OTQwLTA4MDAyNzc1NjFmNyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmRlZmF1bHQifQ.oIgcLwLys7enQLZbHV5FvU9o6z5Ah1dXpvMqfcCUIDAyvEG2H-UANCyd7bjtNSlIEJt5D_1pENfD7g-XXsRHCzrxqKVAy2sIi-aoFxRLOT82VphXAafcyaUVl_4dDpUr-G61djorY-ADwk-RVbeIXlBOW5xp2YBRHLajTmifIeebJXMzI78C67hXRZZt3Zf4Ju3UJ2VXrCRxMX0vx9rGuQtVDYI31Plobhu8YjQxhEPaRA94klsPMsO1RYnTRhOEiIpk1tPlWkwV7JMyWmh4d8d5QtMOxGKXjDOMKagYmLjz1VOfBCabt3ZTMQvbmwNLK030kaLcMs6qE1cxNOH6MQ


Name:         default-token-qhfnm
Namespace:    kube-public
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=default
              kubernetes.io/service-account.uid=d929a655-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXB1YmxpYyIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZWZhdWx0LXRva2VuLXFoZm5tIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImRlZmF1bHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkOTI5YTY1NS0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1wdWJsaWM6ZGVmYXVsdCJ9.dSnbAp8yYKX4rgWDeRXFtumEDbBYajdd7_eEtenGjsdS_Fh0j_V_u2m3y1pO8lQNzj0BQDuXL6Kg2pa1owPFqaNXrFdq-OYkCAvHhtM7vTw5LLux_bbslRgmLEhFp89V0F1Z_H8lfb-8FtmzZtxqSYPmdjKzzLE-kchev5zF8oBKSOz7fvbbL24971EuWNyx3yLL2gPuwTX0NdVV0cGV20VBlo4vcVqbPYeWA-N96zTwSfElv5kVIlcRaC6MpC7aviyT54nhRb-_8kOtvveyVEy9gCBMFb73spN8OZEVYk9jTJkduOfO7d36D965aHWr5cjPPPm8xWS7SrqqTJ82Eg
ca.crt:     1025 bytes
namespace:  11 bytes


Name:         attachdetach-controller-token-76zkt
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=attachdetach-controller
              kubernetes.io/service-account.uid=d6399f15-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhdHRhY2hkZXRhY2gtY29udHJvbGxlci10b2tlbi03NnprdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJhdHRhY2hkZXRhY2gtY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImQ2Mzk5ZjE1LTA5MzItMTFlOC05OTQwLTA4MDAyNzc1NjFmNyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTphdHRhY2hkZXRhY2gtY29udHJvbGxlciJ9.MrkWmZcO31AXmycWfO2fdZSy6EmPHFkdFLzRVa85WCwcGe71BJ-mk7UggbYii1dMrqy5lmbrl4J02sKeflXv84TlSA6CH8nMJ326zSqbxxXUE9BjzQslqx_763QyRl38w1uYtH_o2vmaCv0Grpnl_05EO-3IaIjIM9oFld1X404V_h7xv509xjBjo3NJcYCjMAgpqkEJz6QemZElIHPmJTg0hyllDsvR6JvGYvZ33buMEH9gvyv9wZWKhz4lgaudQCzD4_Kyyo2pG-Q1XKrZV8Pef5UDPsm-G0nB_NyMUzVnT6ZqwqN1uC7ByhR5KPVioPCbg_M0bgQQ48Qm2V2dnw


Name:         bootstrap-signer-token-2pkhf
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=bootstrap-signer
              kubernetes.io/service-account.uid=d626cfe9-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJib290c3RyYXAtc2lnbmVyLXRva2VuLTJwa2hmIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImJvb3RzdHJhcC1zaWduZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkNjI2Y2ZlOS0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Ym9vdHN0cmFwLXNpZ25lciJ9.0mMa3-KYP-ejNZtly_ZbIHjzVpmZ5SQzzBq9ez4LmzqRR7IvFTVI6ySkEjNaLKO73lwUj17DJ5T2BY69s9yKz-grBUcJEhGwlph-DGVsaIAvRImplVIkuoRMhCYXtvp1guhGqcmitvYLl_6-HKanj-3GXkDwyvVlf_fM9GV4baWNLMTU4Oex8EVjdAX5lw-jp10lm-GosqBIkv6X4mmaOgBARIr7paa7gj4Delz6GNH8WQiw4nXCuEw0BqRFDoVtdQvJhMcz1Qwh58nUgox9X-oew2eZJChu4iWTuNSRkc5WSUSNf1uO19LZy1GPmNSNN-uPfV9wnl26eS2CrOzjcA


Name:         certificate-controller-token-bwh4d
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=certificate-controller
              kubernetes.io/service-account.uid=d538b229-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjZXJ0aWZpY2F0ZS1jb250cm9sbGVyLXRva2VuLWJ3aDRkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImNlcnRpZmljYXRlLWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkNTM4YjIyOS0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Y2VydGlmaWNhdGUtY29udHJvbGxlciJ9.etcC-z18fD0qE3d1Xj1G5qU8eJzhMGpMn-7lHh66Y6LiuGfqa8HHvccZDMho6DUBmEFG2fLM5JDWgk7OmLH96UA-MvbJ1HH3bhQirwWi52U68DS_-nOP38S6nbOeSqypIBE_Q1yBKUl1Q8MuR7tujbYCIXQiTYg3r0Xpdc5OWtnfz6CLpw_nbDnCgOOsQr-qISsBHGDY5JgKsWkFDMBmHgEkZcNgKY9PAzDCBshCoeqvn9eW3h4AunJ39NDnQUwTu1aI7Cjx4NSob9rut3NVU1INwJiEkhkRLyfg5BTGceSET8o5mP5CyEDIhzu6pGA6xhr2LUnj0tyiihdqOPnaPA


Name:         clusterrole-aggregation-controller-token-tbk9h
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=clusterrole-aggregation-controller
              kubernetes.io/service-account.uid=d6ea0cba-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjbHVzdGVycm9sZS1hZ2dyZWdhdGlvbi1jb250cm9sbGVyLXRva2VuLXRiazloIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImNsdXN0ZXJyb2xlLWFnZ3JlZ2F0aW9uLWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkNmVhMGNiYS0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Y2x1c3RlcnJvbGUtYWdncmVnYXRpb24tY29udHJvbGxlciJ9.FSyeUWbT6x4-iwwZH1mDc1MwSKw4MRCkqAb0iL6l_v8c6PD4NWrbBItjnLCCxTdYvxvKAAZNo5dM1gzxrL3Sw4-IQ05vmmaC0jaKPhQ8lPcQ4KlGW1murhmPkpeLGAGHI6RTwKkXG2OoWkEakivJkgz5n8uXsb54JxDdRjWEa_kblNjWxAHmReE107tbmkMgyU6i3JXVKlCxtn1BrqpNTdM46QJNPVl1q1fqQx9R2F9vKiLeHvKAbbGddUrdXQFKuwXP0kHYsGIwbwgsIqmQ3FW8YtKQYu3gma4sFg715F74oTZws_ZX6GIV_uUi2kR6wbpNCaC9KSsVunArLv8zow


Name:         contiv-netmaster-token-47bxd
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=contiv-netmaster
              kubernetes.io/service-account.uid=dedddd7a-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjb250aXYtbmV0bWFzdGVyLXRva2VuLTQ3YnhkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImNvbnRpdi1uZXRtYXN0ZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkZWRkZGQ3YS0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Y29udGl2LW5ldG1hc3RlciJ9.0xBoLQkWH_KGiR84HZOHvV2iDWNJ9sHkE0NUoiwXjndak7ih8m-2o6b3AWbiX4wkD730-fJeMrIq-SXjUlw0jJkj_DuGaZkGU7rsxrqsTcueBg8ba3wgeS9RF8I5ptXP7ODod7y6ngQRUsC5QjKmQ__J0AUCpmDH6vEQsMzyfE6OY5f_tgTqTmShbIsRm_RRIqdhm_2wQHEVcFBZcgMPmwg2ZMTYIAbtJPvjuPwGnXTJkVPfqyHVytCiId1T3YSx8y6gHaqwdthNLi_4q9dlYxixDstaMJWOPvlOpjcTCl_OtWja2HpnSuIEikzuSKvIgRoDqCkjSQaq3vZ2L6q5Xg
ca.crt:     1025 bytes
namespace:  11 bytes


Name:         contiv-netplugin-token-xqsb5
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=contiv-netplugin
              kubernetes.io/service-account.uid=ded152da-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjb250aXYtbmV0cGx1Z2luLXRva2VuLXhxc2I1Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImNvbnRpdi1uZXRwbHVnaW4iLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkZWQxNTJkYS0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Y29udGl2LW5ldHBsdWdpbiJ9.dpsLSrMoUObjR8Gce4yuoa6YXqCjlYCP9FKkmBgkMDVn7HHzVnLFZfc4a9lNgXFPREbTPUZNeRAxHSbSjDNQVAuZJXGx7u7LuHQ0KdBY83LEcL4lb61imcVkV7th5nOLpYNhN1EougNZxmOWU5_QgDP4t7cmbCJGiIdhDc0mGD7O42BH4ImWo6PQdj0zxUTWv79ENUHFoOHoVyOcELhFWqs41AuE5yTOj9799URbqS5ApC5t2qV49M1-9AR6dW0D3jddtqgg8R68ogujek8vf2HbLkIhlZzDqy6AVwyQ63K-viQxT_LKUV-ZJ8HW_1eCXBvtJNnCjpgY9Bw32PwrmQ


Name:         cronjob-controller-token-brlcv
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=cronjob-controller
              kubernetes.io/service-account.uid=d8e8af79-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjcm9uam9iLWNvbnRyb2xsZXItdG9rZW4tYnJsY3YiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiY3JvbmpvYi1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDhlOGFmNzktMDkzMi0xMWU4LTk5NDAtMDgwMDI3NzU2MWY3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmNyb25qb2ItY29udHJvbGxlciJ9.1M621dP1T2yJn-C1UHqoxWtdJskZGsWz70mFVLVE76AnB6pT1l6_PBgOUPaRVE931g5zHt8Q0nUNJHJtSzDoYKjLWNbzDjE2nhl5GUqpAyDclRaqaP8z0NP5oFc9SU80IeJsm_l5e9BCPWj1AKIsoKD2k9B5wofkB7OcEn3KHZg5SNJgMEGgettB7XC5LGUivzjU6_7nBNE_m88Rsz6dSXTIZDgdaL9pXkvG9ZxasmBSXtdMgNYFEvxAqCC9bn3nTbFlwC4ushaH3mchMbR70FrdDnUyn9LbSfcAzMzVoQeTIQyq9tWfhlNoSEHeInyP2itgqtDRpvJaDcmYmntTmw


Name:         daemon-set-controller-token-hzfb5
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=daemon-set-controller
              kubernetes.io/service-account.uid=d58ecf4f-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYWVtb24tc2V0LWNvbnRyb2xsZXItdG9rZW4taHpmYjUiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFlbW9uLXNldC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDU4ZWNmNGYtMDkzMi0xMWU4LTk5NDAtMDgwMDI3NzU2MWY3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhZW1vbi1zZXQtY29udHJvbGxlciJ9.GxHR1W1pS4gBsgwLlAqDBSHCBMH-qaPqgZ1hATNCYkRf28RTgA5yd49BVbg0ftqHVWH9kXAgvl0MKYe03P7QhPEHPhOgqiJEmXklBxUOzA_NYveQFDwAtAuxMCz8a16fKfG16Td04kFr5yJoCyfP0Ei0U2hBvbBcrCIqkpVy-8alSa592wCvArWenBZPoUGXOPAFx5bBoKWwFtsurRmfiCbdMLnorxW4rh8zdxKpVbwMH4YVo1PYE0kf7WDzB28YhqQzvW791vEwaZZBX-oSMt49TR9YHusljxJkb8NO62QxlboPDjZc3NzWE1EVZJnkD5RY69DQcHtTLG5kRDNStw


Name:         default-token-9ktff
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=default
              kubernetes.io/service-account.uid=d9275c4a-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZWZhdWx0LXRva2VuLTlrdGZmIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImRlZmF1bHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkOTI3NWM0YS0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06ZGVmYXVsdCJ9.RMDJxLbyjLSEutVkI1g8qiF8kmwC3x1NqZ7kZ6hHfD5839rcIEQQM2OYUI7E0fVATxYANfGFU6On0O20yDH8E-Td-5uUCLvWU7dow69jHpfhHmJQFCYQQnXfean-I3SFypjfxaHVggMTu_Zz_MnhZ5dzaodNAmDWi9kF_igfWJzNnLwG3vrryMGFw8qpRjKLWKO_rgLtvahNjES6NBPn-9pdQQk0vFje5-yZWcF-iDftX2A2qs0NscdIZRhjkYe_NiqIqE0sTnUtP4HcDNCdaf2k-7GFeRuTZd999t2mlVJsISjtxXOL3MbhlToTfevL8UitbqteNSdY4UVgnITqIA


Name:         deployment-controller-token-fvd4k
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=deployment-controller
              kubernetes.io/service-account.uid=d59e1de6-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZXBsb3ltZW50LWNvbnRyb2xsZXItdG9rZW4tZnZkNGsiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVwbG95bWVudC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDU5ZTFkZTYtMDkzMi0xMWU4LTk5NDAtMDgwMDI3NzU2MWY3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRlcGxveW1lbnQtY29udHJvbGxlciJ9.KOTiyV5LZJC2MqSJBjZLCwhFdC_Kts4CkzcIwY4xLPMvxpC5hcqYUxE2O5EkeQyAMELz6sl_yh100f7gBR9S0zGxDyTH1B68jURdURgmskBYM9huxp2AC6I5kl8nHkpdPk5rfrMs2IvmnaNpjrUnvJnpaeUaF4jtZIKgLviK8ofTnwSFehHZPkTmoeHpnRt99_8hjdkwtVZbiMv5TTFFZcxEsForTvpw2NFkHALtXVJ1hkyhGT6qanhgZY9wyut82fGYPXHROcMG1rC1isREvEjk3g-9MXOg0nZtDKKSMvgfxGihTS8pZ2jlWiVKD59C4NDGhZL21xYJ27u3BXg7nQ
ca.crt:     1025 bytes


Name:         disruption-controller-token-lkrtn
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=disruption-controller
              kubernetes.io/service-account.uid=d8d2a032-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkaXNydXB0aW9uLWNvbnRyb2xsZXItdG9rZW4tbGtydG4iLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGlzcnVwdGlvbi1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDhkMmEwMzItMDkzMi0xMWU4LTk5NDAtMDgwMDI3NzU2MWY3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRpc3J1cHRpb24tY29udHJvbGxlciJ9.BEMp80xY5iCLwDSMn2Vm_Q7JnQ5Kc4h15s9RM3BEU1VPMEhE2sPBV1SXaj3O8Lmm_fbPawENwhWiEUSv5HsXZW9DB48wUvhEhaly_7qWwo4T1oZ1RHueESKEqOHFXNh5ZvKj3QKEtHoeVd787e1WPh8OY2nWKqSUOmqnF6DhRIWilTiWw1yzTeZpmMl8aWO0VEGlSQ4se9u-hofP_Xx7kwAWBA2-Gd0pIK_OmoU4BLUsrKlW7FaaIecqzLPA-aBZmm9XU5IUuuH27w8VBzZOL0tVjUeP2Zmlj6BJNFibHRrF2DfdYA69BxngPuYsHaTbDWzn8_E7l1KAIZAFVnG6AA


Name:         endpoint-controller-token-gsdzq
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=endpoint-controller
              kubernetes.io/service-account.uid=d67393ad-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJlbmRwb2ludC1jb250cm9sbGVyLXRva2VuLWdzZHpxIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImVuZHBvaW50LWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkNjczOTNhZC0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06ZW5kcG9pbnQtY29udHJvbGxlciJ9.f7Z_fdvXRwK72t0o1OCBheYBgI90u9HTR_FqsFrcN8RZAv9eqdCcnCsGjiQ3UcktDJBYcYD4B4zXDn_wr9p8JpO3GrL61IRYGVqy-hkBtgwJWFBcpIYvRtSVDuQ2UFkx7hl3IZXebD0BTZ204WQtDBYtd4PNzjp-y3OabgvNM9vYtpV5EvfrQqvqAaEUWjVMKo8DMnmR3jm4xvRZPhDtK01soh5kNieNMHMLCmKoXy0NWDKyB9_2ZVXynifNsu62C0HzFbuFofbo8EBcfur2KsJFm2o2WqKrdIL1t9PfmJGQQb4hoxCXfJDPLjR6UxPsafvQ9QaBoGBAKqk0dndWOA


Name:         generic-garbage-collector-token-9tfjt
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=generic-garbage-collector
              kubernetes.io/service-account.uid=d80a4660-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJnZW5lcmljLWdhcmJhZ2UtY29sbGVjdG9yLXRva2VuLTl0Zmp0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImdlbmVyaWMtZ2FyYmFnZS1jb2xsZWN0b3IiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkODBhNDY2MC0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Z2VuZXJpYy1nYXJiYWdlLWNvbGxlY3RvciJ9.BClqoXSALl5PrJYXwBvAfElQRJZguhlX_nGJeSkvycKtupUPS32Te2tPqhwdTHhoFA_0PyaiFUgknqNClMAhhWl78MoNSkkqwSBGwK6SJUbGHh24jLhBmRusO_k2Fo7ot4uVle2swW0CgtLd3qhyZvWwZ8e7M-ueQ_UKH53k26x6M1wlQMQQYj0TlwX5J0NWOz-NlOPmuD984JNDovcNJFw5v71jR-jLBdMG2aO_MCytHexbVpuJBM34Hfdm6RUHIYx5OtBKSxIvtyjVpXvcyldLQvXGxHrtgJnq7queJf10Ax2BZUXPKYs3VwZzTwKnTo2ZWa66kT062SlpLUInZQ
ca.crt:     1025 bytes
namespace:  11 bytes


Name:         horizontal-pod-autoscaler-token-rgs5t
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=horizontal-pod-autoscaler
              kubernetes.io/service-account.uid=d68f2812-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJob3Jpem9udGFsLXBvZC1hdXRvc2NhbGVyLXRva2VuLXJnczV0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6Imhvcml6b250YWwtcG9kLWF1dG9zY2FsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkNjhmMjgxMi0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06aG9yaXpvbnRhbC1wb2QtYXV0b3NjYWxlciJ9.TQy6Fkgt8PFz6rmRFYwrfIPArb26rI_HSPZgF72ApM8BvhdHGTtv4zgtY7CII_PekpBztoRkmK5fzUgaJIUPFHtBlTWELtQQPTHYlDkxRBKlmAP9PhnnfXl8z4UDoF6JW7r-tDDJ73KbDISaJ08uzHA4Ecj9SEk9SgNmKSEeU4Tm1Hg1F1EXqUF7viQpWmSLOZftc9EUbrFFyaLIDLvNrroYBpQ5cl0TqUvILCG5_xhP1ehVix3sNXeqsLNU0gfKc9y2UhfyqFAVY1wGTAfTS7L7jz7x9ibGZtGJzVfGhbE5NRoEZ6pDRcTv9F5-QyEcTFhkzJKsqHRsMvI_Kb1b-w


Name:         job-controller-token-l2pqw
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=job-controller
              kubernetes.io/service-account.uid=d5bed68d-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJqb2ItY29udHJvbGxlci10b2tlbi1sMnBxdyIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJqb2ItY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImQ1YmVkNjhkLTA5MzItMTFlOC05OTQwLTA4MDAyNzc1NjFmNyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTpqb2ItY29udHJvbGxlciJ9.LJs8ofJGE7dzgDx6HKRxEBk25cyssf2Wz1ZGmRaSbkIbEOuk6LiYGaTG4BHsMKHjuVjS_OW8gbduVY3Gecg528TsWOyNOow6_q8QLrdmJu42SUtDY8gfmoAS74sEuFhBQTAIHXimz2QS0lCU9bkKQkk5QihRc_BEWI0OvZbUkt3Y9H19PVvBb0OzDFYp23MfnrLqUDoKpiFMqKf6YvSB0_e5Tqg7bJcBNeEuOcXulILOWTVXe4TCttQonXTmlMqUsisybki1buijzs7L8yMMkDEIR0cvahqzIdFSr-JgagMQRJ8qtba0XSBDXIxeJAMhmAOWiL7GyQBsovzLDlH77Q
ca.crt:     1025 bytes
namespace:  11 bytes


Name:         kube-proxy-token-wmgjk
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=kube-proxy
              kubernetes.io/service-account.uid=d6105852-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlLXByb3h5LXRva2VuLXdtZ2prIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6Imt1YmUtcHJveHkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkNjEwNTg1Mi0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06a3ViZS1wcm94eSJ9.nfNrrCnwJ1WobvcAYwmjI2xONeYeIM4lKA6dNpKYLeBSVdUjZHjn6UV2XuNY-QVK2GJTCGfVpeZikogTdbwjDusP_B_Fh_qSW15utW2vWEYevWbbt3NWVf8HQH5P-MTKA-xrj_6iVk720DV7dhlwnOR-zmL0EUIAneU_PMbyD17s-fxlHRo5oFRu90A1j46IfmoqZvvMQ7KW5quti4tnzJrX_tsB7h5GLHHgoO6qyCi7psvGCBHZSlRAb9zI7ndEEcVlXEfcTTjcrf8Cx5b6WoeZ1yY1vDxD0L4pBQyOaaBjBfotnofWMOtc2j9iARIvqwpwqS8YC-jcHjDbkiIWRw
ca.crt:     1025 bytes


Name:         namespace-controller-token-z9r52
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=namespace-controller
              kubernetes.io/service-account.uid=d56fd7df-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJuYW1lc3BhY2UtY29udHJvbGxlci10b2tlbi16OXI1MiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJuYW1lc3BhY2UtY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImQ1NmZkN2RmLTA5MzItMTFlOC05OTQwLTA4MDAyNzc1NjFmNyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTpuYW1lc3BhY2UtY29udHJvbGxlciJ9.KsMO4xLmU86lGh86KqpRyGLqKQ5fo8LMaNJg3C_aVC5yZPjTLzu_-m_IpOeWdxnc2iD9-LxFxrpWoeavyTHpLwCs7NwH4j1CAz4dru6rdT2NDV0C2DfN_YlEL1JSI1yqVlSB4Iv8SnSP0cKDVep6s6nTqMUgkOQG-b5-7eaaE9WBA9MHbfRf5u4kVacsxiO4NKLUFGlb2WNJrgZJO8rVDzH--u9hW6SYVjwwTEL5EEBQ79CLutARE6MqZ0JPduA2FJYAzn5vP5WrIeeRReyw-x6fflapySGTa5dw2C9IKQL77rIBdA2EbvIgCQv1xi-uwBMh2ragrTAJPKcxp5KuBw


Name:         node-controller-token-7d5zm
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=node-controller
              kubernetes.io/service-account.uid=d782a3d9-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJub2RlLWNvbnRyb2xsZXItdG9rZW4tN2Q1em0iLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoibm9kZS1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDc4MmEzZDktMDkzMi0xMWU4LTk5NDAtMDgwMDI3NzU2MWY3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOm5vZGUtY29udHJvbGxlciJ9.dExVp0pbj3S-32fINuaqbmB_ORG2DCupO-bWaH7-AgwJPhxhL-pK6xjO4bP3Jac-WmRGMQB_Zr4UwAotEdFqZIZS6WM5Rf6Q-fz1yVUL7uG2nDg6BXF364YDJVNij98HHKYmBRNREZQCbODumaNCcC7lggTmeilVue_fwPqJTmeW8rrVqkyMQ5b0PEBGEDtWihDH7fvZ6yldfAMuOHYW523scPtjjpxYgOn3dA_63RW-RDOMq-D6AvKXMNQHX4h_cAvKytH0l7VjeqvONZchY0sAJE9bf0Xes3LRAl7p-7bJFTmdpK-2pNMKqi7GzLW9VoStwC0u2mwfk-qbdUKc3w
ca.crt:     1025 bytes


Name:         persistent-volume-binder-token-8tbq2
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=persistent-volume-binder
              kubernetes.io/service-account.uid=d6ba806d-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJwZXJzaXN0ZW50LXZvbHVtZS1iaW5kZXItdG9rZW4tOHRicTIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicGVyc2lzdGVudC12b2x1bWUtYmluZGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDZiYTgwNmQtMDkzMi0xMWU4LTk5NDAtMDgwMDI3NzU2MWY3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnBlcnNpc3RlbnQtdm9sdW1lLWJpbmRlciJ9.p5WzHt3YcMc-6JKkPQGtV2MmU6CbcoL6G84_bhhsoCHcIm2fXxDRAqXaJH3ph0MvZvroeYyRVQE_ZfcddvJZSzRbgTSqrl1A7tUyg_QJqG-mzFBeZWmv2aNKwuiRr9KEhuNpVbbxpCn11_R_GdvxA1RHdfIHqLrv0QM2qYeMo4RJOtpme3U7w11MsmeIF5tIWgRl2OTq1qtJefX_k2fuuoX6CwGxxyzAWGfdF1It47FDl5ds4xSSI1V7X-FnZOh_pd3Qnms61jFI4vQjLhlKtWpeFvwye-iuCwgsy37BUaQNgvyAB4mIi6XUYuzSEx0Jnzwn7jM7pIUiroQmLvm8Wg


Name:         pod-garbage-collector-token-7twr4
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=pod-garbage-collector
              kubernetes.io/service-account.uid=d709b34a-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJwb2QtZ2FyYmFnZS1jb2xsZWN0b3ItdG9rZW4tN3R3cjQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicG9kLWdhcmJhZ2UtY29sbGVjdG9yIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDcwOWIzNGEtMDkzMi0xMWU4LTk5NDAtMDgwMDI3NzU2MWY3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnBvZC1nYXJiYWdlLWNvbGxlY3RvciJ9.MhQYglFwSPF73Rq-FzWA7m6vsbRi5jseaDQHbCiaBSm4XtsLw7KHGn35enfj2kSPBN84W_ITm-Sc2o1NEnXMuWTgt48CtRuwI0yZ0quH3gwPdM-EHtfQBA7kKHD6_7r1Aa8s4FC0wdVgX06bjeEQ6AQUCWvUcPOZpMFqv74ltvHU6fXPq8B4nLVzneh2cPs0lLeYWrnfKAwAitONc8IUq3B6xD2oz_Smvtz1WESaXd6pgT_jBVRkLewwyZmL6QQe-Mj-LphT7qBWGSx_9pXJ4ZqSW6cHLVOA6IVqw9XsDIqSNCwFc7waxieOzfHDo0X30bbf2hOULP0Ef5ca7UQ94A


Name:         replicaset-controller-token-8whxt
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=replicaset-controller
              kubernetes.io/service-account.uid=d61537ae-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJyZXBsaWNhc2V0LWNvbnRyb2xsZXItdG9rZW4tOHdoeHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicmVwbGljYXNldC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDYxNTM3YWUtMDkzMi0xMWU4LTk5NDAtMDgwMDI3NzU2MWY3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnJlcGxpY2FzZXQtY29udHJvbGxlciJ9.OY2dwWVtzqCrOpg002yA94PPpku7sQPaUVJ-ad3mfDq7CTnrOwhjK5b6QYPRyZQiySNKEMc93SkOM-yZbfCnybiIAwMDZq5gtMo1PO-9ab6QW7Ad_H3O0qUzIeNzfggoKkV7joOcj019AfaQ5VljWjF4TtQ98BmqiJ9K25Hh4-Yv8a5N0NpVvi0Zv-kMPgO4dxgJ7gufFToyAb3ZQY8TBRTwVgbfMYm4vqyNs4hDcGH1KdGcCRB70g6qW5mYfXLF9ZA0vP1Lmh97wq_e-caCTVE8ZeEwcFnpJlIFEAH44gHuAOLtpp517E3ptRp4Bw4eZbV9-evTdHNxSgihUQeTlg


Name:         replication-controller-token-dlvxb
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=replication-controller
              kubernetes.io/service-account.uid=d5fa3dc7-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJyZXBsaWNhdGlvbi1jb250cm9sbGVyLXRva2VuLWRsdnhiIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6InJlcGxpY2F0aW9uLWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkNWZhM2RjNy0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06cmVwbGljYXRpb24tY29udHJvbGxlciJ9.iQPdOcFA0JYNKG1M8ZDV2f-A6oHoRM2gbvFBnBlB18XeM_ONNMxldgb_jRKmpE49npOI6UoZVsySJdSlPBGjEpU0W_7ef5kZK481_pmEvZCHSjhnJUUbjffk1YTe1bmvAm4JXi3UbSy2oBvNDkPEeehd8VtvWBXMYXkW3pemRmSE4ihCVfvJpjMBVlJr_W7DtZOETctb8Tx_EH4ojpujj_48aM6dQOJvUFAA6HsjZVAFnhTEu0DqRGYn7yNO-a5_T3n4fn4pNQOMLr8eAryU5nvLNryLeIGe4xVBOsa_f_qORwzPlkBHwkcxROntsIBLMYkEWCWiIMrw5B9pra8g6w
ca.crt:     1025 bytes


Name:         resourcequota-controller-token-blqxz
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=resourcequota-controller
              kubernetes.io/service-account.uid=d749edce-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJyZXNvdXJjZXF1b3RhLWNvbnRyb2xsZXItdG9rZW4tYmxxeHoiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicmVzb3VyY2VxdW90YS1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDc0OWVkY2UtMDkzMi0xMWU4LTk5NDAtMDgwMDI3NzU2MWY3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnJlc291cmNlcXVvdGEtY29udHJvbGxlciJ9.x2PhmgN5tAtVZXKBOgsiblOJyiET2dPb8jlsD29-lCtUZQtBnpSkWQm6YsH0B7xS7rFch4qP49qhkNh0ejneOAKk9d5edHM244vE-PscQLA6iGOySjMuKHVyNrW65_vOkPxZx8XDW3J88flGG-wa7fn25CNNQ5PfSZaZxWqYz1c2-yYki49rPKR4b3PD9hgoBeyq6QEAq-V14FWK1SZnO0bUGviszE-T7irmM5YmNH1nQ5zKTsZdiDGeugno9XLVcWvta_fG52mP_tthKA2nlsfyw_KWvUuWWPi__olXdLlqJE5JbvNI4TjBD9GAoFwHk-rmYuvg70jq9zmlrySq0g


Name:         service-account-controller-token-pb4fp
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=service-account-controller
              kubernetes.io/service-account.uid=d7d68b54-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJzZXJ2aWNlLWFjY291bnQtY29udHJvbGxlci10b2tlbi1wYjRmcCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJzZXJ2aWNlLWFjY291bnQtY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImQ3ZDY4YjU0LTA5MzItMTFlOC05OTQwLTA4MDAyNzc1NjFmNyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTpzZXJ2aWNlLWFjY291bnQtY29udHJvbGxlciJ9.0O2J_I7S3-NPb906MYPNMR0hzoUnYxn6s1Ju6UiHWQjuNgSCtkHJZHhzLPlTBMs4JwZDy3uVsBVyMdDUXYFIJLV4AfAPilpX-QTnBJRGB4aVPxDgQXHXmeKEnn91VJ6Xn3_uepuzsMszIe4ocG3_yHF4mXCQU7wHrkPOy5vlOpq33mX1gYmF_G0ITBPtHCaa0gsLmxooys2Mb9olrO8l_2HFfLCwq_rxHtQKKmXW7zpcqKrwKzjJp1PZt-eRA2RWh3Fxl1NUuUYVmwHzuY-juFk5OYsE_cn7akb_D27NDh59yO784BIK2Vwg0RhuEwUslkxEyjiCG2G8n52-RdzkJQ


Name:         service-controller-token-gfn6t
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=service-controller
              kubernetes.io/service-account.uid=d5dd2e50-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJzZXJ2aWNlLWNvbnRyb2xsZXItdG9rZW4tZ2ZuNnQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoic2VydmljZS1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDVkZDJlNTAtMDkzMi0xMWU4LTk5NDAtMDgwMDI3NzU2MWY3Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnNlcnZpY2UtY29udHJvbGxlciJ9.rK4QWbRbm442gXH0AKgirFi4IJ3Y4n8mXeuT5a5w-w1o8aRsybHOqO90MQAGOpneyIeRv7FLx02UwKEEx_jeOVtXjBc-toFSoPSfp39hcvbxfb7ZCmE34cIWQbw7tzNDCLQTvnQCmmwyF85XeaETCqkwQeOKgohgCB42yKoN2SZ89xnJyz_ZhAJayhwH5jgiaTliYoJaC2BVfEiI8j8dAclRctIGzz2PZBQxXBSkJuXSDRbbs6am3OfOCnRZTr0Id7SAnByyOpJQkhWskK2Ks3ctTh78dHPQhOmH-xSo2VZO_aZU964-B-LPSzlvlWP6r8DsUSXw7EkE6ZrDF4CZ3Q


Name:         statefulset-controller-token-4zzvr
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=statefulset-controller
              kubernetes.io/service-account.uid=d5acf452-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJzdGF0ZWZ1bHNldC1jb250cm9sbGVyLXRva2VuLTR6enZyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6InN0YXRlZnVsc2V0LWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkNWFjZjQ1Mi0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06c3RhdGVmdWxzZXQtY29udHJvbGxlciJ9.1_VJh4tKRI5H34u5LnDLMVqKpEwXXJqXCQJRoV2hg8VDK8pcie8hsCFHff74Te3HjdOrF8ld1lF70SDNouVsVHFy4p8AsdBMqliVamDVtypNOsG5--54fz_5N0UKBdozayvrREasHPm_CO3uNJRrJOGaSpfKqFHrX-GD7jovViW8IiuXxXaS7QqCxVwyWrm0Ngexs-S9Qs-5Yqrf8_IhN7UVqhsalIR9V-4veLQrsXH5KAGUTeo7Fg0MBjqeOG1hCsHEdRwsq6C-b3uod7-BKNCtsdXFsT_IE9U7s-loSlPrVIYhvdHLEzoLo3Kv2UTsDFtkr0LEl4gZtxvZH_cfrg


Name:         token-cleaner-token-n6zmf
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=token-cleaner
              kubernetes.io/service-account.uid=d5567611-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJ0b2tlbi1jbGVhbmVyLXRva2VuLW42em1mIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6InRva2VuLWNsZWFuZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkNTU2NzYxMS0wOTMyLTExZTgtOTk0MC0wODAwMjc3NTYxZjciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06dG9rZW4tY2xlYW5lciJ9.GIgpzd3jUeXKjd4EGWJ4rQUF3D8s_eBYbI77OnsUwgpoGTJjRPZi5ly7Y11gksz1kS5xdpeZ20fPclgqjXmuHEuYtDlCY03VfYQILqpb3_m1zZY6RUs7QecHstdf3UrOnw9RsjzVYvK4VceiVORQuri3MO08CTLlhyd0hWEcUkxAyFjt_sIG5sNNAkl4fnMZaMAssmfPIt_Pf42_VNr0NaogO2r187NF4EMLPdom6KvYxC2HgYSta-QXJX8yVkANkk5ldD3qihnZFmaz1en6Allj2wlLCcE2Cp17Utv9RdW239c8xMq9moy7itLgflKQqNxCBntyUzmZJYZl5YyyVQ
ca.crt:     1025 bytes
namespace:  11 bytes


Name:         ttl-controller-token-26zh6
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=ttl-controller
              kubernetes.io/service-account.uid=d9016c64-0932-11e8-9940-0800277561f7

Type:  kubernetes.io/service-account-token

Data
====
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJ0dGwtY29udHJvbGxlci10b2tlbi0yNnpoNiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJ0dGwtY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImQ5MDE2YzY0LTA5MzItMTFlOC05OTQwLTA4MDAyNzc1NjFmNyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTp0dGwtY29udHJvbGxlciJ9.UCLTObWldwuri1JQlIVwAXwqI7bjU5GtOzHW8h52B0V1h4H1b34t97JAEB-1mRx5CRh-5dPWU-65WLWZCu48UFacC48ofeDp2DuPRiiPSHzML6ED326U2yneZzo1ouUzx1XIzl2aM5rePGwMdRmj_ISFG_Ma0l7lDy3Ng0QgXsva34e1PLBqOmRU1jVTkuVO24UT_BApItP_HHhXv7Q4aLZPgZDB2DMSdYnaTSa0evaAl2Kd1vqVlmUM5KYkmvcKkCtPGcJd6YYfyTA7BSi7oiLRuSIAt2r0fJQc_eI4-kW62MvTH26WfjJJibMn9wHaroAkZuGcahS9i_EL9uzm7A
ca.crt:     1025 bytes
\n================
kubectl describe serviceaccounts --all-namespaces
================\n
Name:                default
Namespace:           default
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   default-token-d5kpb
Tokens:              default-token-d5kpb
Events:              <none>


Name:                default
Namespace:           kube-public
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   default-token-qhfnm
Tokens:              default-token-qhfnm
Events:              <none>


Name:                attachdetach-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   attachdetach-controller-token-76zkt
Tokens:              attachdetach-controller-token-76zkt
Events:              <none>


Name:                bootstrap-signer
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   bootstrap-signer-token-2pkhf
Tokens:              bootstrap-signer-token-2pkhf
Events:              <none>


Name:                certificate-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   certificate-controller-token-bwh4d
Tokens:              certificate-controller-token-bwh4d
Events:              <none>


Name:                clusterrole-aggregation-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   clusterrole-aggregation-controller-token-tbk9h
Tokens:              clusterrole-aggregation-controller-token-tbk9h
Events:              <none>


Name:                contiv-netmaster
Namespace:           kube-system
Labels:              kubernetes.io/cluster-service=true
Annotations:         kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"kubernetes.io/cluster-service":"true"},"name":"contiv-netmaster","na...
Image pull secrets:  <none>
Mountable secrets:   contiv-netmaster-token-47bxd
Tokens:              contiv-netmaster-token-47bxd
Events:              <none>


Name:                contiv-netplugin
Namespace:           kube-system
Labels:              kubernetes.io/cluster-service=true
Annotations:         kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"kubernetes.io/cluster-service":"true"},"name":"contiv-netplugin","na...
Image pull secrets:  <none>
Mountable secrets:   contiv-netplugin-token-xqsb5
Tokens:              contiv-netplugin-token-xqsb5
Events:              <none>


Name:                cronjob-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   cronjob-controller-token-brlcv
Tokens:              cronjob-controller-token-brlcv
Events:              <none>


Name:                daemon-set-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   daemon-set-controller-token-hzfb5
Tokens:              daemon-set-controller-token-hzfb5
Events:              <none>


Name:                default
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   default-token-9ktff
Tokens:              default-token-9ktff
Events:              <none>


Name:                deployment-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   deployment-controller-token-fvd4k
Tokens:              deployment-controller-token-fvd4k
Events:              <none>


Name:                disruption-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   disruption-controller-token-lkrtn
Tokens:              disruption-controller-token-lkrtn
Events:              <none>


Name:                endpoint-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   endpoint-controller-token-gsdzq
Tokens:              endpoint-controller-token-gsdzq
Events:              <none>


Name:                generic-garbage-collector
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   generic-garbage-collector-token-9tfjt
Tokens:              generic-garbage-collector-token-9tfjt
Events:              <none>


Name:                horizontal-pod-autoscaler
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   horizontal-pod-autoscaler-token-rgs5t
Tokens:              horizontal-pod-autoscaler-token-rgs5t
Events:              <none>


Name:                job-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   job-controller-token-l2pqw
Tokens:              job-controller-token-l2pqw
Events:              <none>


Name:                kube-proxy
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   kube-proxy-token-wmgjk
Tokens:              kube-proxy-token-wmgjk
Events:              <none>


Name:                namespace-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   namespace-controller-token-z9r52
Tokens:              namespace-controller-token-z9r52
Events:              <none>


Name:                node-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   node-controller-token-7d5zm
Tokens:              node-controller-token-7d5zm
Events:              <none>


Name:                persistent-volume-binder
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   persistent-volume-binder-token-8tbq2
Tokens:              persistent-volume-binder-token-8tbq2
Events:              <none>


Name:                pod-garbage-collector
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   pod-garbage-collector-token-7twr4
Tokens:              pod-garbage-collector-token-7twr4
Events:              <none>


Name:                replicaset-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   replicaset-controller-token-8whxt
Tokens:              replicaset-controller-token-8whxt
Events:              <none>


Name:                replication-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   replication-controller-token-dlvxb
Tokens:              replication-controller-token-dlvxb
Events:              <none>


Name:                resourcequota-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   resourcequota-controller-token-blqxz
Tokens:              resourcequota-controller-token-blqxz
Events:              <none>


Name:                service-account-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   service-account-controller-token-pb4fp
Tokens:              service-account-controller-token-pb4fp
Events:              <none>


Name:                service-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   service-controller-token-gfn6t
Tokens:              service-controller-token-gfn6t
Events:              <none>


Name:                statefulset-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   statefulset-controller-token-4zzvr
Tokens:              statefulset-controller-token-4zzvr
Events:              <none>


Name:                token-cleaner
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   token-cleaner-token-n6zmf
Tokens:              token-cleaner-token-n6zmf
Events:              <none>


Name:                ttl-controller
Namespace:           kube-system
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   ttl-controller-token-26zh6
Tokens:              ttl-controller-token-26zh6
Events:              <none>
\n================
kubectl describe services --all-namespaces
================\n
Name:              kubernetes
Namespace:         default
Labels:            component=apiserver
                   provider=kubernetes
Annotations:       <none>
Selector:          <none>
Type:              ClusterIP
IP:                10.96.0.1
Port:              https  443/TCP
TargetPort:        6443/TCP
Endpoints:         192.168.2.10:6443
Session Affinity:  ClientIP
Events:            <none>


Name:              contiv-etcd
Namespace:         kube-system
Labels:            k8s-app=contiv-etcd
Annotations:       kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":"kube-system"},"sp...
Selector:          k8s-app=contiv-etcd
Type:              ClusterIP
IP:                10.96.232.136
Port:              <unset>  6666/TCP
TargetPort:        6666/TCP
Endpoints:         192.168.2.10:6666
Session Affinity:  None
Events:            <none>
\n================
kubectl describe statefulsets --all-namespaces
================\n
\n================
kubectl describe kubectl --all-namespaces && echo ================n && kubectl describe kubectl --all-namespaces
\n================
kubectl get all --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":"kube-system"},"spec":{"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-etcd"}},"spec":{"containers":[{"args":["ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd"],"command":["/bin/sh","-c"],"env":[{"name":"CONTIV_ETCD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"ETCD_NAME","value":"contiv-etcd"},{"name":"ETCD_DATA_DIR","value":"/var/lib/etcd/contiv-data"},{"name":"ETCD_LISTEN_CLIENT_URLS","value":"http://0.0.0.0:6666"},{"name":"ETCD_LISTEN_PEER_URLS","value":"http://0.0.0.0:6667"}],"image":"quay.io/coreos/etcd:v3.2.4","name":"contiv-etcd","volumeMounts":[{"mountPath":"/var/etcd","name":"var-etcd"}]}],"hostNetwork":true,"nodeSelector":{"node-role.kubernetes.io/master":""},"tolerations":[{"effect":"NoSchedule","key":"node.cloudprovider.kubernetes.io/uninitialized","value":"true"},{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"},{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/etcd"},"name":"var-etcd"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    generation: 1
    labels:
      k8s-app: contiv-etcd
    name: contiv-etcd
    namespace: kube-system
    resourceVersion: "558"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/contiv-etcd
    uid: df32d0df-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: contiv-etcd
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-etcd
      spec:
        containers:
        - args:
          - ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
          command:
          - /bin/sh
          - -c
          env:
          - name: CONTIV_ETCD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: ETCD_NAME
            value: contiv-etcd
          - name: ETCD_DATA_DIR
            value: /var/lib/etcd/contiv-data
          - name: ETCD_LISTEN_CLIENT_URLS
            value: http://0.0.0.0:6666
          - name: ETCD_LISTEN_PEER_URLS
            value: http://0.0.0.0:6667
          image: quay.io/coreos/etcd:v3.2.4
          imagePullPolicy: IfNotPresent
          name: contiv-etcd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/etcd
            name: var-etcd
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          node-role.kubernetes.io/master: ""
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node.cloudprovider.kubernetes.io/uninitialized
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /var/etcd
            type: ""
          name: var-etcd
    templateGeneration: 1
    updateStrategy:
      type: OnDelete
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netplugin"},"name":"contiv-netplugin","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"contiv-netplugin"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-netplugin"}},"spec":{"containers":[{"command":["tail","-f","/dev/null"],"env":[{"name":"CONTIV_ROLE","value":"netplugin"},{"name":"CONTIV_NETPLUGIN_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_NETPLUGIN_VTEP_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"CONTIV_NETPLUGIN_FORWARD_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_fwdmode","name":"contiv-config"}}},{"name":"CONTIV_NETPLUGIN_NET_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_netmode","name":"contiv-config"}}}],"image":"contiv/netplugin:latest","name":"contiv-netplugin","resources":{"requests":{"cpu":"250m"}},"securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/var/run","name":"var-run","readOnly":false},{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/contiv/bin","name":"contiv-bin-dir","readOnly":true},{"mountPath":"/contiv/scripts/","name":"contiv-scripts-dir","readOnly":true},{"mountPath":"/var/log/contiv","name":"contiv-log-dir","readOnly":false}]}],"hostNetwork":true,"hostPID":true,"initContainers":[{"env":[{"name":"CONTIV_ROLE","value":"netplugin"},{"name":"CONTIV_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_K8S_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_k8s_config","name":"contiv-config"}}},{"name":"CONTIV_CNI_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_cni_config","name":"contiv-config"}}}],"image":"contiv/netplugin-init:latest","name":"contiv-netplugin-init","volumeMounts":[{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/etc/cni/net.d/","name":"etc-cni-dir","readOnly":false}]},{"command":["cp","/contiv/bin/contivk8s","/opt/cni/bin/contivk8s"],"image":"contiv/netplugin:latest","name":"contiv-cni","volumeMounts":[{"mountPath":"/opt/cni/bin","name":"cni-bin-dir","readOnly":false}]}],"serviceAccountName":"contiv-netplugin","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/var/run"},"name":"var-run"},{"hostPath":{"path":"/var/contiv"},"name":"var-contiv"},{"hostPath":{"path":"/opt/cni/bin"},"name":"cni-bin-dir"},{"hostPath":{"path":"/etc/cni/net.d/"},"name":"etc-cni-dir"},{"hostPath":{"path":"/opt/gopath/bin"},"name":"contiv-bin-dir"},{"hostPath":{"path":"/opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/"},"name":"contiv-scripts-dir"},{"hostPath":{"path":"/var/log/contiv"},"name":"contiv-log-dir"}]}}}}
    creationTimestamp: 2018-02-03T22:37:52Z
    generation: 1
    labels:
      k8s-app: contiv-netplugin
    name: contiv-netplugin
    namespace: kube-system
    resourceVersion: "3182"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/contiv-netplugin
    uid: defd0ade-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: contiv-netplugin
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-netplugin
      spec:
        containers:
        - command:
          - tail
          - -f
          - /dev/null
          env:
          - name: CONTIV_ROLE
            value: netplugin
          - name: CONTIV_NETPLUGIN_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_NETPLUGIN_VTEP_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: CONTIV_NETPLUGIN_FORWARD_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_fwdmode
                name: contiv-config
          - name: CONTIV_NETPLUGIN_NET_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_netmode
                name: contiv-config
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-netplugin
          resources:
            requests:
              cpu: 250m
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/run
            name: var-run
          - mountPath: /var/contiv
            name: var-contiv
          - mountPath: /contiv/bin
            name: contiv-bin-dir
            readOnly: true
          - mountPath: /contiv/scripts/
            name: contiv-scripts-dir
            readOnly: true
          - mountPath: /var/log/contiv
            name: contiv-log-dir
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        initContainers:
        - env:
          - name: CONTIV_ROLE
            value: netplugin
          - name: CONTIV_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_K8S_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_k8s_config
                name: contiv-config
          - name: CONTIV_CNI_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_cni_config
                name: contiv-config
          image: contiv/netplugin-init:latest
          imagePullPolicy: Always
          name: contiv-netplugin-init
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/contiv
            name: var-contiv
          - mountPath: /etc/cni/net.d/
            name: etc-cni-dir
        - command:
          - cp
          - /contiv/bin/contivk8s
          - /opt/cni/bin/contivk8s
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-cni
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /opt/cni/bin
            name: cni-bin-dir
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: contiv-netplugin
        serviceAccountName: contiv-netplugin
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - hostPath:
            path: /var/run
            type: ""
          name: var-run
        - hostPath:
            path: /var/contiv
            type: ""
          name: var-contiv
        - hostPath:
            path: /opt/cni/bin
            type: ""
          name: cni-bin-dir
        - hostPath:
            path: /etc/cni/net.d/
            type: ""
          name: etc-cni-dir
        - hostPath:
            path: /opt/gopath/bin
            type: ""
          name: contiv-bin-dir
        - hostPath:
            path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
            type: ""
          name: contiv-scripts-dir
        - hostPath:
            path: /var/log/contiv
            type: ""
          name: contiv-log-dir
    templateGeneration: 1
    updateStrategy:
      type: OnDelete
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-ovs"},"name":"contiv-ovs","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"contiv-ovs"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-ovs"}},"spec":{"containers":[{"command":["/scripts/start-ovsdb-server.sh"],"image":"contiv/ovs:latest","name":"contiv-ovsdb-server","securityContext":{"privileged":false},"volumeMounts":[{"mountPath":"/etc/openvswitch","name":"etc-openvswitch","readOnly":false},{"mountPath":"/var/run","name":"var-run","readOnly":false}]},{"command":["/scripts/start-ovs-vswitchd.sh"],"image":"contiv/ovs:latest","name":"contiv-ovs-vswitchd","securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/etc/openvswitch","name":"etc-openvswitch","readOnly":false},{"mountPath":"/lib/modules","name":"lib-modules","readOnly":true},{"mountPath":"/var/run","name":"var-run","readOnly":false}]}],"hostNetwork":true,"hostPID":true,"tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/etc/openvswitch"},"name":"etc-openvswitch"},{"hostPath":{"path":"/lib/modules"},"name":"lib-modules"},{"hostPath":{"path":"/var/run"},"name":"var-run"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    generation: 1
    labels:
      k8s-app: contiv-ovs
    name: contiv-ovs
    namespace: kube-system
    resourceVersion: "3167"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/contiv-ovs
    uid: df7106fa-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: contiv-ovs
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-ovs
      spec:
        containers:
        - command:
          - /scripts/start-ovsdb-server.sh
          image: contiv/ovs:latest
          imagePullPolicy: Always
          name: contiv-ovsdb-server
          resources: {}
          securityContext:
            privileged: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/openvswitch
            name: etc-openvswitch
          - mountPath: /var/run
            name: var-run
        - command:
          - /scripts/start-ovs-vswitchd.sh
          image: contiv/ovs:latest
          imagePullPolicy: Always
          name: contiv-ovs-vswitchd
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/openvswitch
            name: etc-openvswitch
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
          - mountPath: /var/run
            name: var-run
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - hostPath:
            path: /etc/openvswitch
            type: ""
          name: etc-openvswitch
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
        - hostPath:
            path: /var/run
            type: ""
          name: var-run
    templateGeneration: 1
    updateStrategy:
      type: OnDelete
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    creationTimestamp: 2018-02-03T22:37:38Z
    generation: 1
    labels:
      k8s-app: kube-proxy
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "2970"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/kube-proxy
    uid: d61ef82d-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-proxy
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-proxy
      spec:
        containers:
        - command:
          - /usr/local/bin/kube-proxy
          - --config=/var/lib/kube-proxy/config.conf
          image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
          imagePullPolicy: IfNotPresent
          name: kube-proxy
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/kube-proxy
            name: kube-proxy
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-proxy
        serviceAccountName: kube-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - effect: NoSchedule
          key: node.cloudprovider.kubernetes.io/uninitialized
          value: "true"
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-proxy
          name: kube-proxy
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
    templateGeneration: 1
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"ReplicaSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netmaster"},"name":"contiv-netmaster","namespace":"kube-system"},"spec":{"replicas":1,"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-netmaster"},"name":"contiv-netmaster","namespace":"kube-system"},"spec":{"containers":[{"command":["tail","-f","/dev/null"],"env":[{"name":"CONTIV_ROLE","value":"netmaster"},{"name":"CONTIV_NETMASTER_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_NETMASTER_FORWARD_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_fwdmode","name":"contiv-config"}}},{"name":"CONTIV_NETMASTER_NET_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_netmode","name":"contiv-config"}}}],"image":"contiv/netplugin:latest","name":"contiv-netmaster","volumeMounts":[{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/contiv/bin","name":"contiv-bin-dir","readOnly":true},{"mountPath":"/contiv/scripts/","name":"contiv-scripts-dir","readOnly":true},{"mountPath":"/var/log/contiv","name":"contiv-log-dir","readOnly":false}]}],"hostNetwork":true,"initContainers":[{"env":[{"name":"CONTIV_ROLE","value":"netmaster"},{"name":"CONTIV_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_K8S_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_k8s_config","name":"contiv-config"}}},{"name":"CONTIV_CNI_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_cni_config","name":"contiv-config"}}}],"image":"contiv/netplugin-init:latest","name":"contiv-netplugin-init","volumeMounts":[{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false}]},{"command":["cp","/contiv/bin/netctl","/usr/local/sbin/netctl"],"image":"contiv/netplugin:latest","name":"contiv-netctl","volumeMounts":[{"mountPath":"/usr/local/sbin/","name":"usr-local-sbin","readOnly":false}]}],"nodeSelector":{"node-role.kubernetes.io/master":""},"serviceAccountName":"contiv-netmaster","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/var/contiv"},"name":"var-contiv"},{"hostPath":{"path":"/usr/local/sbin/"},"name":"usr-local-sbin"},{"hostPath":{"path":"/opt/gopath/bin"},"name":"contiv-bin-dir"},{"hostPath":{"path":"/opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/"},"name":"contiv-scripts-dir"},{"hostPath":{"path":"/var/log/contiv"},"name":"contiv-log-dir"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    generation: 1
    labels:
      k8s-app: contiv-netmaster
    name: contiv-netmaster
    namespace: kube-system
    resourceVersion: "777"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/contiv-netmaster
    uid: df1a16b8-0932-11e8-9940-0800277561f7
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: contiv-netmaster
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-netmaster
        name: contiv-netmaster
        namespace: kube-system
      spec:
        containers:
        - command:
          - tail
          - -f
          - /dev/null
          env:
          - name: CONTIV_ROLE
            value: netmaster
          - name: CONTIV_NETMASTER_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_NETMASTER_FORWARD_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_fwdmode
                name: contiv-config
          - name: CONTIV_NETMASTER_NET_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_netmode
                name: contiv-config
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-netmaster
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/contiv
            name: var-contiv
          - mountPath: /contiv/bin
            name: contiv-bin-dir
            readOnly: true
          - mountPath: /contiv/scripts/
            name: contiv-scripts-dir
            readOnly: true
          - mountPath: /var/log/contiv
            name: contiv-log-dir
        dnsPolicy: ClusterFirst
        hostNetwork: true
        initContainers:
        - env:
          - name: CONTIV_ROLE
            value: netmaster
          - name: CONTIV_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_K8S_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_k8s_config
                name: contiv-config
          - name: CONTIV_CNI_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_cni_config
                name: contiv-config
          image: contiv/netplugin-init:latest
          imagePullPolicy: Always
          name: contiv-netplugin-init
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/contiv
            name: var-contiv
        - command:
          - cp
          - /contiv/bin/netctl
          - /usr/local/sbin/netctl
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-netctl
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/sbin/
            name: usr-local-sbin
        nodeSelector:
          node-role.kubernetes.io/master: ""
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: contiv-netmaster
        serviceAccountName: contiv-netmaster
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - hostPath:
            path: /var/contiv
            type: ""
          name: var-contiv
        - hostPath:
            path: /usr/local/sbin/
            type: ""
          name: usr-local-sbin
        - hostPath:
            path: /opt/gopath/bin
            type: ""
          name: contiv-bin-dir
        - hostPath:
            path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
            type: ""
          name: contiv-scripts-dir
        - hostPath:
            path: /var/log/contiv
            type: ""
          name: contiv-log-dir
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":"kube-system"},"spec":{"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-etcd"}},"spec":{"containers":[{"args":["ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd"],"command":["/bin/sh","-c"],"env":[{"name":"CONTIV_ETCD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"ETCD_NAME","value":"contiv-etcd"},{"name":"ETCD_DATA_DIR","value":"/var/lib/etcd/contiv-data"},{"name":"ETCD_LISTEN_CLIENT_URLS","value":"http://0.0.0.0:6666"},{"name":"ETCD_LISTEN_PEER_URLS","value":"http://0.0.0.0:6667"}],"image":"quay.io/coreos/etcd:v3.2.4","name":"contiv-etcd","volumeMounts":[{"mountPath":"/var/etcd","name":"var-etcd"}]}],"hostNetwork":true,"nodeSelector":{"node-role.kubernetes.io/master":""},"tolerations":[{"effect":"NoSchedule","key":"node.cloudprovider.kubernetes.io/uninitialized","value":"true"},{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"},{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/etcd"},"name":"var-etcd"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    generation: 1
    labels:
      k8s-app: contiv-etcd
    name: contiv-etcd
    namespace: kube-system
    resourceVersion: "558"
    selfLink: /apis/apps/v1/namespaces/kube-system/daemonsets/contiv-etcd
    uid: df32d0df-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: contiv-etcd
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-etcd
      spec:
        containers:
        - args:
          - ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
          command:
          - /bin/sh
          - -c
          env:
          - name: CONTIV_ETCD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: ETCD_NAME
            value: contiv-etcd
          - name: ETCD_DATA_DIR
            value: /var/lib/etcd/contiv-data
          - name: ETCD_LISTEN_CLIENT_URLS
            value: http://0.0.0.0:6666
          - name: ETCD_LISTEN_PEER_URLS
            value: http://0.0.0.0:6667
          image: quay.io/coreos/etcd:v3.2.4
          imagePullPolicy: IfNotPresent
          name: contiv-etcd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/etcd
            name: var-etcd
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          node-role.kubernetes.io/master: ""
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node.cloudprovider.kubernetes.io/uninitialized
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /var/etcd
            type: ""
          name: var-etcd
    updateStrategy:
      type: OnDelete
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netplugin"},"name":"contiv-netplugin","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"contiv-netplugin"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-netplugin"}},"spec":{"containers":[{"command":["tail","-f","/dev/null"],"env":[{"name":"CONTIV_ROLE","value":"netplugin"},{"name":"CONTIV_NETPLUGIN_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_NETPLUGIN_VTEP_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"CONTIV_NETPLUGIN_FORWARD_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_fwdmode","name":"contiv-config"}}},{"name":"CONTIV_NETPLUGIN_NET_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_netmode","name":"contiv-config"}}}],"image":"contiv/netplugin:latest","name":"contiv-netplugin","resources":{"requests":{"cpu":"250m"}},"securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/var/run","name":"var-run","readOnly":false},{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/contiv/bin","name":"contiv-bin-dir","readOnly":true},{"mountPath":"/contiv/scripts/","name":"contiv-scripts-dir","readOnly":true},{"mountPath":"/var/log/contiv","name":"contiv-log-dir","readOnly":false}]}],"hostNetwork":true,"hostPID":true,"initContainers":[{"env":[{"name":"CONTIV_ROLE","value":"netplugin"},{"name":"CONTIV_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_K8S_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_k8s_config","name":"contiv-config"}}},{"name":"CONTIV_CNI_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_cni_config","name":"contiv-config"}}}],"image":"contiv/netplugin-init:latest","name":"contiv-netplugin-init","volumeMounts":[{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/etc/cni/net.d/","name":"etc-cni-dir","readOnly":false}]},{"command":["cp","/contiv/bin/contivk8s","/opt/cni/bin/contivk8s"],"image":"contiv/netplugin:latest","name":"contiv-cni","volumeMounts":[{"mountPath":"/opt/cni/bin","name":"cni-bin-dir","readOnly":false}]}],"serviceAccountName":"contiv-netplugin","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/var/run"},"name":"var-run"},{"hostPath":{"path":"/var/contiv"},"name":"var-contiv"},{"hostPath":{"path":"/opt/cni/bin"},"name":"cni-bin-dir"},{"hostPath":{"path":"/etc/cni/net.d/"},"name":"etc-cni-dir"},{"hostPath":{"path":"/opt/gopath/bin"},"name":"contiv-bin-dir"},{"hostPath":{"path":"/opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/"},"name":"contiv-scripts-dir"},{"hostPath":{"path":"/var/log/contiv"},"name":"contiv-log-dir"}]}}}}
    creationTimestamp: 2018-02-03T22:37:52Z
    generation: 1
    labels:
      k8s-app: contiv-netplugin
    name: contiv-netplugin
    namespace: kube-system
    resourceVersion: "3182"
    selfLink: /apis/apps/v1/namespaces/kube-system/daemonsets/contiv-netplugin
    uid: defd0ade-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: contiv-netplugin
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-netplugin
      spec:
        containers:
        - command:
          - tail
          - -f
          - /dev/null
          env:
          - name: CONTIV_ROLE
            value: netplugin
          - name: CONTIV_NETPLUGIN_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_NETPLUGIN_VTEP_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: CONTIV_NETPLUGIN_FORWARD_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_fwdmode
                name: contiv-config
          - name: CONTIV_NETPLUGIN_NET_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_netmode
                name: contiv-config
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-netplugin
          resources:
            requests:
              cpu: 250m
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/run
            name: var-run
          - mountPath: /var/contiv
            name: var-contiv
          - mountPath: /contiv/bin
            name: contiv-bin-dir
            readOnly: true
          - mountPath: /contiv/scripts/
            name: contiv-scripts-dir
            readOnly: true
          - mountPath: /var/log/contiv
            name: contiv-log-dir
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        initContainers:
        - env:
          - name: CONTIV_ROLE
            value: netplugin
          - name: CONTIV_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_K8S_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_k8s_config
                name: contiv-config
          - name: CONTIV_CNI_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_cni_config
                name: contiv-config
          image: contiv/netplugin-init:latest
          imagePullPolicy: Always
          name: contiv-netplugin-init
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/contiv
            name: var-contiv
          - mountPath: /etc/cni/net.d/
            name: etc-cni-dir
        - command:
          - cp
          - /contiv/bin/contivk8s
          - /opt/cni/bin/contivk8s
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-cni
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /opt/cni/bin
            name: cni-bin-dir
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: contiv-netplugin
        serviceAccountName: contiv-netplugin
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - hostPath:
            path: /var/run
            type: ""
          name: var-run
        - hostPath:
            path: /var/contiv
            type: ""
          name: var-contiv
        - hostPath:
            path: /opt/cni/bin
            type: ""
          name: cni-bin-dir
        - hostPath:
            path: /etc/cni/net.d/
            type: ""
          name: etc-cni-dir
        - hostPath:
            path: /opt/gopath/bin
            type: ""
          name: contiv-bin-dir
        - hostPath:
            path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
            type: ""
          name: contiv-scripts-dir
        - hostPath:
            path: /var/log/contiv
            type: ""
          name: contiv-log-dir
    updateStrategy:
      type: OnDelete
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-ovs"},"name":"contiv-ovs","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"contiv-ovs"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-ovs"}},"spec":{"containers":[{"command":["/scripts/start-ovsdb-server.sh"],"image":"contiv/ovs:latest","name":"contiv-ovsdb-server","securityContext":{"privileged":false},"volumeMounts":[{"mountPath":"/etc/openvswitch","name":"etc-openvswitch","readOnly":false},{"mountPath":"/var/run","name":"var-run","readOnly":false}]},{"command":["/scripts/start-ovs-vswitchd.sh"],"image":"contiv/ovs:latest","name":"contiv-ovs-vswitchd","securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/etc/openvswitch","name":"etc-openvswitch","readOnly":false},{"mountPath":"/lib/modules","name":"lib-modules","readOnly":true},{"mountPath":"/var/run","name":"var-run","readOnly":false}]}],"hostNetwork":true,"hostPID":true,"tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/etc/openvswitch"},"name":"etc-openvswitch"},{"hostPath":{"path":"/lib/modules"},"name":"lib-modules"},{"hostPath":{"path":"/var/run"},"name":"var-run"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    generation: 1
    labels:
      k8s-app: contiv-ovs
    name: contiv-ovs
    namespace: kube-system
    resourceVersion: "3167"
    selfLink: /apis/apps/v1/namespaces/kube-system/daemonsets/contiv-ovs
    uid: df7106fa-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: contiv-ovs
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-ovs
      spec:
        containers:
        - command:
          - /scripts/start-ovsdb-server.sh
          image: contiv/ovs:latest
          imagePullPolicy: Always
          name: contiv-ovsdb-server
          resources: {}
          securityContext:
            privileged: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/openvswitch
            name: etc-openvswitch
          - mountPath: /var/run
            name: var-run
        - command:
          - /scripts/start-ovs-vswitchd.sh
          image: contiv/ovs:latest
          imagePullPolicy: Always
          name: contiv-ovs-vswitchd
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/openvswitch
            name: etc-openvswitch
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
          - mountPath: /var/run
            name: var-run
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - hostPath:
            path: /etc/openvswitch
            type: ""
          name: etc-openvswitch
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
        - hostPath:
            path: /var/run
            type: ""
          name: var-run
    updateStrategy:
      type: OnDelete
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: 2018-02-03T22:37:38Z
    generation: 1
    labels:
      k8s-app: kube-proxy
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "2970"
    selfLink: /apis/apps/v1/namespaces/kube-system/daemonsets/kube-proxy
    uid: d61ef82d-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-proxy
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-proxy
      spec:
        containers:
        - command:
          - /usr/local/bin/kube-proxy
          - --config=/var/lib/kube-proxy/config.conf
          image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
          imagePullPolicy: IfNotPresent
          name: kube-proxy
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/kube-proxy
            name: kube-proxy
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-proxy
        serviceAccountName: kube-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - effect: NoSchedule
          key: node.cloudprovider.kubernetes.io/uninitialized
          value: "true"
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-proxy
          name: kube-proxy
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"ReplicaSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netmaster"},"name":"contiv-netmaster","namespace":"kube-system"},"spec":{"replicas":1,"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-netmaster"},"name":"contiv-netmaster","namespace":"kube-system"},"spec":{"containers":[{"command":["tail","-f","/dev/null"],"env":[{"name":"CONTIV_ROLE","value":"netmaster"},{"name":"CONTIV_NETMASTER_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_NETMASTER_FORWARD_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_fwdmode","name":"contiv-config"}}},{"name":"CONTIV_NETMASTER_NET_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_netmode","name":"contiv-config"}}}],"image":"contiv/netplugin:latest","name":"contiv-netmaster","volumeMounts":[{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/contiv/bin","name":"contiv-bin-dir","readOnly":true},{"mountPath":"/contiv/scripts/","name":"contiv-scripts-dir","readOnly":true},{"mountPath":"/var/log/contiv","name":"contiv-log-dir","readOnly":false}]}],"hostNetwork":true,"initContainers":[{"env":[{"name":"CONTIV_ROLE","value":"netmaster"},{"name":"CONTIV_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_K8S_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_k8s_config","name":"contiv-config"}}},{"name":"CONTIV_CNI_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_cni_config","name":"contiv-config"}}}],"image":"contiv/netplugin-init:latest","name":"contiv-netplugin-init","volumeMounts":[{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false}]},{"command":["cp","/contiv/bin/netctl","/usr/local/sbin/netctl"],"image":"contiv/netplugin:latest","name":"contiv-netctl","volumeMounts":[{"mountPath":"/usr/local/sbin/","name":"usr-local-sbin","readOnly":false}]}],"nodeSelector":{"node-role.kubernetes.io/master":""},"serviceAccountName":"contiv-netmaster","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/var/contiv"},"name":"var-contiv"},{"hostPath":{"path":"/usr/local/sbin/"},"name":"usr-local-sbin"},{"hostPath":{"path":"/opt/gopath/bin"},"name":"contiv-bin-dir"},{"hostPath":{"path":"/opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/"},"name":"contiv-scripts-dir"},{"hostPath":{"path":"/var/log/contiv"},"name":"contiv-log-dir"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    generation: 1
    labels:
      k8s-app: contiv-netmaster
    name: contiv-netmaster
    namespace: kube-system
    resourceVersion: "777"
    selfLink: /apis/apps/v1/namespaces/kube-system/replicasets/contiv-netmaster
    uid: df1a16b8-0932-11e8-9940-0800277561f7
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: contiv-netmaster
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-netmaster
        name: contiv-netmaster
        namespace: kube-system
      spec:
        containers:
        - command:
          - tail
          - -f
          - /dev/null
          env:
          - name: CONTIV_ROLE
            value: netmaster
          - name: CONTIV_NETMASTER_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_NETMASTER_FORWARD_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_fwdmode
                name: contiv-config
          - name: CONTIV_NETMASTER_NET_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_netmode
                name: contiv-config
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-netmaster
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/contiv
            name: var-contiv
          - mountPath: /contiv/bin
            name: contiv-bin-dir
            readOnly: true
          - mountPath: /contiv/scripts/
            name: contiv-scripts-dir
            readOnly: true
          - mountPath: /var/log/contiv
            name: contiv-log-dir
        dnsPolicy: ClusterFirst
        hostNetwork: true
        initContainers:
        - env:
          - name: CONTIV_ROLE
            value: netmaster
          - name: CONTIV_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_K8S_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_k8s_config
                name: contiv-config
          - name: CONTIV_CNI_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_cni_config
                name: contiv-config
          image: contiv/netplugin-init:latest
          imagePullPolicy: Always
          name: contiv-netplugin-init
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/contiv
            name: var-contiv
        - command:
          - cp
          - /contiv/bin/netctl
          - /usr/local/sbin/netctl
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-netctl
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/sbin/
            name: usr-local-sbin
        nodeSelector:
          node-role.kubernetes.io/master: ""
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: contiv-netmaster
        serviceAccountName: contiv-netmaster
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - hostPath:
            path: /var/contiv
            type: ""
          name: var-contiv
        - hostPath:
            path: /usr/local/sbin/
            type: ""
          name: usr-local-sbin
        - hostPath:
            path: /opt/gopath/bin
            type: ""
          name: contiv-bin-dir
        - hostPath:
            path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
            type: ""
          name: contiv-scripts-dir
        - hostPath:
            path: /var/log/contiv
            type: ""
          name: contiv-log-dir
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:37:53Z
    generateName: contiv-etcd-
    labels:
      controller-revision-hash: "3440706255"
      k8s-app: contiv-etcd
      pod-template-generation: "1"
    name: contiv-etcd-6mcxz
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-etcd
      uid: df32d0df-0932-11e8-9940-0800277561f7
    resourceVersion: "556"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-etcd-6mcxz
    uid: df3a7063-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - args:
      - ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
      command:
      - /bin/sh
      - -c
      env:
      - name: CONTIV_ETCD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: ETCD_NAME
        value: contiv-etcd
      - name: ETCD_DATA_DIR
        value: /var/lib/etcd/contiv-data
      - name: ETCD_LISTEN_CLIENT_URLS
        value: http://0.0.0.0:6666
      - name: ETCD_LISTEN_PEER_URLS
        value: http://0.0.0.0:6667
      image: quay.io/coreos/etcd:v3.2.4
      imagePullPolicy: IfNotPresent
      name: contiv-etcd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/etcd
        name: var-etcd
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    nodeSelector:
      node-role.kubernetes.io/master: ""
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: "true"
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /var/etcd
        type: ""
      name: var-etcd
    - name: default-token-9ktff
      secret:
        defaultMode: 420
        secretName: default-token-9ktff
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:37:53Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:41:00Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:38:42Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c584086fab59c85c04c80b189f2b74361d8249d629812f1f12062311d6329732
      image: quay.io/coreos/etcd:v3.2.4
      imageID: docker-pullable://quay.io/coreos/etcd@sha256:0a582c6ca6d32f1bed74c51bb1e33a215b301e0f28683777ec6af0c2e3925588
      lastState: {}
      name: contiv-etcd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:40:57Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: BestEffort
    startTime: 2018-02-03T22:37:53Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:37:53Z
    generateName: contiv-netmaster-
    labels:
      k8s-app: contiv-netmaster
    name: contiv-netmaster-vkc6s
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: contiv-netmaster
      uid: df1a16b8-0932-11e8-9940-0800277561f7
    resourceVersion: "776"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-netmaster-vkc6s
    uid: df377d13-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - tail
      - -f
      - /dev/null
      env:
      - name: CONTIV_ROLE
        value: netmaster
      - name: CONTIV_NETMASTER_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_NETMASTER_FORWARD_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_fwdmode
            name: contiv-config
      - name: CONTIV_NETMASTER_NET_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_netmode
            name: contiv-config
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netmaster
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /contiv/bin
        name: contiv-bin-dir
        readOnly: true
      - mountPath: /contiv/scripts/
        name: contiv-scripts-dir
        readOnly: true
      - mountPath: /var/log/contiv
        name: contiv-log-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netmaster-token-47bxd
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    initContainers:
    - env:
      - name: CONTIV_ROLE
        value: netmaster
      - name: CONTIV_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_K8S_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_k8s_config
            name: contiv-config
      - name: CONTIV_CNI_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_cni_config
            name: contiv-config
      image: contiv/netplugin-init:latest
      imagePullPolicy: Always
      name: contiv-netplugin-init
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netmaster-token-47bxd
        readOnly: true
    - command:
      - cp
      - /contiv/bin/netctl
      - /usr/local/sbin/netctl
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netctl
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /usr/local/sbin/
        name: usr-local-sbin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netmaster-token-47bxd
        readOnly: true
    nodeName: k8master
    nodeSelector:
      node-role.kubernetes.io/master: ""
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: contiv-netmaster
    serviceAccountName: contiv-netmaster
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /var/contiv
        type: ""
      name: var-contiv
    - hostPath:
        path: /usr/local/sbin/
        type: ""
      name: usr-local-sbin
    - hostPath:
        path: /opt/gopath/bin
        type: ""
      name: contiv-bin-dir
    - hostPath:
        path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
        type: ""
      name: contiv-scripts-dir
    - hostPath:
        path: /var/log/contiv
        type: ""
      name: contiv-log-dir
    - name: contiv-netmaster-token-47bxd
      secret:
        defaultMode: 420
        secretName: contiv-netmaster-token-47bxd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:45:09Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:45:20Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:40:22Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://dd9e75217cfb963e0806de0d573fe10d28e9f71ff7e8fc560825e2e753903661
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netmaster
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:45:18Z
    hostIP: 192.168.2.10
    initContainerStatuses:
    - containerID: docker://e1993b2b63c42729f6d24eaac6e4805e3509e39d08ff3078e27e5a52f8a2d74a
      image: docker.io/contiv/netplugin-init:latest
      imageID: docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      lastState: {}
      name: contiv-netplugin-init
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://e1993b2b63c42729f6d24eaac6e4805e3509e39d08ff3078e27e5a52f8a2d74a
          exitCode: 0
          finishedAt: 2018-02-03T22:44:49Z
          reason: Completed
          startedAt: 2018-02-03T22:44:46Z
    - containerID: docker://0c9a499dd9a3f027c6aafa2fadac4820d4977eb6a6e036638ac8f3f32c636834
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netctl
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://0c9a499dd9a3f027c6aafa2fadac4820d4977eb6a6e036638ac8f3f32c636834
          exitCode: 0
          finishedAt: 2018-02-03T22:45:07Z
          reason: Completed
          startedAt: 2018-02-03T22:45:07Z
    phase: Running
    podIP: 192.168.2.10
    qosClass: BestEffort
    startTime: 2018-02-03T22:40:22Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:55:35Z
    generateName: contiv-netplugin-
    labels:
      controller-revision-hash: "4029632485"
      k8s-app: contiv-netplugin
      pod-template-generation: "1"
    name: contiv-netplugin-2d7rp
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-netplugin
      uid: defd0ade-0932-11e8-9940-0800277561f7
    resourceVersion: "2733"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-netplugin-2d7rp
    uid: 58794095-0935-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - tail
      - -f
      - /dev/null
      env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_NETPLUGIN_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_VTEP_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: CONTIV_NETPLUGIN_FORWARD_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_fwdmode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_NET_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_netmode
            name: contiv-config
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netplugin
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /contiv/bin
        name: contiv-bin-dir
        readOnly: true
      - mountPath: /contiv/scripts/
        name: contiv-scripts-dir
        readOnly: true
      - mountPath: /var/log/contiv
        name: contiv-log-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    initContainers:
    - env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_K8S_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_k8s_config
            name: contiv-config
      - name: CONTIV_CNI_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_cni_config
            name: contiv-config
      image: contiv/netplugin-init:latest
      imagePullPolicy: Always
      name: contiv-netplugin-init
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /etc/cni/net.d/
        name: etc-cni-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    - command:
      - cp
      - /contiv/bin/contivk8s
      - /opt/cni/bin/contivk8s
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    nodeName: k8node-02
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: contiv-netplugin
    serviceAccountName: contiv-netplugin
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - hostPath:
        path: /var/contiv
        type: ""
      name: var-contiv
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d/
        type: ""
      name: etc-cni-dir
    - hostPath:
        path: /opt/gopath/bin
        type: ""
      name: contiv-bin-dir
    - hostPath:
        path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
        type: ""
      name: contiv-scripts-dir
    - hostPath:
        path: /var/log/contiv
        type: ""
      name: contiv-log-dir
    - name: contiv-netplugin-token-xqsb5
      secret:
        defaultMode: 420
        secretName: contiv-netplugin-token-xqsb5
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:06:54Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:08:20Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:57:03Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://d87a66a8c2913d4ec5daecfadf73b64e38872b00b37a1e58021b4c465654ef72
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netplugin
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:08:19Z
    hostIP: 192.168.2.12
    initContainerStatuses:
    - containerID: docker://92bb1a18866c331d3273f8c89b77e922ae6370346d8ca90e077419edede9193c
      image: docker.io/contiv/netplugin-init:latest
      imageID: docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      lastState: {}
      name: contiv-netplugin-init
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://92bb1a18866c331d3273f8c89b77e922ae6370346d8ca90e077419edede9193c
          exitCode: 0
          finishedAt: 2018-02-03T23:00:52Z
          reason: Completed
          startedAt: 2018-02-03T23:00:52Z
    - containerID: docker://26a9d7ca4ecda56afd9b216076f091466ee1a40b7a81f30907af18446d947064
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://26a9d7ca4ecda56afd9b216076f091466ee1a40b7a81f30907af18446d947064
          exitCode: 0
          finishedAt: 2018-02-03T23:06:16Z
          reason: Completed
          startedAt: 2018-02-03T23:06:16Z
    phase: Running
    podIP: 192.168.2.12
    qosClass: Burstable
    startTime: 2018-02-03T22:55:38Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T23:06:36Z
    generateName: contiv-netplugin-
    labels:
      controller-revision-hash: "4029632485"
      k8s-app: contiv-netplugin
      pod-template-generation: "1"
    name: contiv-netplugin-5pqjs
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-netplugin
      uid: defd0ade-0932-11e8-9940-0800277561f7
    resourceVersion: "3181"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-netplugin-5pqjs
    uid: e2725eca-0936-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - tail
      - -f
      - /dev/null
      env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_NETPLUGIN_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_VTEP_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: CONTIV_NETPLUGIN_FORWARD_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_fwdmode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_NET_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_netmode
            name: contiv-config
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netplugin
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /contiv/bin
        name: contiv-bin-dir
        readOnly: true
      - mountPath: /contiv/scripts/
        name: contiv-scripts-dir
        readOnly: true
      - mountPath: /var/log/contiv
        name: contiv-log-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    initContainers:
    - env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_K8S_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_k8s_config
            name: contiv-config
      - name: CONTIV_CNI_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_cni_config
            name: contiv-config
      image: contiv/netplugin-init:latest
      imagePullPolicy: Always
      name: contiv-netplugin-init
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /etc/cni/net.d/
        name: etc-cni-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    - command:
      - cp
      - /contiv/bin/contivk8s
      - /opt/cni/bin/contivk8s
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    nodeName: k8node-03
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: contiv-netplugin
    serviceAccountName: contiv-netplugin
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - hostPath:
        path: /var/contiv
        type: ""
      name: var-contiv
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d/
        type: ""
      name: etc-cni-dir
    - hostPath:
        path: /opt/gopath/bin
        type: ""
      name: contiv-bin-dir
    - hostPath:
        path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
        type: ""
      name: contiv-scripts-dir
    - hostPath:
        path: /var/log/contiv
        type: ""
      name: contiv-log-dir
    - name: contiv-netplugin-token-xqsb5
      secret:
        defaultMode: 420
        secretName: contiv-netplugin-token-xqsb5
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:13:09Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:13:15Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:08:03Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://71658aba1dea2b49ad888b5d6880c5313dc5635945df76491a5f51d33da5d857
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netplugin
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:13:14Z
    hostIP: 192.168.2.13
    initContainerStatuses:
    - containerID: docker://d3d3cae725515e434b8fffe529d9255b15a9a7772812aa604997b727ecae8933
      image: docker.io/contiv/netplugin-init:latest
      imageID: docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      lastState: {}
      name: contiv-netplugin-init
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://d3d3cae725515e434b8fffe529d9255b15a9a7772812aa604997b727ecae8933
          exitCode: 0
          finishedAt: 2018-02-03T23:09:07Z
          reason: Completed
          startedAt: 2018-02-03T23:09:07Z
    - containerID: docker://80fe8f20c15247503588028d51f9595ed406561b1d940c1e47e1b473b70ff967
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://80fe8f20c15247503588028d51f9595ed406561b1d940c1e47e1b473b70ff967
          exitCode: 0
          finishedAt: 2018-02-03T23:13:07Z
          reason: Completed
          startedAt: 2018-02-03T23:13:07Z
    phase: Running
    podIP: 192.168.2.13
    qosClass: Burstable
    startTime: 2018-02-03T23:06:39Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:37:53Z
    generateName: contiv-netplugin-
    labels:
      controller-revision-hash: "4029632485"
      k8s-app: contiv-netplugin
      pod-template-generation: "1"
    name: contiv-netplugin-qwgd5
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-netplugin
      uid: defd0ade-0932-11e8-9940-0800277561f7
    resourceVersion: "760"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-netplugin-qwgd5
    uid: df13632a-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - tail
      - -f
      - /dev/null
      env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_NETPLUGIN_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_VTEP_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: CONTIV_NETPLUGIN_FORWARD_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_fwdmode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_NET_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_netmode
            name: contiv-config
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netplugin
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /contiv/bin
        name: contiv-bin-dir
        readOnly: true
      - mountPath: /contiv/scripts/
        name: contiv-scripts-dir
        readOnly: true
      - mountPath: /var/log/contiv
        name: contiv-log-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    initContainers:
    - env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_K8S_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_k8s_config
            name: contiv-config
      - name: CONTIV_CNI_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_cni_config
            name: contiv-config
      image: contiv/netplugin-init:latest
      imagePullPolicy: Always
      name: contiv-netplugin-init
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /etc/cni/net.d/
        name: etc-cni-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    - command:
      - cp
      - /contiv/bin/contivk8s
      - /opt/cni/bin/contivk8s
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: contiv-netplugin
    serviceAccountName: contiv-netplugin
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - hostPath:
        path: /var/contiv
        type: ""
      name: var-contiv
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d/
        type: ""
      name: etc-cni-dir
    - hostPath:
        path: /opt/gopath/bin
        type: ""
      name: contiv-bin-dir
    - hostPath:
        path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
        type: ""
      name: contiv-scripts-dir
    - hostPath:
        path: /var/log/contiv
        type: ""
      name: contiv-log-dir
    - name: contiv-netplugin-token-xqsb5
      secret:
        defaultMode: 420
        secretName: contiv-netplugin-token-xqsb5
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:44:52Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:45:10Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:38:53Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://a4137c814f9832676d7df279495ab131f77f1119ad666633ee0cae9c8d6f4c1b
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netplugin
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:45:09Z
    hostIP: 192.168.2.10
    initContainerStatuses:
    - containerID: docker://04bc313a43b9a37cb93d161cdcb4e002824307b5c7db2b0ea664a577e879dd19
      image: docker.io/contiv/netplugin-init:latest
      imageID: docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      lastState: {}
      name: contiv-netplugin-init
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://04bc313a43b9a37cb93d161cdcb4e002824307b5c7db2b0ea664a577e879dd19
          exitCode: 0
          finishedAt: 2018-02-03T22:40:12Z
          reason: Completed
          startedAt: 2018-02-03T22:40:07Z
    - containerID: docker://1e9df8ab383baf7e9890712058863f523b437a26acb84659006ede9551d3e533
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://1e9df8ab383baf7e9890712058863f523b437a26acb84659006ede9551d3e533
          exitCode: 0
          finishedAt: 2018-02-03T22:44:39Z
          reason: Completed
          startedAt: 2018-02-03T22:44:39Z
    phase: Running
    podIP: 192.168.2.10
    qosClass: Burstable
    startTime: 2018-02-03T22:37:53Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:47:42Z
    generateName: contiv-netplugin-
    labels:
      controller-revision-hash: "4029632485"
      k8s-app: contiv-netplugin
      pod-template-generation: "1"
    name: contiv-netplugin-xwxkn
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-netplugin
      uid: defd0ade-0932-11e8-9940-0800277561f7
    resourceVersion: "2271"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-netplugin-xwxkn
    uid: 3eb6c622-0934-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - tail
      - -f
      - /dev/null
      env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_NETPLUGIN_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_VTEP_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: CONTIV_NETPLUGIN_FORWARD_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_fwdmode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_NET_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_netmode
            name: contiv-config
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netplugin
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /contiv/bin
        name: contiv-bin-dir
        readOnly: true
      - mountPath: /contiv/scripts/
        name: contiv-scripts-dir
        readOnly: true
      - mountPath: /var/log/contiv
        name: contiv-log-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    initContainers:
    - env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_K8S_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_k8s_config
            name: contiv-config
      - name: CONTIV_CNI_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_cni_config
            name: contiv-config
      image: contiv/netplugin-init:latest
      imagePullPolicy: Always
      name: contiv-netplugin-init
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /etc/cni/net.d/
        name: etc-cni-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    - command:
      - cp
      - /contiv/bin/contivk8s
      - /opt/cni/bin/contivk8s
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    nodeName: k8node-01
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: contiv-netplugin
    serviceAccountName: contiv-netplugin
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - hostPath:
        path: /var/contiv
        type: ""
      name: var-contiv
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d/
        type: ""
      name: etc-cni-dir
    - hostPath:
        path: /opt/gopath/bin
        type: ""
      name: contiv-bin-dir
    - hostPath:
        path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
        type: ""
      name: contiv-scripts-dir
    - hostPath:
        path: /var/log/contiv
        type: ""
      name: contiv-log-dir
    - name: contiv-netplugin-token-xqsb5
      secret:
        defaultMode: 420
        secretName: contiv-netplugin-token-xqsb5
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:03:03Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:03:20Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:48:22Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://9aaa1c9cb44a3e36a18bec6f9cf00f1c82e7c319ecbcd73cb78b208f7bcd5a44
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netplugin
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:03:18Z
    hostIP: 192.168.2.11
    initContainerStatuses:
    - containerID: docker://d1526ce58adecc381edae40be851e718f64e6055678245513dc1cca02567c455
      image: docker.io/contiv/netplugin-init:latest
      imageID: docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      lastState: {}
      name: contiv-netplugin-init
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://d1526ce58adecc381edae40be851e718f64e6055678245513dc1cca02567c455
          exitCode: 0
          finishedAt: 2018-02-03T22:48:51Z
          reason: Completed
          startedAt: 2018-02-03T22:48:51Z
    - containerID: docker://d47429eb736387693dcf5a8c9befea3aaec5353b18870a1ff084c2fbb7a4ef03
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://d47429eb736387693dcf5a8c9befea3aaec5353b18870a1ff084c2fbb7a4ef03
          exitCode: 0
          finishedAt: 2018-02-03T23:03:00Z
          reason: Completed
          startedAt: 2018-02-03T23:02:59Z
    phase: Running
    podIP: 192.168.2.11
    qosClass: Burstable
    startTime: 2018-02-03T22:47:46Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:55:35Z
    generateName: contiv-ovs-
    labels:
      controller-revision-hash: "1824568849"
      k8s-app: contiv-ovs
      pod-template-generation: "1"
    name: contiv-ovs-8mfdn
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-ovs
      uid: df7106fa-0932-11e8-9940-0800277561f7
    resourceVersion: "2607"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-ovs-8mfdn
    uid: 589ce7a8-0935-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /scripts/start-ovsdb-server.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovsdb-server
      resources: {}
      securityContext:
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    - command:
      - /scripts/start-ovs-vswitchd.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovs-vswitchd
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    nodeName: k8node-02
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/openvswitch
        type: ""
      name: etc-openvswitch
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - name: default-token-9ktff
      secret:
        defaultMode: 420
        secretName: default-token-9ktff
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:55:38Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:06:55Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:06:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://5d3a3a03ca28ba31d3193f5c24367d5df59e620d5ef4b4012648498f54b37464
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovs-vswitchd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:06:21Z
    - containerID: docker://9cb6eb87e5781c179ce895e55b02f926f3a7abcaf7a23c35a67dfcfe1a3c561d
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovsdb-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:01:06Z
    hostIP: 192.168.2.12
    phase: Running
    podIP: 192.168.2.12
    qosClass: BestEffort
    startTime: 2018-02-03T22:55:38Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:37:53Z
    generateName: contiv-ovs-
    labels:
      controller-revision-hash: "1824568849"
      k8s-app: contiv-ovs
      pod-template-generation: "1"
    name: contiv-ovs-mwfjk
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-ovs
      uid: df7106fa-0932-11e8-9940-0800277561f7
    resourceVersion: "734"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-ovs-mwfjk
    uid: df87efc2-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /scripts/start-ovsdb-server.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovsdb-server
      resources: {}
      securityContext:
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    - command:
      - /scripts/start-ovs-vswitchd.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovs-vswitchd
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/openvswitch
        type: ""
      name: etc-openvswitch
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - name: default-token-9ktff
      secret:
        defaultMode: 420
        secretName: default-token-9ktff
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:37:53Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:44:52Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:44:52Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://e32264562935b103bb84aa237add0c06ab70136ff288263bc78c03a3f0475553
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovs-vswitchd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:44:51Z
    - containerID: docker://39e7cc6199270908b8fd259c1ff09e21af4cf64c5714d3525923ec8566555232
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovsdb-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:41:33Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: BestEffort
    startTime: 2018-02-03T22:37:53Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T23:06:37Z
    generateName: contiv-ovs-
    labels:
      controller-revision-hash: "1824568849"
      k8s-app: contiv-ovs
      pod-template-generation: "1"
    name: contiv-ovs-zmk5s
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-ovs
      uid: df7106fa-0932-11e8-9940-0800277561f7
    resourceVersion: "3166"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-ovs-zmk5s
    uid: e2aab8a2-0936-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /scripts/start-ovsdb-server.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovsdb-server
      resources: {}
      securityContext:
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    - command:
      - /scripts/start-ovs-vswitchd.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovs-vswitchd
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    nodeName: k8node-03
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/openvswitch
        type: ""
      name: etc-openvswitch
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - name: default-token-9ktff
      secret:
        defaultMode: 420
        secretName: default-token-9ktff
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:06:39Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:13:09Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:08:04Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://364a2a0e04c9e14f0ca1c85e40986f3d09b4643c45c5df03df4bbc06f26c456c
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovs-vswitchd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:13:08Z
    - containerID: docker://dc98559482d862433e27244ecd0ee36fce64027dfb6ce1798ef6f633b6ae3e35
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovsdb-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:09:37Z
    hostIP: 192.168.2.13
    phase: Running
    podIP: 192.168.2.13
    qosClass: BestEffort
    startTime: 2018-02-03T23:06:39Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:47:43Z
    generateName: contiv-ovs-
    labels:
      controller-revision-hash: "1824568849"
      k8s-app: contiv-ovs
      pod-template-generation: "1"
    name: contiv-ovs-zwb9t
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-ovs
      uid: df7106fa-0932-11e8-9940-0800277561f7
    resourceVersion: "1430"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-ovs-zwb9t
    uid: 3ec118ff-0934-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /scripts/start-ovsdb-server.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovsdb-server
      resources: {}
      securityContext:
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    - command:
      - /scripts/start-ovs-vswitchd.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovs-vswitchd
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    nodeName: k8node-01
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/openvswitch
        type: ""
      name: etc-openvswitch
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - name: default-token-9ktff
      secret:
        defaultMode: 420
        secretName: default-token-9ktff
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:47:46Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:53:35Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:53:35Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://9fc9fad02f6bb178f3e63e4d2023e34c7f93abc1a350e61630c3360acc770902
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovs-vswitchd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:53:33Z
    - containerID: docker://abfd1933ea861649f13510742edc983ea29e56c8c7f0002bc8515e1763423157
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovsdb-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:51:27Z
    hostIP: 192.168.2.11
    phase: Running
    podIP: 192.168.2.11
    qosClass: BestEffort
    startTime: 2018-02-03T22:47:46Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 7278f85057e8bf5cb81c9f96d3b25320
      kubernetes.io/config.mirror: 7278f85057e8bf5cb81c9f96d3b25320
      kubernetes.io/config.seen: 2018-02-03T22:31:50.423856543Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:38:26Z
    labels:
      component: etcd
      tier: control-plane
    name: etcd-k8master
    namespace: kube-system
    resourceVersion: "431"
    selfLink: /api/v1/namespaces/kube-system/pods/etcd-k8master
    uid: f3035191-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - etcd
      - --listen-client-urls=http://127.0.0.1:2379
      - --advertise-client-urls=http://127.0.0.1:2379
      - --data-dir=/var/lib/etcd
      image: gcr.io/google_containers/etcd-amd64:3.1.11
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health
          port: 2379
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/etcd
        name: etcd
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/etcd
        type: DirectoryOrCreate
      name: etcd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:35:32Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://eab796c7ae3cc778244b6175dc7a8e081f57b4dd79bfc77346b5e12e1e87460e
      image: gcr.io/google_containers/etcd-amd64:3.1.11
      imageID: docker-pullable://gcr.io/google_containers/etcd-amd64@sha256:54889c08665d241e321ca5ce976b2df0f766794b698d53faf6b7dacb95316680
      lastState: {}
      name: etcd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:35:31Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: BestEffort
    startTime: 2018-02-03T22:31:55Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 8269013687f7c93ae98df858c8ca8f73
      kubernetes.io/config.mirror: 8269013687f7c93ae98df858c8ca8f73
      kubernetes.io/config.seen: 2018-02-03T22:31:50.423866266Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:38:53Z
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-k8master
    namespace: kube-system
    resourceVersion: "457"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-apiserver-k8master
    uid: 0335ef59-0933-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - kube-apiserver
      - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      - --secure-port=6443
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --requestheader-allowed-names=front-proxy-client
      - --service-cluster-ip-range=10.96.0.0/12
      - --service-account-key-file=/etc/kubernetes/pki/sa.pub
      - --allow-privileged=true
      - --requestheader-group-headers=X-Remote-Group
      - --advertise-address=192.168.2.10
      - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      - --insecure-port=0
      - --admission-control=Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota
      - --enable-bootstrap-token-auth=true
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --requestheader-username-headers=X-Remote-User
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      - --authorization-mode=Node,RBAC
      - --etcd-servers=http://127.0.0.1:2379
      env:
      - name: no_proxy
        value: k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
      image: gcr.io/google_containers/kube-apiserver-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 192.168.2.10
          path: /healthz
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      resources:
        requests:
          cpu: 250m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/pki
        name: ca-certs-etc-pki
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: ca-certs-etc-pki
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:37:22Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://cd38db17a5b2870dc43318f687d04a037c731188efee8818dde853cfc5c52535
      image: gcr.io/google_containers/kube-apiserver-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-apiserver-amd64@sha256:eec4329de0892f4a960b7f1202272f93880d3071a9b40d8407585125b37d527d
      lastState: {}
      name: kube-apiserver
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:37:21Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: Burstable
    startTime: 2018-02-03T22:31:55Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 3e62d6d6684d8169bc7a1ad3c99997bc
      kubernetes.io/config.mirror: 3e62d6d6684d8169bc7a1ad3c99997bc
      kubernetes.io/config.seen: 2018-02-03T22:31:50.423869393Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:38:15Z
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-k8master
    namespace: kube-system
    resourceVersion: "411"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-controller-manager-k8master
    uid: ec8a5065-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      - --address=127.0.0.1
      - --use-service-account-credentials=true
      - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      - --root-ca-file=/etc/kubernetes/pki/ca.crt
      - --leader-elect=true
      - --controllers=*,bootstrapsigner,tokencleaner
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      env:
      - name: no_proxy
        value: k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
      image: gcr.io/google_containers/kube-controller-manager-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10252
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /etc/pki
        name: ca-certs-etc-pki
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: ca-certs-etc-pki
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:33:18Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://409aa1bbfd5ace3dc4891da1aa7b841aa7b43a075c19dd1cc832ce67e8a31058
      image: gcr.io/google_containers/kube-controller-manager-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-controller-manager-amd64@sha256:10daf65c6e8d0ff032323931f3869cd30af23feab90345265ea405b6104a41c7
      lastState: {}
      name: kube-controller-manager
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:33:16Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: Burstable
    startTime: 2018-02-03T22:31:55Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2018-02-03T23:06:36Z
    generateName: kube-proxy-
    labels:
      controller-revision-hash: "588621068"
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-6j2b4
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: d61ef82d-0932-11e8-9940-0800277561f7
    resourceVersion: "2969"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-6j2b4
    uid: e279e689-0936-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-wmgjk
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8node-03
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: "true"
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-wmgjk
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-wmgjk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:06:39Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:10:54Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:08:03Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://6a1d4fb9c76c4750bbf134fd7baa1d5462cca42342e1d47cfc4c967048126c7a
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:10:53Z
    hostIP: 192.168.2.13
    phase: Running
    podIP: 192.168.2.13
    qosClass: BestEffort
    startTime: 2018-02-03T23:06:39Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2018-02-03T22:37:43Z
    generateName: kube-proxy-
    labels:
      controller-revision-hash: "588621068"
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-8wx7q
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: d61ef82d-0932-11e8-9940-0800277561f7
    resourceVersion: "477"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-8wx7q
    uid: d94add08-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-wmgjk
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: "true"
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-wmgjk
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-wmgjk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:37:43Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:39:39Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:39:39Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://b893576cd9a52e57bc66c2d9572c8d677f3c8a619702f911146d09d5ecd5204f
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:39:37Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: BestEffort
    startTime: 2018-02-03T22:37:43Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2018-02-03T22:55:35Z
    generateName: kube-proxy-
    labels:
      controller-revision-hash: "588621068"
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-l9msk
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: d61ef82d-0932-11e8-9940-0800277561f7
    resourceVersion: "2737"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-l9msk
    uid: 58793a23-0935-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-wmgjk
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8node-02
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: "true"
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-wmgjk
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-wmgjk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:55:38Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:08:21Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:57:00Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://cac2484e758141295b0cabaf20a15c6d9bac8b8b22a91d7f6362bc23985ff510
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:08:19Z
    hostIP: 192.168.2.12
    phase: Running
    podIP: 192.168.2.12
    qosClass: BestEffort
    startTime: 2018-02-03T22:55:38Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2018-02-03T22:47:42Z
    generateName: kube-proxy-
    labels:
      controller-revision-hash: "588621068"
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-zg92c
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: d61ef82d-0932-11e8-9940-0800277561f7
    resourceVersion: "1222"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-zg92c
    uid: 3eb6b38a-0934-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-wmgjk
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8node-01
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: "true"
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-wmgjk
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-wmgjk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:47:46Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:50:55Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:50:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c33c70f5a692eb4786b50bc8b136745b04d0ac94529a537bbd35bfdee88f2b5f
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:50:53Z
    hostIP: 192.168.2.11
    phase: Running
    podIP: 192.168.2.11
    qosClass: BestEffort
    startTime: 2018-02-03T22:47:46Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 419e9c2b7c2d4889af65758618bbed88
      kubernetes.io/config.mirror: 419e9c2b7c2d4889af65758618bbed88
      kubernetes.io/config.seen: 2018-02-03T22:31:50.423881438Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:37:37Z
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-k8master
    namespace: kube-system
    resourceVersion: "254"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-scheduler-k8master
    uid: d5d42c35-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - kube-scheduler
      - --address=127.0.0.1
      - --leader-elect=true
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      env:
      - name: no_proxy
        value: k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
      image: gcr.io/google_containers/kube-scheduler-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10251
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:33:47Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://75dfd82dae23666b4c39b3d32221913e7e4181323a13b711fdf6121d6d6c672e
      image: gcr.io/google_containers/kube-scheduler-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-scheduler-amd64@sha256:082520e24e697f3228046ca13cddf46e4e01ae2982685b4ccc7df8f8e9145abc
      lastState: {}
      name: kube-scheduler
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:33:45Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: Burstable
    startTime: 2018-02-03T22:31:55Z
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "129"
    selfLink: /api/v1/namespaces/default/services/kubernetes
    uid: d4ae84b1-0932-11e8-9940-0800277561f7
  spec:
    clusterIP: 10.96.0.1
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 6443
    sessionAffinity: ClientIP
    sessionAffinityConfig:
      clientIP:
        timeoutSeconds: 10800
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":"kube-system"},"spec":{"clusterIP":"10.96.232.136","ports":[{"port":6666}],"selector":{"k8s-app":"contiv-etcd"}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    labels:
      k8s-app: contiv-etcd
    name: contiv-etcd
    namespace: kube-system
    resourceVersion: "373"
    selfLink: /api/v1/namespaces/kube-system/services/contiv-etcd
    uid: df57476f-0932-11e8-9940-0800277561f7
  spec:
    clusterIP: 10.96.232.136
    ports:
    - port: 6666
      protocol: TCP
      targetPort: 6666
    selector:
      k8s-app: contiv-etcd
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get certificatesigningrequests --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: certificates.k8s.io/v1beta1
  kind: CertificateSigningRequest
  metadata:
    creationTimestamp: 2018-02-03T23:06:35Z
    name: node-csr-NQ3d6g41WV1WWJisOnSa9fS7yJOwNd_lR1Aic4EnvQA
    namespace: ""
    resourceVersion: "2529"
    selfLink: /apis/certificates.k8s.io/v1beta1/certificatesigningrequests/node-csr-NQ3d6g41WV1WWJisOnSa9fS7yJOwNd_lR1Aic4EnvQA
    uid: e1b51223-0936-11e8-9940-0800277561f7
  spec:
    groups:
    - system:bootstrappers
    - system:bootstrappers:kubeadm:default-node-token
    - system:authenticated
    request: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlIeU1JR1pBZ0VBTURjeEZUQVRCZ05WQkFvVERITjVjM1JsYlRwdWIyUmxjekVlTUJ3R0ExVUVBeE1WYzNsegpkR1Z0T201dlpHVTZhemh1YjJSbExUQXpNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUUvY1dUCkJJbDUvdXAyRHkyUnEyaHJ2TmFYWGt2TnJMOVBVaVJhV0FEbHdUanN5TGc3TStwRXpjbUZ1VDRmTW9lL0g1TnIKc0d4aGVSWjdZKzlmMkh3NnI2QUFNQW9HQ0NxR1NNNDlCQU1DQTBnQU1FVUNJUURlZzloejJIa280dW5FdjlkTAp0WXAwTDJ1M0pZQTRuMzRvOTJuek5oL2V4d0lnYkc5UkZUR2pWbm9SVnJGayt6WFpGTGtpOXdFanZkaFFabzBsCnREQUx3dlk9Ci0tLS0tRU5EIENFUlRJRklDQVRFIFJFUVVFU1QtLS0tLQo=
    usages:
    - digital signature
    - key encipherment
    - client auth
    username: system:bootstrap:d0d1be
  status:
    certificate: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNZekNDQVV1Z0F3SUJBZ0lVU3plTXpUNWNqNmdZS2IvSVlMN1F5bDR6WWlrd0RRWUpLb1pJaHZjTkFRRUwKQlFBd0ZURVRNQkVHQTFVRUF4TUthM1ZpWlhKdVpYUmxjekFlRncweE9EQXlNRE15TXpBeU1EQmFGdzB4T1RBeQpNRE15TXpBeU1EQmFNRGN4RlRBVEJnTlZCQW9UREhONWMzUmxiVHB1YjJSbGN6RWVNQndHQTFVRUF4TVZjM2x6CmRHVnRPbTV2WkdVNmF6aHViMlJsTFRBek1Ga3dFd1lIS29aSXpqMENBUVlJS29aSXpqMERBUWNEUWdBRS9jV1QKQklsNS91cDJEeTJScTJocnZOYVhYa3ZOckw5UFVpUmFXQURsd1Rqc3lMZzdNK3BFemNtRnVUNGZNb2UvSDVOcgpzR3hoZVJaN1krOWYySHc2cjZOVU1GSXdEZ1lEVlIwUEFRSC9CQVFEQWdXZ01CTUdBMVVkSlFRTU1Bb0dDQ3NHCkFRVUZCd01DTUF3R0ExVWRFd0VCL3dRQ01BQXdIUVlEVlIwT0JCWUVGSUhZclcvL3hNc2VabThpSUV2WTVmcjkKMExaaU1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQWo5ZkFQK0IwbXl1MVVmeHVaSzBuYkpxYllmQU1BaXhDagpha3NDdGNCRnNobVVBT0o0UWJJMDE4M09JSnJhaUVIU2JqVlpub0VYUkFFVG9Db0xJUVY0VGRLdWxaK0xlRTBTCklxN1lYL29RR2lCejJqbGdtbjh4Z1hha1pvaFJyVzRtWnpIL09WWWtTekhMUjZVZEJXTGZMbzg2WVIzT2RKM0sKaHNobzhSZHBlUEtJNjFEQ2RvdjVUYUNuR2haeVJrMWdmelBXOXkwNFl3eDJlZXIzd1ZWV1V1WmVra0lpOFpQdgo2WUl2bnBLcVV2OURCakE5ZjZiOGNGZ0U1bXFwM1AwM1FTVWJQZmZrVUpIdEI3bHBVRXRZTUVtMWxVTEsydzcvCjR4dDQ4U1RHOWs1L09lV3BpOWJ1dHNwSjVEdUtpY3NhcmhESDBpeXFOT0FIZytBZUY2b08KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    conditions:
    - lastUpdateTime: 2018-02-03T23:06:35Z
      message: Auto approving kubelet client certificate after SubjectAccessReview.
      reason: AutoApproved
      type: Approved
- apiVersion: certificates.k8s.io/v1beta1
  kind: CertificateSigningRequest
  metadata:
    creationTimestamp: 2018-02-03T22:46:44Z
    name: node-csr-WebmZ45AIlmmXlhpUOInVWUntDe1z8m2eTN8YwFCm2s
    namespace: ""
    resourceVersion: "869"
    selfLink: /apis/certificates.k8s.io/v1beta1/certificatesigningrequests/node-csr-WebmZ45AIlmmXlhpUOInVWUntDe1z8m2eTN8YwFCm2s
    uid: 1b9037d3-0934-11e8-9940-0800277561f7
  spec:
    groups:
    - system:bootstrappers
    - system:bootstrappers:kubeadm:default-node-token
    - system:authenticated
    request: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlIeU1JR1pBZ0VBTURjeEZUQVRCZ05WQkFvVERITjVjM1JsYlRwdWIyUmxjekVlTUJ3R0ExVUVBeE1WYzNsegpkR1Z0T201dlpHVTZhemh1YjJSbExUQXhNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUVaeUJZCkFoOEc4SVhrKzBEeVJsTHhFRXVUbE1sNDcyaTRaVDdhS1Z5ajdZNUU5dlNnc0djbllaMkJkZTlqQWw5UE1palQKVm03aEJobXVhOGZZRnhqS25hQUFNQW9HQ0NxR1NNNDlCQU1DQTBnQU1FVUNJRTVNaW5pdS81VVZWbnJSUy9NcQo5cHp3OUlGSGlUcUduUGJFVWg2YmVUOGdBaUVBa0dGQjNZM3VITDY3OGg2TmhlRXN5Sm9ta0twa29jaTJxRDhmCkdJMUk1azA9Ci0tLS0tRU5EIENFUlRJRklDQVRFIFJFUVVFU1QtLS0tLQo=
    usages:
    - digital signature
    - key encipherment
    - client auth
    username: system:bootstrap:d0d1be
  status:
    certificate: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNZekNDQVV1Z0F3SUJBZ0lVTTlZd0VOSXExMGV1R0Vaa0Zjd1R5V3UvaDFJd0RRWUpLb1pJaHZjTkFRRUwKQlFBd0ZURVRNQkVHQTFVRUF4TUthM1ZpWlhKdVpYUmxjekFlRncweE9EQXlNRE15TWpReU1EQmFGdzB4T1RBeQpNRE15TWpReU1EQmFNRGN4RlRBVEJnTlZCQW9UREhONWMzUmxiVHB1YjJSbGN6RWVNQndHQTFVRUF4TVZjM2x6CmRHVnRPbTV2WkdVNmF6aHViMlJsTFRBeE1Ga3dFd1lIS29aSXpqMENBUVlJS29aSXpqMERBUWNEUWdBRVp5QlkKQWg4RzhJWGsrMER5UmxMeEVFdVRsTWw0NzJpNFpUN2FLVnlqN1k1RTl2U2dzR2NuWVoyQmRlOWpBbDlQTWlqVApWbTdoQmhtdWE4ZllGeGpLbmFOVU1GSXdEZ1lEVlIwUEFRSC9CQVFEQWdXZ01CTUdBMVVkSlFRTU1Bb0dDQ3NHCkFRVUZCd01DTUF3R0ExVWRFd0VCL3dRQ01BQXdIUVlEVlIwT0JCWUVGQ2gwZ2dOY2dXZ2lxTmlJbGRrSGN0NWIKUXNGdk1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQldVbFAzS1NsWGRoQS9vb2RuNkFnbm4rS2U1b2dlOVBjMgo5RmllYytJdEcyd2ZJWGZtc0pvY0IxSmJid1FLK1NhTGxrUkgrT0hRR0FRYldBbkZiRUY3WG40ZHRXeXZPZGU4CnAyVEs3U05CZ1ZpWU5kQXpVQld2dmpmVjlxWVU0eVpiZ1lKWitIZGpBYXRVdWVObWhYUmhldlNsRENLOXdLOEsKaEI0Uk5hOTduWmI1eHVjOE1hMExtbXRjaU5RamZ3bGJDV0VoVVhvdThQdWllMU9sOXlEM1FNUFdXYnZSbWdmZwpsbHpJQkJEUHkxM1hiZWpaNlFXN1d0VzF1d0pKR0JDQWYvNU9IeXJmZERMNGhnK2xXdE9mQkQwejZNMGh4RlphCnUrOVM5cnRKMTVtRXMzRG14SENscEpHdU02OHNkODlVMVJ5T3FBczVuV3R4Q2M0UVFNT3UKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    conditions:
    - lastUpdateTime: 2018-02-03T22:46:44Z
      message: Auto approving kubelet client certificate after SubjectAccessReview.
      reason: AutoApproved
      type: Approved
- apiVersion: certificates.k8s.io/v1beta1
  kind: CertificateSigningRequest
  metadata:
    creationTimestamp: 2018-02-03T22:55:34Z
    name: node-csr-jtPWYkKUWhh1-OuAIo7wM7YG-RRp3viT2EfJy33wHjI
    namespace: ""
    resourceVersion: "1579"
    selfLink: /apis/certificates.k8s.io/v1beta1/certificatesigningrequests/node-csr-jtPWYkKUWhh1-OuAIo7wM7YG-RRp3viT2EfJy33wHjI
    uid: 57c2cbc9-0935-11e8-9940-0800277561f7
  spec:
    groups:
    - system:bootstrappers
    - system:bootstrappers:kubeadm:default-node-token
    - system:authenticated
    request: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlIeE1JR1pBZ0VBTURjeEZUQVRCZ05WQkFvVERITjVjM1JsYlRwdWIyUmxjekVlTUJ3R0ExVUVBeE1WYzNsegpkR1Z0T201dlpHVTZhemh1YjJSbExUQXlNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUUyUkR4ClZaYTNZdUtSRU9Eclh4WFdlSHVhUWF1byttZHF6Y2Z1SzMxNTA1azBFZHQzVXBvdlZ0bFE3bE02bjFMc3pyTG4KNXpteWFMSWhHb1k1cWR3ZC9hQUFNQW9HQ0NxR1NNNDlCQU1DQTBjQU1FUUNJSHlMUlpxTi81bE5zRXpIUkMvTgplNjNiZFV1ZmM3b0hyclNWNExaTEZ5Y2tBaUJkR1BteTBFMlMvSmVZQUJhZlFBSUZvcHJEYk1ydC85WWJ4WHlNCm1BNjlHdz09Ci0tLS0tRU5EIENFUlRJRklDQVRFIFJFUVVFU1QtLS0tLQo=
    usages:
    - digital signature
    - key encipherment
    - client auth
    username: system:bootstrap:d0d1be
  status:
    certificate: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNZekNDQVV1Z0F3SUJBZ0lVV0M5NlFCVWN0T0RNSWdaRDcyeThjVWkwaFpNd0RRWUpLb1pJaHZjTkFRRUwKQlFBd0ZURVRNQkVHQTFVRUF4TUthM1ZpWlhKdVpYUmxjekFlRncweE9EQXlNRE15TWpVeE1EQmFGdzB4T1RBeQpNRE15TWpVeE1EQmFNRGN4RlRBVEJnTlZCQW9UREhONWMzUmxiVHB1YjJSbGN6RWVNQndHQTFVRUF4TVZjM2x6CmRHVnRPbTV2WkdVNmF6aHViMlJsTFRBeU1Ga3dFd1lIS29aSXpqMENBUVlJS29aSXpqMERBUWNEUWdBRTJSRHgKVlphM1l1S1JFT0RyWHhYV2VIdWFRYXVvK21kcXpjZnVLMzE1MDVrMEVkdDNVcG92VnRsUTdsTTZuMUxzenJMbgo1em15YUxJaEdvWTVxZHdkL2FOVU1GSXdEZ1lEVlIwUEFRSC9CQVFEQWdXZ01CTUdBMVVkSlFRTU1Bb0dDQ3NHCkFRVUZCd01DTUF3R0ExVWRFd0VCL3dRQ01BQXdIUVlEVlIwT0JCWUVGTEJoOWFwTlJSWUFKM0J1bzdqRXl0bEcKWHkvdE1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQTZzbGVuUFovZStneHdtK1V4SHNnd1p1TlJjeGNKalZaZwpOV2tyNjVuZkFWZWpkK0poWmxQU0xTVlp6UHJoZlpwWkNGNWduSk1TdDRSWTVzQWpPSWtCNXc2OTcrNWlGOHZ0CkNzZVhKZmwyVEZLOS9IQUxwbkdGUnlYdjVGK3VBWUFCM1dVb0ZWZVNaQ2MxVm1DbkJCVFZYbVpqYWo5NldRT2YKMHNNeVRyVlAxWHQ2emVkUStSSzkrbnoxa043WUl4Rm9jeWFteFRhSUF3OW5MUHNHa2tGOTdQcHQxd3piT1VxdAp2amdKR2xuSTVydzBNd1ZxeWJwTE5ZS2FsVWhXRGkwSnFjUEplOThTTVVUaHVCbER0WWFkZy83bDF1NWthTUJICitIM3JFTEQ3WFhSS3p4UzJsKzFldFhjWWlvMXM1ZW9tNk5xSWd3ZTIrTjY2N1ZGbnBSTWYKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    conditions:
    - lastUpdateTime: 2018-02-03T22:55:34Z
      message: Auto approving kubelet client certificate after SubjectAccessReview.
      reason: AutoApproved
      type: Approved
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get clusterrolebindings --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: cluster-admin
    namespace: ""
    resourceVersion: "74"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/cluster-admin
    uid: d3b91738-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cluster-admin
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:masters
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1beta1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"name":"contiv-netmaster","namespace":""},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"contiv-netmaster"},"subjects":[{"kind":"ServiceAccount","name":"contiv-netmaster","namespace":"kube-system"}]}
    creationTimestamp: 2018-02-03T22:37:52Z
    name: contiv-netmaster
    namespace: ""
    resourceVersion: "342"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/contiv-netmaster
    uid: ded4c2a6-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: contiv-netmaster
  subjects:
  - kind: ServiceAccount
    name: contiv-netmaster
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1beta1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"name":"contiv-netplugin","namespace":""},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"contiv-netplugin"},"subjects":[{"kind":"ServiceAccount","name":"contiv-netplugin","namespace":"kube-system"}]}
    creationTimestamp: 2018-02-03T22:37:52Z
    name: contiv-netplugin
    namespace: ""
    resourceVersion: "339"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/contiv-netplugin
    uid: de7f1aa6-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: contiv-netplugin
  subjects:
  - kind: ServiceAccount
    name: contiv-netplugin
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: kubeadm:kubelet-bootstrap
    namespace: ""
    resourceVersion: "181"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/kubeadm%3Akubelet-bootstrap
    uid: d5ce86ba-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node-bootstrapper
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:bootstrappers:kubeadm:default-node-token
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: kubeadm:node-autoapprove-bootstrap
    namespace: ""
    resourceVersion: "182"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/kubeadm%3Anode-autoapprove-bootstrap
    uid: d5d26748-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:certificates.k8s.io:certificatesigningrequests:nodeclient
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:bootstrappers:kubeadm:default-node-token
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: kubeadm:node-autoapprove-certificate-rotation
    namespace: ""
    resourceVersion: "184"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/kubeadm%3Anode-autoapprove-certificate-rotation
    uid: d5d46be3-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:nodes
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    creationTimestamp: 2018-02-03T22:37:38Z
    name: kubeadm:node-proxier
    namespace: ""
    resourceVersion: "210"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/kubeadm%3Anode-proxier
    uid: d62113e6-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node-proxier
  subjects:
  - kind: ServiceAccount
    name: kube-proxy
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:aws-cloud-provider
    namespace: ""
    resourceVersion: "81"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Aaws-cloud-provider
    uid: d3d63bca-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:aws-cloud-provider
  subjects:
  - kind: ServiceAccount
    name: aws-cloud-provider
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:basic-user
    namespace: ""
    resourceVersion: "76"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Abasic-user
    uid: d3c0aef2-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:basic-user
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:authenticated
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:unauthenticated
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:attachdetach-controller
    namespace: ""
    resourceVersion: "83"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aattachdetach-controller
    uid: d3de6a34-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:attachdetach-controller
  subjects:
  - kind: ServiceAccount
    name: attachdetach-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:certificate-controller
    namespace: ""
    resourceVersion: "119"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Acertificate-controller
    uid: d47f60f8-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:certificate-controller
  subjects:
  - kind: ServiceAccount
    name: certificate-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:clusterrole-aggregation-controller
    namespace: ""
    resourceVersion: "84"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aclusterrole-aggregation-controller
    uid: d3e1c1ba-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:clusterrole-aggregation-controller
  subjects:
  - kind: ServiceAccount
    name: clusterrole-aggregation-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:cronjob-controller
    namespace: ""
    resourceVersion: "85"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Acronjob-controller
    uid: d3eb1fc9-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:cronjob-controller
  subjects:
  - kind: ServiceAccount
    name: cronjob-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:daemon-set-controller
    namespace: ""
    resourceVersion: "86"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Adaemon-set-controller
    uid: d3ee6729-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:daemon-set-controller
  subjects:
  - kind: ServiceAccount
    name: daemon-set-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:deployment-controller
    namespace: ""
    resourceVersion: "87"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Adeployment-controller
    uid: d3f0f6ce-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:deployment-controller
  subjects:
  - kind: ServiceAccount
    name: deployment-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:disruption-controller
    namespace: ""
    resourceVersion: "88"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Adisruption-controller
    uid: d3f6145c-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:disruption-controller
  subjects:
  - kind: ServiceAccount
    name: disruption-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:endpoint-controller
    namespace: ""
    resourceVersion: "90"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aendpoint-controller
    uid: d3f8b2de-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:endpoint-controller
  subjects:
  - kind: ServiceAccount
    name: endpoint-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:generic-garbage-collector
    namespace: ""
    resourceVersion: "94"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Ageneric-garbage-collector
    uid: d409351c-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:generic-garbage-collector
  subjects:
  - kind: ServiceAccount
    name: generic-garbage-collector
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:horizontal-pod-autoscaler
    namespace: ""
    resourceVersion: "95"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Ahorizontal-pod-autoscaler
    uid: d410d352-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:horizontal-pod-autoscaler
  subjects:
  - kind: ServiceAccount
    name: horizontal-pod-autoscaler
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:job-controller
    namespace: ""
    resourceVersion: "97"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Ajob-controller
    uid: d4137339-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:job-controller
  subjects:
  - kind: ServiceAccount
    name: job-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:namespace-controller
    namespace: ""
    resourceVersion: "98"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Anamespace-controller
    uid: d426ed35-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:namespace-controller
  subjects:
  - kind: ServiceAccount
    name: namespace-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:node-controller
    namespace: ""
    resourceVersion: "100"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Anode-controller
    uid: d42a4d96-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:node-controller
  subjects:
  - kind: ServiceAccount
    name: node-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:persistent-volume-binder
    namespace: ""
    resourceVersion: "101"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Apersistent-volume-binder
    uid: d431e9f5-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:persistent-volume-binder
  subjects:
  - kind: ServiceAccount
    name: persistent-volume-binder
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:pod-garbage-collector
    namespace: ""
    resourceVersion: "103"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Apod-garbage-collector
    uid: d4347de1-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:pod-garbage-collector
  subjects:
  - kind: ServiceAccount
    name: pod-garbage-collector
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:replicaset-controller
    namespace: ""
    resourceVersion: "104"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Areplicaset-controller
    uid: d4417e71-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:replicaset-controller
  subjects:
  - kind: ServiceAccount
    name: replicaset-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:replication-controller
    namespace: ""
    resourceVersion: "106"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Areplication-controller
    uid: d444e81a-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:replication-controller
  subjects:
  - kind: ServiceAccount
    name: replication-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:resourcequota-controller
    namespace: ""
    resourceVersion: "108"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aresourcequota-controller
    uid: d44a017a-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:resourcequota-controller
  subjects:
  - kind: ServiceAccount
    name: resourcequota-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:route-controller
    namespace: ""
    resourceVersion: "109"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aroute-controller
    uid: d45a9cfe-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:route-controller
  subjects:
  - kind: ServiceAccount
    name: route-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:service-account-controller
    namespace: ""
    resourceVersion: "112"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aservice-account-controller
    uid: d45faf7a-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:service-account-controller
  subjects:
  - kind: ServiceAccount
    name: service-account-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:service-controller
    namespace: ""
    resourceVersion: "114"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aservice-controller
    uid: d464b8e9-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:service-controller
  subjects:
  - kind: ServiceAccount
    name: service-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:statefulset-controller
    namespace: ""
    resourceVersion: "115"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Astatefulset-controller
    uid: d4753107-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:statefulset-controller
  subjects:
  - kind: ServiceAccount
    name: statefulset-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:ttl-controller
    namespace: ""
    resourceVersion: "118"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Attl-controller
    uid: d47a50cf-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:ttl-controller
  subjects:
  - kind: ServiceAccount
    name: ttl-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:discovery
    namespace: ""
    resourceVersion: "75"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Adiscovery
    uid: d3be1d67-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:discovery
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:authenticated
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:unauthenticated
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-controller-manager
    namespace: ""
    resourceVersion: "78"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Akube-controller-manager
    uid: d3c5b129-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:kube-controller-manager
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-controller-manager
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-scheduler
    namespace: ""
    resourceVersion: "80"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Akube-scheduler
    uid: d3d2df87-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:kube-scheduler
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-scheduler
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node
    namespace: ""
    resourceVersion: "82"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Anode
    uid: d3db6026-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node
  subjects: null
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:34Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node-proxier
    namespace: ""
    resourceVersion: "77"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Anode-proxier
    uid: d3c335c7-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node-proxier
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-proxy
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get clusterroles --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        rbac.authorization.k8s.io/aggregate-to-admin: "true"
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: admin
    namespace: ""
    resourceVersion: "309"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/admin
    uid: d2e0d679-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    - pods/attach
    - pods/exec
    - pods/portforward
    - pods/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - replicationcontrollers
    - replicationcontrollers/scale
    - secrets
    - serviceaccounts
    - services
    - services/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - events
    - limitranges
    - namespaces/status
    - pods/log
    - pods/status
    - replicationcontrollers/status
    - resourcequotas
    - resourcequotas/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - serviceaccounts
    verbs:
    - impersonate
  - apiGroups:
    - apps
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - ingresses
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - authorization.k8s.io
    resources:
    - localsubjectaccessreviews
    verbs:
    - create
  - apiGroups:
    - rbac.authorization.k8s.io
    resources:
    - rolebindings
    - roles
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: cluster-admin
    namespace: ""
    resourceVersion: "13"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/cluster-admin
    uid: d2d12dd7-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - '*'
  - nonResourceURLs:
    - '*'
    verbs:
    - '*'
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1beta1","kind":"ClusterRole","metadata":{"annotations":{},"name":"contiv-netmaster","namespace":""},"rules":[{"apiGroups":["","extensions"],"resources":["pods","nodes","namespaces","networkpolicies"],"verbs":["get","watch","list","update"]}]}
    creationTimestamp: 2018-02-03T22:37:52Z
    name: contiv-netmaster
    namespace: ""
    resourceVersion: "344"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/contiv-netmaster
    uid: ded73cb2-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    - extensions
    resources:
    - pods
    - nodes
    - namespaces
    - networkpolicies
    verbs:
    - get
    - watch
    - list
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1beta1","kind":"ClusterRole","metadata":{"annotations":{},"name":"contiv-netplugin","namespace":""},"rules":[{"apiGroups":["","extensions"],"resources":["endpoints","nodes","namespaces","networkpolicies","pods","services"],"verbs":["watch","list","update","get"]}]}
    creationTimestamp: 2018-02-03T22:37:52Z
    name: contiv-netplugin
    namespace: ""
    resourceVersion: "340"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/contiv-netplugin
    uid: dea9f86d-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    - extensions
    resources:
    - endpoints
    - nodes
    - namespaces
    - networkpolicies
    - pods
    - services
    verbs:
    - watch
    - list
    - update
    - get
- aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        rbac.authorization.k8s.io/aggregate-to-edit: "true"
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: edit
    namespace: ""
    resourceVersion: "311"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/edit
    uid: d2e362a2-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    - pods/attach
    - pods/exec
    - pods/portforward
    - pods/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - replicationcontrollers
    - replicationcontrollers/scale
    - secrets
    - serviceaccounts
    - services
    - services/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - events
    - limitranges
    - namespaces/status
    - pods/log
    - pods/status
    - replicationcontrollers/status
    - resourcequotas
    - resourcequotas/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - serviceaccounts
    verbs:
    - impersonate
  - apiGroups:
    - apps
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - ingresses
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
      rbac.authorization.k8s.io/aggregate-to-admin: "true"
    name: system:aggregate-to-admin
    namespace: ""
    resourceVersion: "20"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aaggregate-to-admin
    uid: d2e9cdce-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    - pods/attach
    - pods/exec
    - pods/portforward
    - pods/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - replicationcontrollers
    - replicationcontrollers/scale
    - secrets
    - serviceaccounts
    - services
    - services/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - events
    - limitranges
    - namespaces/status
    - pods/log
    - pods/status
    - replicationcontrollers/status
    - resourcequotas
    - resourcequotas/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - serviceaccounts
    verbs:
    - impersonate
  - apiGroups:
    - apps
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - ingresses
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - authorization.k8s.io
    resources:
    - localsubjectaccessreviews
    verbs:
    - create
  - apiGroups:
    - rbac.authorization.k8s.io
    resources:
    - rolebindings
    - roles
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
      rbac.authorization.k8s.io/aggregate-to-edit: "true"
    name: system:aggregate-to-edit
    namespace: ""
    resourceVersion: "23"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aaggregate-to-edit
    uid: d2f4ac65-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    - pods/attach
    - pods/exec
    - pods/portforward
    - pods/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - replicationcontrollers
    - replicationcontrollers/scale
    - secrets
    - serviceaccounts
    - services
    - services/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - events
    - limitranges
    - namespaces/status
    - pods/log
    - pods/status
    - replicationcontrollers/status
    - resourcequotas
    - resourcequotas/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - serviceaccounts
    verbs:
    - impersonate
  - apiGroups:
    - apps
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - ingresses
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
      rbac.authorization.k8s.io/aggregate-to-view: "true"
    name: system:aggregate-to-view
    namespace: ""
    resourceVersion: "27"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aaggregate-to-view
    uid: d2fa57d0-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - pods
    - replicationcontrollers
    - replicationcontrollers/scale
    - serviceaccounts
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - events
    - limitranges
    - namespaces/status
    - pods/log
    - pods/status
    - replicationcontrollers/status
    - resourcequotas
    - resourcequotas/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - daemonsets
    - deployments
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/scale
    - ingresses
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:auth-delegator
    namespace: ""
    resourceVersion: "42"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aauth-delegator
    uid: d31f17e1-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - authentication.k8s.io
    resources:
    - tokenreviews
    verbs:
    - create
  - apiGroups:
    - authorization.k8s.io
    resources:
    - subjectaccessreviews
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:aws-cloud-provider
    namespace: ""
    resourceVersion: "48"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aaws-cloud-provider
    uid: d342cfff-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - patch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:basic-user
    namespace: ""
    resourceVersion: "16"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Abasic-user
    uid: d2dd1347-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - authorization.k8s.io
    resources:
    - selfsubjectaccessreviews
    - selfsubjectrulesreviews
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:certificates.k8s.io:certificatesigningrequests:nodeclient
    namespace: ""
    resourceVersion: "49"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acertificates.k8s.io%3Acertificatesigningrequests%3Anodeclient
    uid: d34548c4-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests/nodeclient
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
    namespace: ""
    resourceVersion: "50"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acertificates.k8s.io%3Acertificatesigningrequests%3Aselfnodeclient
    uid: d34e40a4-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests/selfnodeclient
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:attachdetach-controller
    namespace: ""
    resourceVersion: "51"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aattachdetach-controller
    uid: d3549961-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    - persistentvolumes
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes/status
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:certificate-controller
    namespace: ""
    resourceVersion: "73"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Acertificate-controller
    uid: d3aec7dd-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests/approval
    - certificatesigningrequests/status
    verbs:
    - update
  - apiGroups:
    - authorization.k8s.io
    resources:
    - subjectaccessreviews
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:clusterrole-aggregation-controller
    namespace: ""
    resourceVersion: "52"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aclusterrole-aggregation-controller
    uid: d3571487-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - '*'
  - nonResourceURLs:
    - '*'
    verbs:
    - '*'
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:cronjob-controller
    namespace: ""
    resourceVersion: "53"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Acronjob-controller
    uid: d359ab52-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - batch
    resources:
    - cronjobs
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - batch
    resources:
    - jobs
    verbs:
    - create
    - delete
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs/status
    verbs:
    - update
  - apiGroups:
    - batch
    resources:
    - cronjobs/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - delete
    - list
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:daemon-set-controller
    namespace: ""
    resourceVersion: "54"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Adaemon-set-controller
    uid: d35c2bdb-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - apps
    - extensions
    resources:
    - daemonsets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - daemonsets/status
    verbs:
    - update
  - apiGroups:
    - apps
    - extensions
    resources:
    - daemonsets/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - list
    - patch
    - watch
  - apiGroups:
    - ""
    resources:
    - pods/binding
    verbs:
    - create
  - apiGroups:
    - apps
    resources:
    - controllerrevisions
    verbs:
    - create
    - delete
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:deployment-controller
    namespace: ""
    resourceVersion: "55"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Adeployment-controller
    uid: d35eb787-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments/status
    verbs:
    - update
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments/finalizers
    verbs:
    - update
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets
    verbs:
    - create
    - delete
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:disruption-controller
    namespace: ""
    resourceVersion: "56"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Adisruption-controller
    uid: d363d3c3-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - statefulsets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:endpoint-controller
    namespace: ""
    resourceVersion: "57"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aendpoint-controller
    uid: d36e7981-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - endpoints
    verbs:
    - create
    - delete
    - get
    - list
    - update
  - apiGroups:
    - ""
    resources:
    - endpoints/restricted
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:generic-garbage-collector
    namespace: ""
    resourceVersion: "58"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Ageneric-garbage-collector
    uid: d371d72c-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - delete
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:horizontal-pod-autoscaler
    namespace: ""
    resourceVersion: "59"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Ahorizontal-pod-autoscaler
    uid: d3745599-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers/status
    verbs:
    - update
  - apiGroups:
    - '*'
    resources:
    - '*/scale'
    verbs:
    - get
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - list
  - apiGroups:
    - ""
    resourceNames:
    - 'http:heapster:'
    - 'https:heapster:'
    resources:
    - services/proxy
    verbs:
    - get
  - apiGroups:
    - metrics.k8s.io
    resources:
    - pods
    verbs:
    - list
  - apiGroups:
    - custom.metrics.k8s.io
    resources:
    - '*'
    verbs:
    - get
    - list
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:job-controller
    namespace: ""
    resourceVersion: "60"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Ajob-controller
    uid: d376ddfb-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - batch
    resources:
    - jobs
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - batch
    resources:
    - jobs/status
    verbs:
    - update
  - apiGroups:
    - batch
    resources:
    - jobs/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - list
    - patch
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:namespace-controller
    namespace: ""
    resourceVersion: "61"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Anamespace-controller
    uid: d3796552-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces/finalize
    - namespaces/status
    verbs:
    - update
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - delete
    - deletecollection
    - get
    - list
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:node-controller
    namespace: ""
    resourceVersion: "62"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Anode-controller
    uid: d3862249-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - delete
    - get
    - list
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - nodes/status
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - pods/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - delete
    - list
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:persistent-volume-binder
    namespace: ""
    resourceVersion: "63"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Apersistent-volume-binder
    uid: d388b5ab-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumes
    verbs:
    - create
    - delete
    - get
    - list
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumes/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - storageclasses
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    verbs:
    - create
    - delete
    - get
  - apiGroups:
    - ""
    resources:
    - secrets
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - list
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:pod-garbage-collector
    namespace: ""
    resourceVersion: "64"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Apod-garbage-collector
    uid: d38b3e7e-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - delete
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:replicaset-controller
    namespace: ""
    resourceVersion: "65"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Areplicaset-controller
    uid: d38dcbf7-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets/status
    verbs:
    - update
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - list
    - patch
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:replication-controller
    namespace: ""
    resourceVersion: "66"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Areplication-controller
    uid: d3919a23-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - list
    - patch
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:resourcequota-controller
    namespace: ""
    resourceVersion: "67"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aresourcequota-controller
    uid: d39426f6-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - resourcequotas/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:route-controller
    namespace: ""
    resourceVersion: "68"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aroute-controller
    uid: d3a0de64-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes/status
    verbs:
    - patch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:service-account-controller
    namespace: ""
    resourceVersion: "69"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aservice-account-controller
    uid: d3a3620b-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - serviceaccounts
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:service-controller
    namespace: ""
    resourceVersion: "70"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aservice-controller
    uid: d3a5f30f-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - services/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:statefulset-controller
    namespace: ""
    resourceVersion: "71"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Astatefulset-controller
    uid: d3a9d18c-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - statefulsets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - statefulsets/status
    verbs:
    - update
  - apiGroups:
    - apps
    resources:
    - statefulsets/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - get
    - patch
    - update
  - apiGroups:
    - apps
    resources:
    - controllerrevisions
    verbs:
    - create
    - delete
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    verbs:
    - create
    - get
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:ttl-controller
    namespace: ""
    resourceVersion: "72"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Attl-controller
    uid: d3ac4538-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:discovery
    namespace: ""
    resourceVersion: "14"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Adiscovery
    uid: d2daff5a-0932-11e8-9940-0800277561f7
  rules:
  - nonResourceURLs:
    - /api
    - /api/*
    - /apis
    - /apis/*
    - /healthz
    - /swagger-2.0.0.pb-v1
    - /swagger.json
    - /swaggerapi
    - /swaggerapi/*
    - /version
    verbs:
    - get
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:heapster
    namespace: ""
    resourceVersion: "31"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aheapster
    uid: d2ff7049-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - events
    - namespaces
    - nodes
    - pods
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resources:
    - deployments
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-aggregator
    namespace: ""
    resourceVersion: "43"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Akube-aggregator
    uid: d3280c9a-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-controller-manager
    namespace: ""
    resourceVersion: "44"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Akube-controller-manager
    uid: d32d2963-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - endpoints
    - secrets
    - serviceaccounts
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - secrets
    verbs:
    - delete
  - apiGroups:
    - ""
    resources:
    - endpoints
    - namespaces
    - secrets
    - serviceaccounts
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - endpoints
    - secrets
    - serviceaccounts
    verbs:
    - update
  - apiGroups:
    - authentication.k8s.io
    resources:
    - tokenreviews
    verbs:
    - create
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-dns
    namespace: ""
    resourceVersion: "46"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Akube-dns
    uid: d33638f9-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    verbs:
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-scheduler
    namespace: ""
    resourceVersion: "45"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Akube-scheduler
    uid: d32fb507-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - endpoints
    verbs:
    - create
  - apiGroups:
    - ""
    resourceNames:
    - kube-scheduler
    resources:
    - endpoints
    verbs:
    - delete
    - get
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - pods/binding
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - pods/status
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - statefulsets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    - persistentvolumes
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node
    namespace: ""
    resourceVersion: "35"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Anode
    uid: d3113f27-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - authentication.k8s.io
    resources:
    - tokenreviews
    verbs:
    - create
  - apiGroups:
    - authorization.k8s.io
    resources:
    - localsubjectaccessreviews
    - subjectaccessreviews
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - create
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes/status
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - delete
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
  - apiGroups:
    - ""
    resources:
    - pods/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods/eviction
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - configmaps
    - secrets
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    - persistentvolumes
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - endpoints
    verbs:
    - get
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests
    verbs:
    - create
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node-bootstrapper
    namespace: ""
    resourceVersion: "41"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Anode-bootstrapper
    uid: d31c9feb-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests
    verbs:
    - create
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node-problem-detector
    namespace: ""
    resourceVersion: "38"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Anode-problem-detector
    uid: d31785d5-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - nodes/status
    verbs:
    - patch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node-proxier
    namespace: ""
    resourceVersion: "40"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Anode-proxier
    uid: d31a231a-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:33Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:persistent-volume-provisioner
    namespace: ""
    resourceVersion: "47"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Apersistent-volume-provisioner
    uid: d3403d30-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumes
    verbs:
    - create
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - storageclasses
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        rbac.authorization.k8s.io/aggregate-to-view: "true"
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:32Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: view
    namespace: ""
    resourceVersion: "312"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/view
    uid: d2e5ea45-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - pods
    - replicationcontrollers
    - replicationcontrollers/scale
    - serviceaccounts
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - events
    - limitranges
    - namespaces/status
    - pods/log
    - pods/status
    - replicationcontrollers/status
    - resourcequotas
    - resourcequotas/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - daemonsets
    - deployments
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/scale
    - ingresses
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - get
    - list
    - watch
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get componentstatuses --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: v1
  conditions:
  - message: ok
    status: "True"
    type: Healthy
  kind: ComponentStatus
  metadata:
    creationTimestamp: null
    name: scheduler
    namespace: ""
    selfLink: /api/v1/componentstatuses/scheduler
- apiVersion: v1
  conditions:
  - message: ok
    status: "True"
    type: Healthy
  kind: ComponentStatus
  metadata:
    creationTimestamp: null
    name: controller-manager
    namespace: ""
    selfLink: /api/v1/componentstatuses/controller-manager
- apiVersion: v1
  conditions:
  - message: '{"health": "true"}'
    status: "True"
    type: Healthy
  kind: ComponentStatus
  metadata:
    creationTimestamp: null
    name: etcd-0
    namespace: ""
    selfLink: /api/v1/componentstatuses/etcd-0
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get configmaps --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: v1
  data:
    kubeconfig: |
      apiVersion: v1
      clusters:
      - cluster:
          certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
          server: https://192.168.2.10:6443
        name: ""
      contexts: []
      current-context: ""
      kind: Config
      preferences: {}
      users: []
  kind: ConfigMap
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: cluster-info
    namespace: kube-public
    resourceVersion: "134507"
    selfLink: /api/v1/namespaces/kube-public/configmaps/cluster-info
    uid: d5d79741-0932-11e8-9940-0800277561f7
- apiVersion: v1
  data:
    contiv_cni_config: |-
      {
        "cniVersion": "0.3.1",
        "name": "contiv-net",
        "type": "contivk8s"
      }
    contiv_etcd: http://192.168.2.10:6666
    contiv_fwdmode: routing
    contiv_k8s_config: |-
      {
         "K8S_API_SERVER": "https://192.168.2.10:6443",
         "K8S_CA": "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt",
         "K8S_KEY": "",
         "K8S_CERT": "",
         "K8S_TOKEN": "",
         "SVC_SUBNET": "10.96.0.0/12"
      }
    contiv_mode: kubernetes
    contiv_netmode: vxlan
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"contiv_cni_config":"{\n  \"cniVersion\": \"0.3.1\",\n  \"name\": \"contiv-net\",\n  \"type\": \"contivk8s\"\n}","contiv_etcd":"http://192.168.2.10:6666","contiv_fwdmode":"routing","contiv_k8s_config":"{\n   \"K8S_API_SERVER\": \"https://192.168.2.10:6443\",\n   \"K8S_CA\": \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\",\n   \"K8S_KEY\": \"\",\n   \"K8S_CERT\": \"\",\n   \"K8S_TOKEN\": \"\",\n   \"SVC_SUBNET\": \"10.96.0.0/12\"\n}","contiv_mode":"kubernetes","contiv_netmode":"vxlan"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"contiv-config","namespace":"kube-system"}}
    creationTimestamp: 2018-02-03T22:37:52Z
    name: contiv-config
    namespace: kube-system
    resourceVersion: "347"
    selfLink: /api/v1/namespaces/kube-system/configmaps/contiv-config
    uid: def1144a-0932-11e8-9940-0800277561f7
- apiVersion: v1
  data:
    client-ca-file: |
      -----BEGIN CERTIFICATE-----
      MIICyDCCAbCgAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl
      cm5ldGVzMB4XDTE4MDIwMzIyMzEzOFoXDTI4MDIwMTIyMzEzOFowFTETMBEGA1UE
      AxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAKQW
      CCyzeAi6/vmatCdyIA778+K68ArOVzmMfjVqW6FlQZR9tq4C+KngMdK1raNVSl9g
      uJZXLvpO45ZgPYgrDpSbDOCLKOrIHsvjLMZWNUO9GXfObmlIDZcojrqMT8wFWa3u
      FeJ7ESpuf8EuopM3FdLytkQVz8DoW9rOSzVtmUMg6vuiTDYLFw/JYhCLvmVbIRxQ
      seAYaub+TPTFt6GYK/tvMnY2k9E+CaNxeDtZWmXzyAjkHVGL5aYh/K+h7c9mPczd
      +LjvDLI03RxphwJ97ldFPSruYUsXgGcz23z8pm+ifws0UVDgIm++0MASWiSuGaXc
      AUmEBsI3ICJBjCksRkECAwEAAaMjMCEwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB
      /wQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAGtxnHBxP6hEkFxW2895oTBqmY4j
      WUEb8GkxzORiuSExjkDxe5C94XZaF+CjL3gd7OBWrAVZS5rjbWJBPTOuFLwD9pLO
      yRUJCJ5czR50p/FsnPdyt5yzpdRrFYnrjYvotewzbIXsNpz3wKgG4YEdCPjV3QgX
      E2TJxPF+GYZXr8KWd7jK92rn4lqRjrVJHN/jL+xYwi1tdhCI9A0KjJYvsdMvnuVl
      3QJnLIlc4EQGJjicDmjSIwGXD4CmjNPWwJr5dfjULq4IIGMNH5EghcZlhc3Gr/G4
      5ErcjSiBiDEdULDQ4WXvIA4pUhf8wm2pCADO8L/fYsL9jxnTuCX0OObxs14=
      -----END CERTIFICATE-----
    requestheader-allowed-names: '["front-proxy-client"]'
    requestheader-client-ca-file: |
      -----BEGIN CERTIFICATE-----
      MIICyDCCAbCgAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl
      cm5ldGVzMB4XDTE4MDIwMzIyMzEzOVoXDTI4MDIwMTIyMzEzOVowFTETMBEGA1UE
      AxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBANnN
      gpVUT0uGvxe+klT0zIkomVsqDh8oltNNiJJJG9yJ3qay+VEXko8BEOaLiKKC6h3/
      jpQGSnM1/EQZYmkXckhxcviZ+/9rdr7a5AMVW2xvnpdX2ATbvKjjOU1rfr66r+cw
      CHdcPvsJcD1+tXLl5KRWgLB/+LsoiulNT3r1hDDBi39rl6Aw+YN3nXFLd41ZLLcc
      fIWFCwVEzpHKwGU0gfVqQlBZmbzxcOW7UgPFZp7gP3hWbEDS28gBh3dd9O52ryL6
      nzLDJa0bOZBdrguIWa4t/EhNwQIuE85LO/6VJkDhLMjnwNxCvZEbnDeoTDT/vFUJ
      ShtyXcNzQpHKRRQWeZMCAwEAAaMjMCEwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB
      /wQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAJYlXje8uvd1FVkDrHOYUCPHhIOp
      Jzwbp2DlqoXdXp8wV7FaT6f/Cu0ZWaYCnqMPFeF3BKT47ENTq1b2PkemJf9/AiE3
      1j9tVFsiIQrn0Eij9rGekqj/ok2/HEnKHPvX5ANenvX3M/XxIsWryTMfN7cA62lW
      ZtbFWVZFxN+atPMIU8hDlMopGRqo5vvobAHSHqdNukyHNuGolIqcv4Hso5zeWNsB
      ggz+/xnbNdVfyZ1XJwh6Meo97PoER0EkUDH+bWy1bd4nczOU+eTsuZOCGASUsPCo
      KeBqblUAgiTiCEuMhMyDvQcnB+Wl7qbyBkLthfoHJrS/I5FE9e6m9TnXH4g=
      -----END CERTIFICATE-----
    requestheader-extra-headers-prefix: '["X-Remote-Extra-"]'
    requestheader-group-headers: '["X-Remote-Group"]'
    requestheader-username-headers: '["X-Remote-User"]'
  kind: ConfigMap
  metadata:
    creationTimestamp: 2018-02-03T22:37:32Z
    name: extension-apiserver-authentication
    namespace: kube-system
    resourceVersion: "15"
    selfLink: /api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication
    uid: d2dab4fc-0932-11e8-9940-0800277561f7
- apiVersion: v1
  data:
    config.conf: |-
      apiVersion: kubeproxy.config.k8s.io/v1alpha1
      bindAddress: 0.0.0.0
      clientConnection:
        acceptContentTypes: ""
        burst: 10
        contentType: application/vnd.kubernetes.protobuf
        kubeconfig: /var/lib/kube-proxy/kubeconfig.conf
        qps: 5
      clusterCIDR: ""
      configSyncPeriod: 15m0s
      conntrack:
        max: null
        maxPerCore: 32768
        min: 131072
        tcpCloseWaitTimeout: 1h0m0s
        tcpEstablishedTimeout: 24h0m0s
      enableProfiling: false
      featureGates: ""
      healthzBindAddress: 0.0.0.0:10256
      hostnameOverride: ""
      iptables:
        masqueradeAll: false
        masqueradeBit: 14
        minSyncPeriod: 0s
        syncPeriod: 30s
      ipvs:
        minSyncPeriod: 0s
        scheduler: ""
        syncPeriod: 30s
      kind: KubeProxyConfiguration
      metricsBindAddress: 127.0.0.1:10249
      mode: ""
      oomScoreAdj: -999
      portRange: ""
      resourceContainer: /kube-proxy
      udpTimeoutMilliseconds: 250ms
    kubeconfig.conf: |-
      apiVersion: v1
      kind: Config
      clusters:
      - cluster:
          certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          server: https://192.168.2.10:6443
        name: default
      contexts:
      - context:
          cluster: default
          namespace: default
          user: default
        name: default
      current-context: default
      users:
      - name: default
        user:
          tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
  kind: ConfigMap
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    labels:
      app: kube-proxy
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "203"
    selfLink: /api/v1/namespaces/kube-system/configmaps/kube-proxy
    uid: d61538c5-0932-11e8-9940-0800277561f7
- apiVersion: v1
  data:
    MasterConfiguration: |
      api:
        advertiseAddress: 192.168.2.10
        bindPort: 6443
      authorizationModes:
      - Node
      - RBAC
      certificatesDir: /etc/kubernetes/pki
      cloudProvider: ""
      etcd:
        caFile: ""
        certFile: ""
        dataDir: /var/lib/etcd
        endpoints: null
        image: ""
        keyFile: ""
      imageRepository: gcr.io/google_containers
      kubeProxy:
        config:
          bindAddress: 0.0.0.0
          clientConnection:
            acceptContentTypes: ""
            burst: 10
            contentType: application/vnd.kubernetes.protobuf
            kubeconfig: /var/lib/kube-proxy/kubeconfig.conf
            qps: 5
          clusterCIDR: ""
          configSyncPeriod: 15m0s
          conntrack:
            max: null
            maxPerCore: 32768
            min: 131072
            tcpCloseWaitTimeout: 1h0m0s
            tcpEstablishedTimeout: 24h0m0s
          enableProfiling: false
          featureGates: ""
          healthzBindAddress: 0.0.0.0:10256
          hostnameOverride: ""
          iptables:
            masqueradeAll: false
            masqueradeBit: 14
            minSyncPeriod: 0s
            syncPeriod: 30s
          ipvs:
            minSyncPeriod: 0s
            scheduler: ""
            syncPeriod: 30s
          metricsBindAddress: 127.0.0.1:10249
          mode: ""
          oomScoreAdj: -999
          portRange: ""
          resourceContainer: /kube-proxy
          udpTimeoutMilliseconds: 250ms
      kubeletConfiguration: {}
      kubernetesVersion: v1.9.2
      networking:
        dnsDomain: cluster.local
        podSubnet: ""
        serviceSubnet: 10.96.0.0/12
      nodeName: k8master
      token: ""
      tokenTTL: 24h0m0s
      unifiedControlPlaneImage: ""
  kind: ConfigMap
  metadata:
    creationTimestamp: 2018-02-03T22:37:36Z
    name: kubeadm-config
    namespace: kube-system
    resourceVersion: "158"
    selfLink: /api/v1/namespaces/kube-system/configmaps/kubeadm-config
    uid: d561dfba-0932-11e8-9940-0800277561f7
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get controllerrevisions --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: apps/v1
  data:
    spec:
      template:
        $patch: replace
        metadata:
          annotations:
            scheduler.alpha.kubernetes.io/critical-pod: ""
          creationTimestamp: null
          labels:
            k8s-app: contiv-etcd
        spec:
          containers:
          - args:
            - ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
            command:
            - /bin/sh
            - -c
            env:
            - name: CONTIV_ETCD_IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: ETCD_NAME
              value: contiv-etcd
            - name: ETCD_DATA_DIR
              value: /var/lib/etcd/contiv-data
            - name: ETCD_LISTEN_CLIENT_URLS
              value: http://0.0.0.0:6666
            - name: ETCD_LISTEN_PEER_URLS
              value: http://0.0.0.0:6667
            image: quay.io/coreos/etcd:v3.2.4
            imagePullPolicy: IfNotPresent
            name: contiv-etcd
            resources: {}
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /var/etcd
              name: var-etcd
          dnsPolicy: ClusterFirst
          hostNetwork: true
          nodeSelector:
            node-role.kubernetes.io/master: ""
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext: {}
          terminationGracePeriodSeconds: 30
          tolerations:
          - effect: NoSchedule
            key: node.cloudprovider.kubernetes.io/uninitialized
            value: "true"
          - effect: NoSchedule
            key: node-role.kubernetes.io/master
          - key: CriticalAddonsOnly
            operator: Exists
          volumes:
          - hostPath:
              path: /var/etcd
              type: ""
            name: var-etcd
  kind: ControllerRevision
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":"kube-system"},"spec":{"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-etcd"}},"spec":{"containers":[{"args":["ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd"],"command":["/bin/sh","-c"],"env":[{"name":"CONTIV_ETCD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"ETCD_NAME","value":"contiv-etcd"},{"name":"ETCD_DATA_DIR","value":"/var/lib/etcd/contiv-data"},{"name":"ETCD_LISTEN_CLIENT_URLS","value":"http://0.0.0.0:6666"},{"name":"ETCD_LISTEN_PEER_URLS","value":"http://0.0.0.0:6667"}],"image":"quay.io/coreos/etcd:v3.2.4","name":"contiv-etcd","volumeMounts":[{"mountPath":"/var/etcd","name":"var-etcd"}]}],"hostNetwork":true,"nodeSelector":{"node-role.kubernetes.io/master":""},"tolerations":[{"effect":"NoSchedule","key":"node.cloudprovider.kubernetes.io/uninitialized","value":"true"},{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"},{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/etcd"},"name":"var-etcd"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    labels:
      controller-revision-hash: "3440706255"
      k8s-app: contiv-etcd
    name: contiv-etcd-7884c4b699
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-etcd
      uid: df32d0df-0932-11e8-9940-0800277561f7
    resourceVersion: "360"
    selfLink: /apis/apps/v1/namespaces/kube-system/controllerrevisions/contiv-etcd-7884c4b699
    uid: df37e2f3-0932-11e8-9940-0800277561f7
  revision: 1
- apiVersion: apps/v1
  data:
    spec:
      template:
        $patch: replace
        metadata:
          annotations:
            scheduler.alpha.kubernetes.io/critical-pod: ""
          creationTimestamp: null
          labels:
            k8s-app: contiv-netplugin
        spec:
          containers:
          - command:
            - tail
            - -f
            - /dev/null
            env:
            - name: CONTIV_ROLE
              value: netplugin
            - name: CONTIV_NETPLUGIN_MODE
              valueFrom:
                configMapKeyRef:
                  key: contiv_mode
                  name: contiv-config
            - name: CONTIV_NETPLUGIN_VTEP_IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: CONTIV_NETPLUGIN_FORWARD_MODE
              valueFrom:
                configMapKeyRef:
                  key: contiv_fwdmode
                  name: contiv-config
            - name: CONTIV_NETPLUGIN_NET_MODE
              valueFrom:
                configMapKeyRef:
                  key: contiv_netmode
                  name: contiv-config
            image: contiv/netplugin:latest
            imagePullPolicy: Always
            name: contiv-netplugin
            resources:
              requests:
                cpu: 250m
            securityContext:
              privileged: true
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /var/run
              name: var-run
            - mountPath: /var/contiv
              name: var-contiv
            - mountPath: /contiv/bin
              name: contiv-bin-dir
              readOnly: true
            - mountPath: /contiv/scripts/
              name: contiv-scripts-dir
              readOnly: true
            - mountPath: /var/log/contiv
              name: contiv-log-dir
          dnsPolicy: ClusterFirst
          hostNetwork: true
          hostPID: true
          initContainers:
          - env:
            - name: CONTIV_ROLE
              value: netplugin
            - name: CONTIV_MODE
              valueFrom:
                configMapKeyRef:
                  key: contiv_mode
                  name: contiv-config
            - name: CONTIV_K8S_CONFIG
              valueFrom:
                configMapKeyRef:
                  key: contiv_k8s_config
                  name: contiv-config
            - name: CONTIV_CNI_CONFIG
              valueFrom:
                configMapKeyRef:
                  key: contiv_cni_config
                  name: contiv-config
            image: contiv/netplugin-init:latest
            imagePullPolicy: Always
            name: contiv-netplugin-init
            resources: {}
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /var/contiv
              name: var-contiv
            - mountPath: /etc/cni/net.d/
              name: etc-cni-dir
          - command:
            - cp
            - /contiv/bin/contivk8s
            - /opt/cni/bin/contivk8s
            image: contiv/netplugin:latest
            imagePullPolicy: Always
            name: contiv-cni
            resources: {}
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /opt/cni/bin
              name: cni-bin-dir
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext: {}
          serviceAccount: contiv-netplugin
          serviceAccountName: contiv-netplugin
          terminationGracePeriodSeconds: 30
          tolerations:
          - effect: NoSchedule
            key: node-role.kubernetes.io/master
          volumes:
          - hostPath:
              path: /var/run
              type: ""
            name: var-run
          - hostPath:
              path: /var/contiv
              type: ""
            name: var-contiv
          - hostPath:
              path: /opt/cni/bin
              type: ""
            name: cni-bin-dir
          - hostPath:
              path: /etc/cni/net.d/
              type: ""
            name: etc-cni-dir
          - hostPath:
              path: /opt/gopath/bin
              type: ""
            name: contiv-bin-dir
          - hostPath:
              path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
              type: ""
            name: contiv-scripts-dir
          - hostPath:
              path: /var/log/contiv
              type: ""
            name: contiv-log-dir
  kind: ControllerRevision
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netplugin"},"name":"contiv-netplugin","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"contiv-netplugin"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-netplugin"}},"spec":{"containers":[{"command":["tail","-f","/dev/null"],"env":[{"name":"CONTIV_ROLE","value":"netplugin"},{"name":"CONTIV_NETPLUGIN_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_NETPLUGIN_VTEP_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"CONTIV_NETPLUGIN_FORWARD_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_fwdmode","name":"contiv-config"}}},{"name":"CONTIV_NETPLUGIN_NET_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_netmode","name":"contiv-config"}}}],"image":"contiv/netplugin:latest","name":"contiv-netplugin","resources":{"requests":{"cpu":"250m"}},"securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/var/run","name":"var-run","readOnly":false},{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/contiv/bin","name":"contiv-bin-dir","readOnly":true},{"mountPath":"/contiv/scripts/","name":"contiv-scripts-dir","readOnly":true},{"mountPath":"/var/log/contiv","name":"contiv-log-dir","readOnly":false}]}],"hostNetwork":true,"hostPID":true,"initContainers":[{"env":[{"name":"CONTIV_ROLE","value":"netplugin"},{"name":"CONTIV_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_K8S_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_k8s_config","name":"contiv-config"}}},{"name":"CONTIV_CNI_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_cni_config","name":"contiv-config"}}}],"image":"contiv/netplugin-init:latest","name":"contiv-netplugin-init","volumeMounts":[{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/etc/cni/net.d/","name":"etc-cni-dir","readOnly":false}]},{"command":["cp","/contiv/bin/contivk8s","/opt/cni/bin/contivk8s"],"image":"contiv/netplugin:latest","name":"contiv-cni","volumeMounts":[{"mountPath":"/opt/cni/bin","name":"cni-bin-dir","readOnly":false}]}],"serviceAccountName":"contiv-netplugin","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/var/run"},"name":"var-run"},{"hostPath":{"path":"/var/contiv"},"name":"var-contiv"},{"hostPath":{"path":"/opt/cni/bin"},"name":"cni-bin-dir"},{"hostPath":{"path":"/etc/cni/net.d/"},"name":"etc-cni-dir"},{"hostPath":{"path":"/opt/gopath/bin"},"name":"contiv-bin-dir"},{"hostPath":{"path":"/opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/"},"name":"contiv-scripts-dir"},{"hostPath":{"path":"/var/log/contiv"},"name":"contiv-log-dir"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    labels:
      controller-revision-hash: "4029632485"
      k8s-app: contiv-netplugin
    name: contiv-netplugin-846fb768d9
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-netplugin
      uid: defd0ade-0932-11e8-9940-0800277561f7
    resourceVersion: "351"
    selfLink: /apis/apps/v1/namespaces/kube-system/controllerrevisions/contiv-netplugin-846fb768d9
    uid: df12ad29-0932-11e8-9940-0800277561f7
  revision: 1
- apiVersion: apps/v1
  data:
    spec:
      template:
        $patch: replace
        metadata:
          annotations:
            scheduler.alpha.kubernetes.io/critical-pod: ""
          creationTimestamp: null
          labels:
            k8s-app: contiv-ovs
        spec:
          containers:
          - command:
            - /scripts/start-ovsdb-server.sh
            image: contiv/ovs:latest
            imagePullPolicy: Always
            name: contiv-ovsdb-server
            resources: {}
            securityContext:
              privileged: false
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /etc/openvswitch
              name: etc-openvswitch
            - mountPath: /var/run
              name: var-run
          - command:
            - /scripts/start-ovs-vswitchd.sh
            image: contiv/ovs:latest
            imagePullPolicy: Always
            name: contiv-ovs-vswitchd
            resources: {}
            securityContext:
              privileged: true
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /etc/openvswitch
              name: etc-openvswitch
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /var/run
              name: var-run
          dnsPolicy: ClusterFirst
          hostNetwork: true
          hostPID: true
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext: {}
          terminationGracePeriodSeconds: 30
          tolerations:
          - effect: NoSchedule
            key: node-role.kubernetes.io/master
          volumes:
          - hostPath:
              path: /etc/openvswitch
              type: ""
            name: etc-openvswitch
          - hostPath:
              path: /lib/modules
              type: ""
            name: lib-modules
          - hostPath:
              path: /var/run
              type: ""
            name: var-run
  kind: ControllerRevision
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-ovs"},"name":"contiv-ovs","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"contiv-ovs"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-ovs"}},"spec":{"containers":[{"command":["/scripts/start-ovsdb-server.sh"],"image":"contiv/ovs:latest","name":"contiv-ovsdb-server","securityContext":{"privileged":false},"volumeMounts":[{"mountPath":"/etc/openvswitch","name":"etc-openvswitch","readOnly":false},{"mountPath":"/var/run","name":"var-run","readOnly":false}]},{"command":["/scripts/start-ovs-vswitchd.sh"],"image":"contiv/ovs:latest","name":"contiv-ovs-vswitchd","securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/etc/openvswitch","name":"etc-openvswitch","readOnly":false},{"mountPath":"/lib/modules","name":"lib-modules","readOnly":true},{"mountPath":"/var/run","name":"var-run","readOnly":false}]}],"hostNetwork":true,"hostPID":true,"tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/etc/openvswitch"},"name":"etc-openvswitch"},{"hostPath":{"path":"/lib/modules"},"name":"lib-modules"},{"hostPath":{"path":"/var/run"},"name":"var-run"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    labels:
      controller-revision-hash: "1824568849"
      k8s-app: contiv-ovs
    name: contiv-ovs-5d689bdd8f
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-ovs
      uid: df7106fa-0932-11e8-9940-0800277561f7
    resourceVersion: "381"
    selfLink: /apis/apps/v1/namespaces/kube-system/controllerrevisions/contiv-ovs-5d689bdd8f
    uid: df7a005d-0932-11e8-9940-0800277561f7
  revision: 1
- apiVersion: apps/v1
  data:
    spec:
      template:
        $patch: replace
        metadata:
          creationTimestamp: null
          labels:
            k8s-app: kube-proxy
        spec:
          containers:
          - command:
            - /usr/local/bin/kube-proxy
            - --config=/var/lib/kube-proxy/config.conf
            image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
            imagePullPolicy: IfNotPresent
            name: kube-proxy
            resources: {}
            securityContext:
              privileged: true
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /var/lib/kube-proxy
              name: kube-proxy
            - mountPath: /run/xtables.lock
              name: xtables-lock
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
          dnsPolicy: ClusterFirst
          hostNetwork: true
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext: {}
          serviceAccount: kube-proxy
          serviceAccountName: kube-proxy
          terminationGracePeriodSeconds: 30
          tolerations:
          - effect: NoSchedule
            key: node-role.kubernetes.io/master
          - effect: NoSchedule
            key: node.cloudprovider.kubernetes.io/uninitialized
            value: "true"
          volumes:
          - configMap:
              defaultMode: 420
              name: kube-proxy
            name: kube-proxy
          - hostPath:
              path: /run/xtables.lock
              type: FileOrCreate
            name: xtables-lock
          - hostPath:
              path: /lib/modules
              type: ""
            name: lib-modules
  kind: ControllerRevision
  metadata:
    creationTimestamp: 2018-02-03T22:37:43Z
    labels:
      controller-revision-hash: "588621068"
      k8s-app: kube-proxy
    name: kube-proxy-9ddb654bd
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: d61ef82d-0932-11e8-9940-0800277561f7
    resourceVersion: "300"
    selfLink: /apis/apps/v1/namespaces/kube-system/controllerrevisions/kube-proxy-9ddb654bd
    uid: d93bd875-0932-11e8-9940-0800277561f7
  revision: 1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get cronjobs --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get customresourcedefinition --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get daemonsets --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":"kube-system"},"spec":{"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-etcd"}},"spec":{"containers":[{"args":["ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd"],"command":["/bin/sh","-c"],"env":[{"name":"CONTIV_ETCD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"ETCD_NAME","value":"contiv-etcd"},{"name":"ETCD_DATA_DIR","value":"/var/lib/etcd/contiv-data"},{"name":"ETCD_LISTEN_CLIENT_URLS","value":"http://0.0.0.0:6666"},{"name":"ETCD_LISTEN_PEER_URLS","value":"http://0.0.0.0:6667"}],"image":"quay.io/coreos/etcd:v3.2.4","name":"contiv-etcd","volumeMounts":[{"mountPath":"/var/etcd","name":"var-etcd"}]}],"hostNetwork":true,"nodeSelector":{"node-role.kubernetes.io/master":""},"tolerations":[{"effect":"NoSchedule","key":"node.cloudprovider.kubernetes.io/uninitialized","value":"true"},{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"},{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/etcd"},"name":"var-etcd"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    generation: 1
    labels:
      k8s-app: contiv-etcd
    name: contiv-etcd
    namespace: kube-system
    resourceVersion: "558"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/contiv-etcd
    uid: df32d0df-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: contiv-etcd
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-etcd
      spec:
        containers:
        - args:
          - ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
          command:
          - /bin/sh
          - -c
          env:
          - name: CONTIV_ETCD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: ETCD_NAME
            value: contiv-etcd
          - name: ETCD_DATA_DIR
            value: /var/lib/etcd/contiv-data
          - name: ETCD_LISTEN_CLIENT_URLS
            value: http://0.0.0.0:6666
          - name: ETCD_LISTEN_PEER_URLS
            value: http://0.0.0.0:6667
          image: quay.io/coreos/etcd:v3.2.4
          imagePullPolicy: IfNotPresent
          name: contiv-etcd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/etcd
            name: var-etcd
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          node-role.kubernetes.io/master: ""
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node.cloudprovider.kubernetes.io/uninitialized
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /var/etcd
            type: ""
          name: var-etcd
    templateGeneration: 1
    updateStrategy:
      type: OnDelete
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netplugin"},"name":"contiv-netplugin","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"contiv-netplugin"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-netplugin"}},"spec":{"containers":[{"command":["tail","-f","/dev/null"],"env":[{"name":"CONTIV_ROLE","value":"netplugin"},{"name":"CONTIV_NETPLUGIN_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_NETPLUGIN_VTEP_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"CONTIV_NETPLUGIN_FORWARD_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_fwdmode","name":"contiv-config"}}},{"name":"CONTIV_NETPLUGIN_NET_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_netmode","name":"contiv-config"}}}],"image":"contiv/netplugin:latest","name":"contiv-netplugin","resources":{"requests":{"cpu":"250m"}},"securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/var/run","name":"var-run","readOnly":false},{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/contiv/bin","name":"contiv-bin-dir","readOnly":true},{"mountPath":"/contiv/scripts/","name":"contiv-scripts-dir","readOnly":true},{"mountPath":"/var/log/contiv","name":"contiv-log-dir","readOnly":false}]}],"hostNetwork":true,"hostPID":true,"initContainers":[{"env":[{"name":"CONTIV_ROLE","value":"netplugin"},{"name":"CONTIV_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_K8S_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_k8s_config","name":"contiv-config"}}},{"name":"CONTIV_CNI_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_cni_config","name":"contiv-config"}}}],"image":"contiv/netplugin-init:latest","name":"contiv-netplugin-init","volumeMounts":[{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/etc/cni/net.d/","name":"etc-cni-dir","readOnly":false}]},{"command":["cp","/contiv/bin/contivk8s","/opt/cni/bin/contivk8s"],"image":"contiv/netplugin:latest","name":"contiv-cni","volumeMounts":[{"mountPath":"/opt/cni/bin","name":"cni-bin-dir","readOnly":false}]}],"serviceAccountName":"contiv-netplugin","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/var/run"},"name":"var-run"},{"hostPath":{"path":"/var/contiv"},"name":"var-contiv"},{"hostPath":{"path":"/opt/cni/bin"},"name":"cni-bin-dir"},{"hostPath":{"path":"/etc/cni/net.d/"},"name":"etc-cni-dir"},{"hostPath":{"path":"/opt/gopath/bin"},"name":"contiv-bin-dir"},{"hostPath":{"path":"/opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/"},"name":"contiv-scripts-dir"},{"hostPath":{"path":"/var/log/contiv"},"name":"contiv-log-dir"}]}}}}
    creationTimestamp: 2018-02-03T22:37:52Z
    generation: 1
    labels:
      k8s-app: contiv-netplugin
    name: contiv-netplugin
    namespace: kube-system
    resourceVersion: "3182"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/contiv-netplugin
    uid: defd0ade-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: contiv-netplugin
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-netplugin
      spec:
        containers:
        - command:
          - tail
          - -f
          - /dev/null
          env:
          - name: CONTIV_ROLE
            value: netplugin
          - name: CONTIV_NETPLUGIN_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_NETPLUGIN_VTEP_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: CONTIV_NETPLUGIN_FORWARD_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_fwdmode
                name: contiv-config
          - name: CONTIV_NETPLUGIN_NET_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_netmode
                name: contiv-config
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-netplugin
          resources:
            requests:
              cpu: 250m
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/run
            name: var-run
          - mountPath: /var/contiv
            name: var-contiv
          - mountPath: /contiv/bin
            name: contiv-bin-dir
            readOnly: true
          - mountPath: /contiv/scripts/
            name: contiv-scripts-dir
            readOnly: true
          - mountPath: /var/log/contiv
            name: contiv-log-dir
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        initContainers:
        - env:
          - name: CONTIV_ROLE
            value: netplugin
          - name: CONTIV_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_K8S_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_k8s_config
                name: contiv-config
          - name: CONTIV_CNI_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_cni_config
                name: contiv-config
          image: contiv/netplugin-init:latest
          imagePullPolicy: Always
          name: contiv-netplugin-init
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/contiv
            name: var-contiv
          - mountPath: /etc/cni/net.d/
            name: etc-cni-dir
        - command:
          - cp
          - /contiv/bin/contivk8s
          - /opt/cni/bin/contivk8s
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-cni
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /opt/cni/bin
            name: cni-bin-dir
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: contiv-netplugin
        serviceAccountName: contiv-netplugin
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - hostPath:
            path: /var/run
            type: ""
          name: var-run
        - hostPath:
            path: /var/contiv
            type: ""
          name: var-contiv
        - hostPath:
            path: /opt/cni/bin
            type: ""
          name: cni-bin-dir
        - hostPath:
            path: /etc/cni/net.d/
            type: ""
          name: etc-cni-dir
        - hostPath:
            path: /opt/gopath/bin
            type: ""
          name: contiv-bin-dir
        - hostPath:
            path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
            type: ""
          name: contiv-scripts-dir
        - hostPath:
            path: /var/log/contiv
            type: ""
          name: contiv-log-dir
    templateGeneration: 1
    updateStrategy:
      type: OnDelete
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-ovs"},"name":"contiv-ovs","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"contiv-ovs"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-ovs"}},"spec":{"containers":[{"command":["/scripts/start-ovsdb-server.sh"],"image":"contiv/ovs:latest","name":"contiv-ovsdb-server","securityContext":{"privileged":false},"volumeMounts":[{"mountPath":"/etc/openvswitch","name":"etc-openvswitch","readOnly":false},{"mountPath":"/var/run","name":"var-run","readOnly":false}]},{"command":["/scripts/start-ovs-vswitchd.sh"],"image":"contiv/ovs:latest","name":"contiv-ovs-vswitchd","securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/etc/openvswitch","name":"etc-openvswitch","readOnly":false},{"mountPath":"/lib/modules","name":"lib-modules","readOnly":true},{"mountPath":"/var/run","name":"var-run","readOnly":false}]}],"hostNetwork":true,"hostPID":true,"tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/etc/openvswitch"},"name":"etc-openvswitch"},{"hostPath":{"path":"/lib/modules"},"name":"lib-modules"},{"hostPath":{"path":"/var/run"},"name":"var-run"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    generation: 1
    labels:
      k8s-app: contiv-ovs
    name: contiv-ovs
    namespace: kube-system
    resourceVersion: "3167"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/contiv-ovs
    uid: df7106fa-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: contiv-ovs
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-ovs
      spec:
        containers:
        - command:
          - /scripts/start-ovsdb-server.sh
          image: contiv/ovs:latest
          imagePullPolicy: Always
          name: contiv-ovsdb-server
          resources: {}
          securityContext:
            privileged: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/openvswitch
            name: etc-openvswitch
          - mountPath: /var/run
            name: var-run
        - command:
          - /scripts/start-ovs-vswitchd.sh
          image: contiv/ovs:latest
          imagePullPolicy: Always
          name: contiv-ovs-vswitchd
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/openvswitch
            name: etc-openvswitch
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
          - mountPath: /var/run
            name: var-run
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - hostPath:
            path: /etc/openvswitch
            type: ""
          name: etc-openvswitch
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
        - hostPath:
            path: /var/run
            type: ""
          name: var-run
    templateGeneration: 1
    updateStrategy:
      type: OnDelete
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    creationTimestamp: 2018-02-03T22:37:38Z
    generation: 1
    labels:
      k8s-app: kube-proxy
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "2970"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/kube-proxy
    uid: d61ef82d-0932-11e8-9940-0800277561f7
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-proxy
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-proxy
      spec:
        containers:
        - command:
          - /usr/local/bin/kube-proxy
          - --config=/var/lib/kube-proxy/config.conf
          image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
          imagePullPolicy: IfNotPresent
          name: kube-proxy
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/kube-proxy
            name: kube-proxy
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-proxy
        serviceAccountName: kube-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - effect: NoSchedule
          key: node.cloudprovider.kubernetes.io/uninitialized
          value: "true"
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-proxy
          name: kube-proxy
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
    templateGeneration: 1
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 4
    desiredNumberScheduled: 4
    numberAvailable: 4
    numberMisscheduled: 0
    numberReady: 4
    observedGeneration: 1
    updatedNumberScheduled: 4
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get deployments --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get endpoints --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: v1
  kind: Endpoints
  metadata:
    creationTimestamp: 2018-02-03T22:37:35Z
    name: kubernetes
    namespace: default
    resourceVersion: "130"
    selfLink: /api/v1/namespaces/default/endpoints/kubernetes
    uid: d4b622d1-0932-11e8-9940-0800277561f7
  subsets:
  - addresses:
    - ip: 192.168.2.10
    ports:
    - name: https
      port: 6443
      protocol: TCP
- apiVersion: v1
  kind: Endpoints
  metadata:
    creationTimestamp: 2018-02-03T22:37:53Z
    labels:
      k8s-app: contiv-etcd
    name: contiv-etcd
    namespace: kube-system
    resourceVersion: "557"
    selfLink: /api/v1/namespaces/kube-system/endpoints/contiv-etcd
    uid: df6d1bb0-0932-11e8-9940-0800277561f7
  subsets:
  - addresses:
    - ip: 192.168.2.10
      nodeName: k8master
      targetRef:
        kind: Pod
        name: contiv-etcd-6mcxz
        namespace: kube-system
        resourceVersion: "556"
        uid: df3a7063-0932-11e8-9940-0800277561f7
    ports:
    - port: 6666
      protocol: TCP
- apiVersion: v1
  kind: Endpoints
  metadata:
    annotations:
      control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"k8master","leaseDurationSeconds":15,"acquireTime":"2018-02-03T22:37:34Z","renewTime":"2018-02-20T17:18:22Z","leaderTransitions":0}'
    creationTimestamp: 2018-02-03T22:37:34Z
    name: kube-controller-manager
    namespace: kube-system
    resourceVersion: "2035992"
    selfLink: /api/v1/namespaces/kube-system/endpoints/kube-controller-manager
    uid: d3f641df-0932-11e8-9940-0800277561f7
  subsets: null
- apiVersion: v1
  kind: Endpoints
  metadata:
    annotations:
      control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"k8master","leaseDurationSeconds":15,"acquireTime":"2018-02-03T22:37:35Z","renewTime":"2018-02-20T17:18:22Z","leaderTransitions":0}'
    creationTimestamp: 2018-02-03T22:37:35Z
    name: kube-scheduler
    namespace: kube-system
    resourceVersion: "2035993"
    selfLink: /api/v1/namespaces/kube-system/endpoints/kube-scheduler
    uid: d493eebd-0932-11e8-9940-0800277561f7
  subsets: null
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get events --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get horizontalpodautoscalers --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get ingresses --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get jobs --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get limitranges --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get namespaces --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: v1
  kind: Namespace
  metadata:
    creationTimestamp: 2018-02-03T22:37:31Z
    name: default
    namespace: ""
    resourceVersion: "6"
    selfLink: /api/v1/namespaces/default
    uid: d23ec639-0932-11e8-9940-0800277561f7
  spec:
    finalizers:
    - kubernetes
  status:
    phase: Active
- apiVersion: v1
  kind: Namespace
  metadata:
    creationTimestamp: 2018-02-03T22:37:35Z
    name: kube-public
    namespace: ""
    resourceVersion: "136"
    selfLink: /api/v1/namespaces/kube-public
    uid: d4c6f505-0932-11e8-9940-0800277561f7
  spec:
    finalizers:
    - kubernetes
  status:
    phase: Active
- apiVersion: v1
  kind: Namespace
  metadata:
    creationTimestamp: 2018-02-03T22:37:32Z
    name: kube-system
    namespace: ""
    resourceVersion: "12"
    selfLink: /api/v1/namespaces/kube-system
    uid: d2ccb5c7-0932-11e8-9940-0800277561f7
  spec:
    finalizers:
    - kubernetes
  status:
    phase: Active
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get networkpolicies --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get nodes --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: v1
  kind: Node
  metadata:
    annotations:
      node.alpha.kubernetes.io/ttl: "0"
      volumes.kubernetes.io/controller-managed-attach-detach: "true"
    creationTimestamp: 2018-02-03T22:37:31Z
    labels:
      beta.kubernetes.io/arch: amd64
      beta.kubernetes.io/os: linux
      kubernetes.io/hostname: k8master
      node-role.kubernetes.io/master: ""
    name: k8master
    namespace: ""
    resourceVersion: "2035997"
    selfLink: /api/v1/nodes/k8master
    uid: d2386232-0932-11e8-9940-0800277561f7
  spec:
    externalID: k8master
    taints:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
  status:
    addresses:
    - address: 192.168.2.10
      type: InternalIP
    - address: k8master
      type: Hostname
    allocatable:
      cpu: "8"
      memory: 3778784Ki
      pods: "110"
    capacity:
      cpu: "8"
      memory: 3881184Ki
      pods: "110"
    conditions:
    - lastHeartbeatTime: 2018-02-20T17:18:24Z
      lastTransitionTime: 2018-02-03T22:37:26Z
      message: kubelet has sufficient disk space available
      reason: KubeletHasSufficientDisk
      status: "False"
      type: OutOfDisk
    - lastHeartbeatTime: 2018-02-20T17:18:24Z
      lastTransitionTime: 2018-02-03T22:37:26Z
      message: kubelet has sufficient memory available
      reason: KubeletHasSufficientMemory
      status: "False"
      type: MemoryPressure
    - lastHeartbeatTime: 2018-02-20T17:18:24Z
      lastTransitionTime: 2018-02-03T22:37:26Z
      message: kubelet has no disk pressure
      reason: KubeletHasNoDiskPressure
      status: "False"
      type: DiskPressure
    - lastHeartbeatTime: 2018-02-20T17:18:24Z
      lastTransitionTime: 2018-02-03T22:40:09Z
      message: kubelet is posting ready status
      reason: KubeletReady
      status: "True"
      type: Ready
    daemonEndpoints:
      kubeletEndpoint:
        Port: 10250
    images:
    - names:
      - docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      - docker.io/contiv/netplugin:latest
      sizeBytes: 232848188
    - names:
      - gcr.io/google_containers/kube-apiserver-amd64@sha256:eec4329de0892f4a960b7f1202272f93880d3071a9b40d8407585125b37d527d
      - gcr.io/google_containers/kube-apiserver-amd64:v1.9.2
      sizeBytes: 210430863
    - names:
      - gcr.io/google_containers/etcd-amd64@sha256:54889c08665d241e321ca5ce976b2df0f766794b698d53faf6b7dacb95316680
      - gcr.io/google_containers/etcd-amd64:3.1.11
      sizeBytes: 193862870
    - names:
      - gcr.io/google_containers/kube-controller-manager-amd64@sha256:10daf65c6e8d0ff032323931f3869cd30af23feab90345265ea405b6104a41c7
      - gcr.io/google_containers/kube-controller-manager-amd64:v1.9.2
      sizeBytes: 137820233
    - names:
      - gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      - gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      sizeBytes: 109093516
    - names:
      - gcr.io/google_containers/kube-scheduler-amd64@sha256:082520e24e697f3228046ca13cddf46e4e01ae2982685b4ccc7df8f8e9145abc
      - gcr.io/google_containers/kube-scheduler-amd64:v1.9.2
      sizeBytes: 62710076
    - names:
      - quay.io/coreos/etcd@sha256:0a582c6ca6d32f1bed74c51bb1e33a215b301e0f28683777ec6af0c2e3925588
      - quay.io/coreos/etcd:v3.2.4
      sizeBytes: 35737458
    - names:
      - docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      - docker.io/contiv/ovs:latest
      sizeBytes: 22636521
    - names:
      - docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      - docker.io/contiv/netplugin-init:latest
      sizeBytes: 12223114
    - names:
      - gcr.io/google_containers/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516
      - gcr.io/google_containers/pause-amd64:3.0
      sizeBytes: 746888
    nodeInfo:
      architecture: amd64
      bootID: 2f1b43cc-19ef-4889-8565-4a3aa97005fc
      containerRuntimeVersion: docker://1.12.6
      kernelVersion: 3.10.0-514.21.1.el7.x86_64
      kubeProxyVersion: v1.9.2
      kubeletVersion: v1.9.2
      machineID: 1b74045253ca4eeb9b2954f6d03bbc8d
      operatingSystem: linux
      osImage: CentOS Linux 7 (Core)
      systemUUID: 635EC630-A4AA-44EC-BACA-F00D8977743C
- apiVersion: v1
  kind: Node
  metadata:
    annotations:
      node.alpha.kubernetes.io/ttl: "0"
      volumes.kubernetes.io/controller-managed-attach-detach: "true"
    creationTimestamp: 2018-02-03T22:47:42Z
    labels:
      beta.kubernetes.io/arch: amd64
      beta.kubernetes.io/os: linux
      kubernetes.io/hostname: k8node-01
    name: k8node-01
    namespace: ""
    resourceVersion: "2035987"
    selfLink: /api/v1/nodes/k8node-01
    uid: 3e886d68-0934-11e8-9940-0800277561f7
  spec:
    externalID: k8node-01
  status:
    addresses:
    - address: 192.168.2.11
      type: InternalIP
    - address: k8node-01
      type: Hostname
    allocatable:
      cpu: "4"
      memory: 1780992Ki
      pods: "110"
    capacity:
      cpu: "4"
      memory: 1883392Ki
      pods: "110"
    conditions:
    - lastHeartbeatTime: 2018-02-20T17:18:17Z
      lastTransitionTime: 2018-02-03T22:47:41Z
      message: kubelet has sufficient disk space available
      reason: KubeletHasSufficientDisk
      status: "False"
      type: OutOfDisk
    - lastHeartbeatTime: 2018-02-20T17:18:17Z
      lastTransitionTime: 2018-02-03T22:47:41Z
      message: kubelet has sufficient memory available
      reason: KubeletHasSufficientMemory
      status: "False"
      type: MemoryPressure
    - lastHeartbeatTime: 2018-02-20T17:18:17Z
      lastTransitionTime: 2018-02-03T22:47:41Z
      message: kubelet has no disk pressure
      reason: KubeletHasNoDiskPressure
      status: "False"
      type: DiskPressure
    - lastHeartbeatTime: 2018-02-20T17:18:17Z
      lastTransitionTime: 2018-02-03T22:49:02Z
      message: kubelet is posting ready status
      reason: KubeletReady
      status: "True"
      type: Ready
    daemonEndpoints:
      kubeletEndpoint:
        Port: 10250
    images:
    - names:
      - docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      - docker.io/contiv/netplugin:latest
      sizeBytes: 232848188
    - names:
      - gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      - gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      sizeBytes: 109093516
    - names:
      - docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      - docker.io/contiv/ovs:latest
      sizeBytes: 22636521
    - names:
      - docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      - docker.io/contiv/netplugin-init:latest
      sizeBytes: 12223114
    - names:
      - docker.io/contiv/alpine@sha256:3cd9a0a4477f1dd764d962edeb784c4c2f609d6533fb3e3d12a7e86819c75462
      - docker.io/contiv/alpine:latest
      sizeBytes: 5512522
    - names:
      - gcr.io/google_containers/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516
      - gcr.io/google_containers/pause-amd64:3.0
      sizeBytes: 746888
    nodeInfo:
      architecture: amd64
      bootID: 22bd2342-b740-4952-8aae-5cf224bdc04f
      containerRuntimeVersion: docker://1.12.6
      kernelVersion: 3.10.0-514.21.1.el7.x86_64
      kubeProxyVersion: v1.9.2
      kubeletVersion: v1.9.2
      machineID: 1b74045253ca4eeb9b2954f6d03bbc8d
      operatingSystem: linux
      osImage: CentOS Linux 7 (Core)
      systemUUID: EC0AB437-FE8A-418F-997F-E581C1E5BB2D
- apiVersion: v1
  kind: Node
  metadata:
    annotations:
      node.alpha.kubernetes.io/ttl: "0"
      volumes.kubernetes.io/controller-managed-attach-detach: "true"
    creationTimestamp: 2018-02-03T22:55:35Z
    labels:
      beta.kubernetes.io/arch: amd64
      beta.kubernetes.io/os: linux
      kubernetes.io/hostname: k8node-02
    name: k8node-02
    namespace: ""
    resourceVersion: "2035984"
    selfLink: /api/v1/nodes/k8node-02
    uid: 583bfa9e-0935-11e8-9940-0800277561f7
  spec:
    externalID: k8node-02
  status:
    addresses:
    - address: 192.168.2.12
      type: InternalIP
    - address: k8node-02
      type: Hostname
    allocatable:
      cpu: "4"
      memory: 1780992Ki
      pods: "110"
    capacity:
      cpu: "4"
      memory: 1883392Ki
      pods: "110"
    conditions:
    - lastHeartbeatTime: 2018-02-20T17:18:16Z
      lastTransitionTime: 2018-02-03T22:55:33Z
      message: kubelet has sufficient disk space available
      reason: KubeletHasSufficientDisk
      status: "False"
      type: OutOfDisk
    - lastHeartbeatTime: 2018-02-20T17:18:16Z
      lastTransitionTime: 2018-02-03T22:55:33Z
      message: kubelet has sufficient memory available
      reason: KubeletHasSufficientMemory
      status: "False"
      type: MemoryPressure
    - lastHeartbeatTime: 2018-02-20T17:18:16Z
      lastTransitionTime: 2018-02-03T22:55:33Z
      message: kubelet has no disk pressure
      reason: KubeletHasNoDiskPressure
      status: "False"
      type: DiskPressure
    - lastHeartbeatTime: 2018-02-20T17:18:16Z
      lastTransitionTime: 2018-02-03T23:01:06Z
      message: kubelet is posting ready status
      reason: KubeletReady
      status: "True"
      type: Ready
    daemonEndpoints:
      kubeletEndpoint:
        Port: 10250
    images:
    - names:
      - docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      - docker.io/contiv/netplugin:latest
      sizeBytes: 232848188
    - names:
      - gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      - gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      sizeBytes: 109093516
    - names:
      - docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      - docker.io/contiv/ovs:latest
      sizeBytes: 22636521
    - names:
      - docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      - docker.io/contiv/netplugin-init:latest
      sizeBytes: 12223114
    - names:
      - docker.io/contiv/alpine@sha256:3cd9a0a4477f1dd764d962edeb784c4c2f609d6533fb3e3d12a7e86819c75462
      - docker.io/contiv/alpine:latest
      sizeBytes: 5512522
    - names:
      - gcr.io/google_containers/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516
      - gcr.io/google_containers/pause-amd64:3.0
      sizeBytes: 746888
    nodeInfo:
      architecture: amd64
      bootID: 308ca593-5afe-4cef-9a2b-45c73951cfee
      containerRuntimeVersion: docker://1.12.6
      kernelVersion: 3.10.0-514.21.1.el7.x86_64
      kubeProxyVersion: v1.9.2
      kubeletVersion: v1.9.2
      machineID: 1b74045253ca4eeb9b2954f6d03bbc8d
      operatingSystem: linux
      osImage: CentOS Linux 7 (Core)
      systemUUID: 4179196B-7C4A-465F-AD70-9CBA1074CB4A
- apiVersion: v1
  kind: Node
  metadata:
    annotations:
      node.alpha.kubernetes.io/ttl: "0"
      volumes.kubernetes.io/controller-managed-attach-detach: "true"
    creationTimestamp: 2018-02-03T23:06:36Z
    labels:
      beta.kubernetes.io/arch: amd64
      beta.kubernetes.io/os: linux
      kubernetes.io/hostname: k8node-03
    name: k8node-03
    namespace: ""
    resourceVersion: "2035994"
    selfLink: /api/v1/nodes/k8node-03
    uid: e2391883-0936-11e8-9940-0800277561f7
  spec:
    externalID: k8node-03
  status:
    addresses:
    - address: 192.168.2.13
      type: InternalIP
    - address: k8node-03
      type: Hostname
    allocatable:
      cpu: "4"
      memory: 1780992Ki
      pods: "110"
    capacity:
      cpu: "4"
      memory: 1883392Ki
      pods: "110"
    conditions:
    - lastHeartbeatTime: 2018-02-20T17:18:23Z
      lastTransitionTime: 2018-02-03T23:06:35Z
      message: kubelet has sufficient disk space available
      reason: KubeletHasSufficientDisk
      status: "False"
      type: OutOfDisk
    - lastHeartbeatTime: 2018-02-20T17:18:23Z
      lastTransitionTime: 2018-02-03T23:06:35Z
      message: kubelet has sufficient memory available
      reason: KubeletHasSufficientMemory
      status: "False"
      type: MemoryPressure
    - lastHeartbeatTime: 2018-02-20T17:18:23Z
      lastTransitionTime: 2018-02-03T23:06:35Z
      message: kubelet has no disk pressure
      reason: KubeletHasNoDiskPressure
      status: "False"
      type: DiskPressure
    - lastHeartbeatTime: 2018-02-20T17:18:23Z
      lastTransitionTime: 2018-02-03T23:09:16Z
      message: kubelet is posting ready status
      reason: KubeletReady
      status: "True"
      type: Ready
    daemonEndpoints:
      kubeletEndpoint:
        Port: 10250
    images:
    - names:
      - docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      - docker.io/contiv/netplugin:latest
      sizeBytes: 232848188
    - names:
      - gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      - gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      sizeBytes: 109093516
    - names:
      - docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      - docker.io/contiv/ovs:latest
      sizeBytes: 22636521
    - names:
      - docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      - docker.io/contiv/netplugin-init:latest
      sizeBytes: 12223114
    - names:
      - docker.io/contiv/alpine@sha256:3cd9a0a4477f1dd764d962edeb784c4c2f609d6533fb3e3d12a7e86819c75462
      - docker.io/contiv/alpine:latest
      sizeBytes: 5512522
    - names:
      - gcr.io/google_containers/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516
      - gcr.io/google_containers/pause-amd64:3.0
      sizeBytes: 746888
    nodeInfo:
      architecture: amd64
      bootID: f9a6e775-b559-423e-91e1-10e300dbdc9e
      containerRuntimeVersion: docker://1.12.6
      kernelVersion: 3.10.0-514.21.1.el7.x86_64
      kubeProxyVersion: v1.9.2
      kubeletVersion: v1.9.2
      machineID: 1b74045253ca4eeb9b2954f6d03bbc8d
      operatingSystem: linux
      osImage: CentOS Linux 7 (Core)
      systemUUID: CC5E8550-8042-48BD-BAC3-778F77B2C6E8
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get persistentvolumeclaims --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get persistentvolumes --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get poddisruptionbudgets --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get podpreset --all-namespaces -o yaml
================\n
the server doesn't have a resource type "podpreset"
\n================
kubectl get pods --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:37:53Z
    generateName: contiv-etcd-
    labels:
      controller-revision-hash: "3440706255"
      k8s-app: contiv-etcd
      pod-template-generation: "1"
    name: contiv-etcd-6mcxz
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-etcd
      uid: df32d0df-0932-11e8-9940-0800277561f7
    resourceVersion: "556"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-etcd-6mcxz
    uid: df3a7063-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - args:
      - ETCD_ADVERTISE_CLIENT_URLS=http://$CONTIV_ETCD_IP:6666 /usr/local/bin/etcd
      command:
      - /bin/sh
      - -c
      env:
      - name: CONTIV_ETCD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: ETCD_NAME
        value: contiv-etcd
      - name: ETCD_DATA_DIR
        value: /var/lib/etcd/contiv-data
      - name: ETCD_LISTEN_CLIENT_URLS
        value: http://0.0.0.0:6666
      - name: ETCD_LISTEN_PEER_URLS
        value: http://0.0.0.0:6667
      image: quay.io/coreos/etcd:v3.2.4
      imagePullPolicy: IfNotPresent
      name: contiv-etcd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/etcd
        name: var-etcd
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    nodeSelector:
      node-role.kubernetes.io/master: ""
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: "true"
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /var/etcd
        type: ""
      name: var-etcd
    - name: default-token-9ktff
      secret:
        defaultMode: 420
        secretName: default-token-9ktff
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:37:53Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:41:00Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:38:42Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c584086fab59c85c04c80b189f2b74361d8249d629812f1f12062311d6329732
      image: quay.io/coreos/etcd:v3.2.4
      imageID: docker-pullable://quay.io/coreos/etcd@sha256:0a582c6ca6d32f1bed74c51bb1e33a215b301e0f28683777ec6af0c2e3925588
      lastState: {}
      name: contiv-etcd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:40:57Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: BestEffort
    startTime: 2018-02-03T22:37:53Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:37:53Z
    generateName: contiv-netmaster-
    labels:
      k8s-app: contiv-netmaster
    name: contiv-netmaster-vkc6s
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: contiv-netmaster
      uid: df1a16b8-0932-11e8-9940-0800277561f7
    resourceVersion: "776"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-netmaster-vkc6s
    uid: df377d13-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - tail
      - -f
      - /dev/null
      env:
      - name: CONTIV_ROLE
        value: netmaster
      - name: CONTIV_NETMASTER_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_NETMASTER_FORWARD_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_fwdmode
            name: contiv-config
      - name: CONTIV_NETMASTER_NET_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_netmode
            name: contiv-config
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netmaster
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /contiv/bin
        name: contiv-bin-dir
        readOnly: true
      - mountPath: /contiv/scripts/
        name: contiv-scripts-dir
        readOnly: true
      - mountPath: /var/log/contiv
        name: contiv-log-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netmaster-token-47bxd
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    initContainers:
    - env:
      - name: CONTIV_ROLE
        value: netmaster
      - name: CONTIV_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_K8S_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_k8s_config
            name: contiv-config
      - name: CONTIV_CNI_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_cni_config
            name: contiv-config
      image: contiv/netplugin-init:latest
      imagePullPolicy: Always
      name: contiv-netplugin-init
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netmaster-token-47bxd
        readOnly: true
    - command:
      - cp
      - /contiv/bin/netctl
      - /usr/local/sbin/netctl
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netctl
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /usr/local/sbin/
        name: usr-local-sbin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netmaster-token-47bxd
        readOnly: true
    nodeName: k8master
    nodeSelector:
      node-role.kubernetes.io/master: ""
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: contiv-netmaster
    serviceAccountName: contiv-netmaster
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /var/contiv
        type: ""
      name: var-contiv
    - hostPath:
        path: /usr/local/sbin/
        type: ""
      name: usr-local-sbin
    - hostPath:
        path: /opt/gopath/bin
        type: ""
      name: contiv-bin-dir
    - hostPath:
        path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
        type: ""
      name: contiv-scripts-dir
    - hostPath:
        path: /var/log/contiv
        type: ""
      name: contiv-log-dir
    - name: contiv-netmaster-token-47bxd
      secret:
        defaultMode: 420
        secretName: contiv-netmaster-token-47bxd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:45:09Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:45:20Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:40:22Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://dd9e75217cfb963e0806de0d573fe10d28e9f71ff7e8fc560825e2e753903661
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netmaster
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:45:18Z
    hostIP: 192.168.2.10
    initContainerStatuses:
    - containerID: docker://e1993b2b63c42729f6d24eaac6e4805e3509e39d08ff3078e27e5a52f8a2d74a
      image: docker.io/contiv/netplugin-init:latest
      imageID: docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      lastState: {}
      name: contiv-netplugin-init
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://e1993b2b63c42729f6d24eaac6e4805e3509e39d08ff3078e27e5a52f8a2d74a
          exitCode: 0
          finishedAt: 2018-02-03T22:44:49Z
          reason: Completed
          startedAt: 2018-02-03T22:44:46Z
    - containerID: docker://0c9a499dd9a3f027c6aafa2fadac4820d4977eb6a6e036638ac8f3f32c636834
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netctl
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://0c9a499dd9a3f027c6aafa2fadac4820d4977eb6a6e036638ac8f3f32c636834
          exitCode: 0
          finishedAt: 2018-02-03T22:45:07Z
          reason: Completed
          startedAt: 2018-02-03T22:45:07Z
    phase: Running
    podIP: 192.168.2.10
    qosClass: BestEffort
    startTime: 2018-02-03T22:40:22Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:55:35Z
    generateName: contiv-netplugin-
    labels:
      controller-revision-hash: "4029632485"
      k8s-app: contiv-netplugin
      pod-template-generation: "1"
    name: contiv-netplugin-2d7rp
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-netplugin
      uid: defd0ade-0932-11e8-9940-0800277561f7
    resourceVersion: "2733"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-netplugin-2d7rp
    uid: 58794095-0935-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - tail
      - -f
      - /dev/null
      env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_NETPLUGIN_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_VTEP_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: CONTIV_NETPLUGIN_FORWARD_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_fwdmode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_NET_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_netmode
            name: contiv-config
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netplugin
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /contiv/bin
        name: contiv-bin-dir
        readOnly: true
      - mountPath: /contiv/scripts/
        name: contiv-scripts-dir
        readOnly: true
      - mountPath: /var/log/contiv
        name: contiv-log-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    initContainers:
    - env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_K8S_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_k8s_config
            name: contiv-config
      - name: CONTIV_CNI_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_cni_config
            name: contiv-config
      image: contiv/netplugin-init:latest
      imagePullPolicy: Always
      name: contiv-netplugin-init
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /etc/cni/net.d/
        name: etc-cni-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    - command:
      - cp
      - /contiv/bin/contivk8s
      - /opt/cni/bin/contivk8s
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    nodeName: k8node-02
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: contiv-netplugin
    serviceAccountName: contiv-netplugin
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - hostPath:
        path: /var/contiv
        type: ""
      name: var-contiv
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d/
        type: ""
      name: etc-cni-dir
    - hostPath:
        path: /opt/gopath/bin
        type: ""
      name: contiv-bin-dir
    - hostPath:
        path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
        type: ""
      name: contiv-scripts-dir
    - hostPath:
        path: /var/log/contiv
        type: ""
      name: contiv-log-dir
    - name: contiv-netplugin-token-xqsb5
      secret:
        defaultMode: 420
        secretName: contiv-netplugin-token-xqsb5
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:06:54Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:08:20Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:57:03Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://d87a66a8c2913d4ec5daecfadf73b64e38872b00b37a1e58021b4c465654ef72
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netplugin
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:08:19Z
    hostIP: 192.168.2.12
    initContainerStatuses:
    - containerID: docker://92bb1a18866c331d3273f8c89b77e922ae6370346d8ca90e077419edede9193c
      image: docker.io/contiv/netplugin-init:latest
      imageID: docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      lastState: {}
      name: contiv-netplugin-init
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://92bb1a18866c331d3273f8c89b77e922ae6370346d8ca90e077419edede9193c
          exitCode: 0
          finishedAt: 2018-02-03T23:00:52Z
          reason: Completed
          startedAt: 2018-02-03T23:00:52Z
    - containerID: docker://26a9d7ca4ecda56afd9b216076f091466ee1a40b7a81f30907af18446d947064
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://26a9d7ca4ecda56afd9b216076f091466ee1a40b7a81f30907af18446d947064
          exitCode: 0
          finishedAt: 2018-02-03T23:06:16Z
          reason: Completed
          startedAt: 2018-02-03T23:06:16Z
    phase: Running
    podIP: 192.168.2.12
    qosClass: Burstable
    startTime: 2018-02-03T22:55:38Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T23:06:36Z
    generateName: contiv-netplugin-
    labels:
      controller-revision-hash: "4029632485"
      k8s-app: contiv-netplugin
      pod-template-generation: "1"
    name: contiv-netplugin-5pqjs
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-netplugin
      uid: defd0ade-0932-11e8-9940-0800277561f7
    resourceVersion: "3181"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-netplugin-5pqjs
    uid: e2725eca-0936-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - tail
      - -f
      - /dev/null
      env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_NETPLUGIN_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_VTEP_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: CONTIV_NETPLUGIN_FORWARD_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_fwdmode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_NET_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_netmode
            name: contiv-config
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netplugin
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /contiv/bin
        name: contiv-bin-dir
        readOnly: true
      - mountPath: /contiv/scripts/
        name: contiv-scripts-dir
        readOnly: true
      - mountPath: /var/log/contiv
        name: contiv-log-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    initContainers:
    - env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_K8S_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_k8s_config
            name: contiv-config
      - name: CONTIV_CNI_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_cni_config
            name: contiv-config
      image: contiv/netplugin-init:latest
      imagePullPolicy: Always
      name: contiv-netplugin-init
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /etc/cni/net.d/
        name: etc-cni-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    - command:
      - cp
      - /contiv/bin/contivk8s
      - /opt/cni/bin/contivk8s
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    nodeName: k8node-03
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: contiv-netplugin
    serviceAccountName: contiv-netplugin
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - hostPath:
        path: /var/contiv
        type: ""
      name: var-contiv
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d/
        type: ""
      name: etc-cni-dir
    - hostPath:
        path: /opt/gopath/bin
        type: ""
      name: contiv-bin-dir
    - hostPath:
        path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
        type: ""
      name: contiv-scripts-dir
    - hostPath:
        path: /var/log/contiv
        type: ""
      name: contiv-log-dir
    - name: contiv-netplugin-token-xqsb5
      secret:
        defaultMode: 420
        secretName: contiv-netplugin-token-xqsb5
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:13:09Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:13:15Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:08:03Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://71658aba1dea2b49ad888b5d6880c5313dc5635945df76491a5f51d33da5d857
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netplugin
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:13:14Z
    hostIP: 192.168.2.13
    initContainerStatuses:
    - containerID: docker://d3d3cae725515e434b8fffe529d9255b15a9a7772812aa604997b727ecae8933
      image: docker.io/contiv/netplugin-init:latest
      imageID: docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      lastState: {}
      name: contiv-netplugin-init
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://d3d3cae725515e434b8fffe529d9255b15a9a7772812aa604997b727ecae8933
          exitCode: 0
          finishedAt: 2018-02-03T23:09:07Z
          reason: Completed
          startedAt: 2018-02-03T23:09:07Z
    - containerID: docker://80fe8f20c15247503588028d51f9595ed406561b1d940c1e47e1b473b70ff967
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://80fe8f20c15247503588028d51f9595ed406561b1d940c1e47e1b473b70ff967
          exitCode: 0
          finishedAt: 2018-02-03T23:13:07Z
          reason: Completed
          startedAt: 2018-02-03T23:13:07Z
    phase: Running
    podIP: 192.168.2.13
    qosClass: Burstable
    startTime: 2018-02-03T23:06:39Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:37:53Z
    generateName: contiv-netplugin-
    labels:
      controller-revision-hash: "4029632485"
      k8s-app: contiv-netplugin
      pod-template-generation: "1"
    name: contiv-netplugin-qwgd5
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-netplugin
      uid: defd0ade-0932-11e8-9940-0800277561f7
    resourceVersion: "760"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-netplugin-qwgd5
    uid: df13632a-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - tail
      - -f
      - /dev/null
      env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_NETPLUGIN_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_VTEP_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: CONTIV_NETPLUGIN_FORWARD_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_fwdmode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_NET_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_netmode
            name: contiv-config
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netplugin
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /contiv/bin
        name: contiv-bin-dir
        readOnly: true
      - mountPath: /contiv/scripts/
        name: contiv-scripts-dir
        readOnly: true
      - mountPath: /var/log/contiv
        name: contiv-log-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    initContainers:
    - env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_K8S_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_k8s_config
            name: contiv-config
      - name: CONTIV_CNI_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_cni_config
            name: contiv-config
      image: contiv/netplugin-init:latest
      imagePullPolicy: Always
      name: contiv-netplugin-init
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /etc/cni/net.d/
        name: etc-cni-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    - command:
      - cp
      - /contiv/bin/contivk8s
      - /opt/cni/bin/contivk8s
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: contiv-netplugin
    serviceAccountName: contiv-netplugin
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - hostPath:
        path: /var/contiv
        type: ""
      name: var-contiv
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d/
        type: ""
      name: etc-cni-dir
    - hostPath:
        path: /opt/gopath/bin
        type: ""
      name: contiv-bin-dir
    - hostPath:
        path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
        type: ""
      name: contiv-scripts-dir
    - hostPath:
        path: /var/log/contiv
        type: ""
      name: contiv-log-dir
    - name: contiv-netplugin-token-xqsb5
      secret:
        defaultMode: 420
        secretName: contiv-netplugin-token-xqsb5
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:44:52Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:45:10Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:38:53Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://a4137c814f9832676d7df279495ab131f77f1119ad666633ee0cae9c8d6f4c1b
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netplugin
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:45:09Z
    hostIP: 192.168.2.10
    initContainerStatuses:
    - containerID: docker://04bc313a43b9a37cb93d161cdcb4e002824307b5c7db2b0ea664a577e879dd19
      image: docker.io/contiv/netplugin-init:latest
      imageID: docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      lastState: {}
      name: contiv-netplugin-init
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://04bc313a43b9a37cb93d161cdcb4e002824307b5c7db2b0ea664a577e879dd19
          exitCode: 0
          finishedAt: 2018-02-03T22:40:12Z
          reason: Completed
          startedAt: 2018-02-03T22:40:07Z
    - containerID: docker://1e9df8ab383baf7e9890712058863f523b437a26acb84659006ede9551d3e533
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://1e9df8ab383baf7e9890712058863f523b437a26acb84659006ede9551d3e533
          exitCode: 0
          finishedAt: 2018-02-03T22:44:39Z
          reason: Completed
          startedAt: 2018-02-03T22:44:39Z
    phase: Running
    podIP: 192.168.2.10
    qosClass: Burstable
    startTime: 2018-02-03T22:37:53Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:47:42Z
    generateName: contiv-netplugin-
    labels:
      controller-revision-hash: "4029632485"
      k8s-app: contiv-netplugin
      pod-template-generation: "1"
    name: contiv-netplugin-xwxkn
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-netplugin
      uid: defd0ade-0932-11e8-9940-0800277561f7
    resourceVersion: "2271"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-netplugin-xwxkn
    uid: 3eb6c622-0934-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - tail
      - -f
      - /dev/null
      env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_NETPLUGIN_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_VTEP_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: CONTIV_NETPLUGIN_FORWARD_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_fwdmode
            name: contiv-config
      - name: CONTIV_NETPLUGIN_NET_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_netmode
            name: contiv-config
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-netplugin
      resources:
        requests:
          cpu: 250m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /contiv/bin
        name: contiv-bin-dir
        readOnly: true
      - mountPath: /contiv/scripts/
        name: contiv-scripts-dir
        readOnly: true
      - mountPath: /var/log/contiv
        name: contiv-log-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    initContainers:
    - env:
      - name: CONTIV_ROLE
        value: netplugin
      - name: CONTIV_MODE
        valueFrom:
          configMapKeyRef:
            key: contiv_mode
            name: contiv-config
      - name: CONTIV_K8S_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_k8s_config
            name: contiv-config
      - name: CONTIV_CNI_CONFIG
        valueFrom:
          configMapKeyRef:
            key: contiv_cni_config
            name: contiv-config
      image: contiv/netplugin-init:latest
      imagePullPolicy: Always
      name: contiv-netplugin-init
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/contiv
        name: var-contiv
      - mountPath: /etc/cni/net.d/
        name: etc-cni-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    - command:
      - cp
      - /contiv/bin/contivk8s
      - /opt/cni/bin/contivk8s
      image: contiv/netplugin:latest
      imagePullPolicy: Always
      name: contiv-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-bin-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: contiv-netplugin-token-xqsb5
        readOnly: true
    nodeName: k8node-01
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: contiv-netplugin
    serviceAccountName: contiv-netplugin
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - hostPath:
        path: /var/contiv
        type: ""
      name: var-contiv
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d/
        type: ""
      name: etc-cni-dir
    - hostPath:
        path: /opt/gopath/bin
        type: ""
      name: contiv-bin-dir
    - hostPath:
        path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
        type: ""
      name: contiv-scripts-dir
    - hostPath:
        path: /var/log/contiv
        type: ""
      name: contiv-log-dir
    - name: contiv-netplugin-token-xqsb5
      secret:
        defaultMode: 420
        secretName: contiv-netplugin-token-xqsb5
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:03:03Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:03:20Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:48:22Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://9aaa1c9cb44a3e36a18bec6f9cf00f1c82e7c319ecbcd73cb78b208f7bcd5a44
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-netplugin
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:03:18Z
    hostIP: 192.168.2.11
    initContainerStatuses:
    - containerID: docker://d1526ce58adecc381edae40be851e718f64e6055678245513dc1cca02567c455
      image: docker.io/contiv/netplugin-init:latest
      imageID: docker-pullable://docker.io/contiv/netplugin-init@sha256:7ec633cea6ad99d0a672a55171d1f8f7d4d4d26a32c553867b142df8f0742412
      lastState: {}
      name: contiv-netplugin-init
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://d1526ce58adecc381edae40be851e718f64e6055678245513dc1cca02567c455
          exitCode: 0
          finishedAt: 2018-02-03T22:48:51Z
          reason: Completed
          startedAt: 2018-02-03T22:48:51Z
    - containerID: docker://d47429eb736387693dcf5a8c9befea3aaec5353b18870a1ff084c2fbb7a4ef03
      image: docker.io/contiv/netplugin:latest
      imageID: docker-pullable://docker.io/contiv/netplugin@sha256:2e803b1306abef3da3614cd0b1754b503aa914ebe3d9bf13ea3d46b4376dbebf
      lastState: {}
      name: contiv-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://d47429eb736387693dcf5a8c9befea3aaec5353b18870a1ff084c2fbb7a4ef03
          exitCode: 0
          finishedAt: 2018-02-03T23:03:00Z
          reason: Completed
          startedAt: 2018-02-03T23:02:59Z
    phase: Running
    podIP: 192.168.2.11
    qosClass: Burstable
    startTime: 2018-02-03T22:47:46Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:55:35Z
    generateName: contiv-ovs-
    labels:
      controller-revision-hash: "1824568849"
      k8s-app: contiv-ovs
      pod-template-generation: "1"
    name: contiv-ovs-8mfdn
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-ovs
      uid: df7106fa-0932-11e8-9940-0800277561f7
    resourceVersion: "2607"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-ovs-8mfdn
    uid: 589ce7a8-0935-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /scripts/start-ovsdb-server.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovsdb-server
      resources: {}
      securityContext:
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    - command:
      - /scripts/start-ovs-vswitchd.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovs-vswitchd
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    nodeName: k8node-02
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/openvswitch
        type: ""
      name: etc-openvswitch
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - name: default-token-9ktff
      secret:
        defaultMode: 420
        secretName: default-token-9ktff
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:55:38Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:06:55Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:06:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://5d3a3a03ca28ba31d3193f5c24367d5df59e620d5ef4b4012648498f54b37464
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovs-vswitchd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:06:21Z
    - containerID: docker://9cb6eb87e5781c179ce895e55b02f926f3a7abcaf7a23c35a67dfcfe1a3c561d
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovsdb-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:01:06Z
    hostIP: 192.168.2.12
    phase: Running
    podIP: 192.168.2.12
    qosClass: BestEffort
    startTime: 2018-02-03T22:55:38Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:37:53Z
    generateName: contiv-ovs-
    labels:
      controller-revision-hash: "1824568849"
      k8s-app: contiv-ovs
      pod-template-generation: "1"
    name: contiv-ovs-mwfjk
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-ovs
      uid: df7106fa-0932-11e8-9940-0800277561f7
    resourceVersion: "734"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-ovs-mwfjk
    uid: df87efc2-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /scripts/start-ovsdb-server.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovsdb-server
      resources: {}
      securityContext:
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    - command:
      - /scripts/start-ovs-vswitchd.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovs-vswitchd
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/openvswitch
        type: ""
      name: etc-openvswitch
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - name: default-token-9ktff
      secret:
        defaultMode: 420
        secretName: default-token-9ktff
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:37:53Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:44:52Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:44:52Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://e32264562935b103bb84aa237add0c06ab70136ff288263bc78c03a3f0475553
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovs-vswitchd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:44:51Z
    - containerID: docker://39e7cc6199270908b8fd259c1ff09e21af4cf64c5714d3525923ec8566555232
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovsdb-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:41:33Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: BestEffort
    startTime: 2018-02-03T22:37:53Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T23:06:37Z
    generateName: contiv-ovs-
    labels:
      controller-revision-hash: "1824568849"
      k8s-app: contiv-ovs
      pod-template-generation: "1"
    name: contiv-ovs-zmk5s
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-ovs
      uid: df7106fa-0932-11e8-9940-0800277561f7
    resourceVersion: "3166"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-ovs-zmk5s
    uid: e2aab8a2-0936-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /scripts/start-ovsdb-server.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovsdb-server
      resources: {}
      securityContext:
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    - command:
      - /scripts/start-ovs-vswitchd.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovs-vswitchd
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    nodeName: k8node-03
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/openvswitch
        type: ""
      name: etc-openvswitch
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - name: default-token-9ktff
      secret:
        defaultMode: 420
        secretName: default-token-9ktff
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:06:39Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:13:09Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:08:04Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://364a2a0e04c9e14f0ca1c85e40986f3d09b4643c45c5df03df4bbc06f26c456c
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovs-vswitchd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:13:08Z
    - containerID: docker://dc98559482d862433e27244ecd0ee36fce64027dfb6ce1798ef6f633b6ae3e35
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovsdb-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:09:37Z
    hostIP: 192.168.2.13
    phase: Running
    podIP: 192.168.2.13
    qosClass: BestEffort
    startTime: 2018-02-03T23:06:39Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:47:43Z
    generateName: contiv-ovs-
    labels:
      controller-revision-hash: "1824568849"
      k8s-app: contiv-ovs
      pod-template-generation: "1"
    name: contiv-ovs-zwb9t
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: contiv-ovs
      uid: df7106fa-0932-11e8-9940-0800277561f7
    resourceVersion: "1430"
    selfLink: /api/v1/namespaces/kube-system/pods/contiv-ovs-zwb9t
    uid: 3ec118ff-0934-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /scripts/start-ovsdb-server.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovsdb-server
      resources: {}
      securityContext:
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    - command:
      - /scripts/start-ovs-vswitchd.sh
      image: contiv/ovs:latest
      imagePullPolicy: Always
      name: contiv-ovs-vswitchd
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/openvswitch
        name: etc-openvswitch
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run
        name: var-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-9ktff
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    hostPID: true
    nodeName: k8node-01
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/openvswitch
        type: ""
      name: etc-openvswitch
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /var/run
        type: ""
      name: var-run
    - name: default-token-9ktff
      secret:
        defaultMode: 420
        secretName: default-token-9ktff
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:47:46Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:53:35Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:53:35Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://9fc9fad02f6bb178f3e63e4d2023e34c7f93abc1a350e61630c3360acc770902
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovs-vswitchd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:53:33Z
    - containerID: docker://abfd1933ea861649f13510742edc983ea29e56c8c7f0002bc8515e1763423157
      image: docker.io/contiv/ovs:latest
      imageID: docker-pullable://docker.io/contiv/ovs@sha256:5a46792145adf97bac7884415274c373ecde9180cc0bf860fe4272898d768f6d
      lastState: {}
      name: contiv-ovsdb-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:51:27Z
    hostIP: 192.168.2.11
    phase: Running
    podIP: 192.168.2.11
    qosClass: BestEffort
    startTime: 2018-02-03T22:47:46Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 7278f85057e8bf5cb81c9f96d3b25320
      kubernetes.io/config.mirror: 7278f85057e8bf5cb81c9f96d3b25320
      kubernetes.io/config.seen: 2018-02-03T22:31:50.423856543Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:38:26Z
    labels:
      component: etcd
      tier: control-plane
    name: etcd-k8master
    namespace: kube-system
    resourceVersion: "431"
    selfLink: /api/v1/namespaces/kube-system/pods/etcd-k8master
    uid: f3035191-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - etcd
      - --listen-client-urls=http://127.0.0.1:2379
      - --advertise-client-urls=http://127.0.0.1:2379
      - --data-dir=/var/lib/etcd
      image: gcr.io/google_containers/etcd-amd64:3.1.11
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health
          port: 2379
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/etcd
        name: etcd
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/etcd
        type: DirectoryOrCreate
      name: etcd
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:35:32Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://eab796c7ae3cc778244b6175dc7a8e081f57b4dd79bfc77346b5e12e1e87460e
      image: gcr.io/google_containers/etcd-amd64:3.1.11
      imageID: docker-pullable://gcr.io/google_containers/etcd-amd64@sha256:54889c08665d241e321ca5ce976b2df0f766794b698d53faf6b7dacb95316680
      lastState: {}
      name: etcd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:35:31Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: BestEffort
    startTime: 2018-02-03T22:31:55Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 8269013687f7c93ae98df858c8ca8f73
      kubernetes.io/config.mirror: 8269013687f7c93ae98df858c8ca8f73
      kubernetes.io/config.seen: 2018-02-03T22:31:50.423866266Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:38:53Z
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-k8master
    namespace: kube-system
    resourceVersion: "457"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-apiserver-k8master
    uid: 0335ef59-0933-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - kube-apiserver
      - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      - --secure-port=6443
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --requestheader-allowed-names=front-proxy-client
      - --service-cluster-ip-range=10.96.0.0/12
      - --service-account-key-file=/etc/kubernetes/pki/sa.pub
      - --allow-privileged=true
      - --requestheader-group-headers=X-Remote-Group
      - --advertise-address=192.168.2.10
      - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      - --insecure-port=0
      - --admission-control=Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota
      - --enable-bootstrap-token-auth=true
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --requestheader-username-headers=X-Remote-User
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      - --authorization-mode=Node,RBAC
      - --etcd-servers=http://127.0.0.1:2379
      env:
      - name: no_proxy
        value: k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
      image: gcr.io/google_containers/kube-apiserver-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 192.168.2.10
          path: /healthz
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      resources:
        requests:
          cpu: 250m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/pki
        name: ca-certs-etc-pki
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: ca-certs-etc-pki
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:37:22Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://cd38db17a5b2870dc43318f687d04a037c731188efee8818dde853cfc5c52535
      image: gcr.io/google_containers/kube-apiserver-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-apiserver-amd64@sha256:eec4329de0892f4a960b7f1202272f93880d3071a9b40d8407585125b37d527d
      lastState: {}
      name: kube-apiserver
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:37:21Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: Burstable
    startTime: 2018-02-03T22:31:55Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 3e62d6d6684d8169bc7a1ad3c99997bc
      kubernetes.io/config.mirror: 3e62d6d6684d8169bc7a1ad3c99997bc
      kubernetes.io/config.seen: 2018-02-03T22:31:50.423869393Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:38:15Z
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-k8master
    namespace: kube-system
    resourceVersion: "411"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-controller-manager-k8master
    uid: ec8a5065-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      - --address=127.0.0.1
      - --use-service-account-credentials=true
      - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      - --root-ca-file=/etc/kubernetes/pki/ca.crt
      - --leader-elect=true
      - --controllers=*,bootstrapsigner,tokencleaner
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      env:
      - name: no_proxy
        value: k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
      image: gcr.io/google_containers/kube-controller-manager-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10252
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /etc/pki
        name: ca-certs-etc-pki
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: ca-certs-etc-pki
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:33:18Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://409aa1bbfd5ace3dc4891da1aa7b841aa7b43a075c19dd1cc832ce67e8a31058
      image: gcr.io/google_containers/kube-controller-manager-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-controller-manager-amd64@sha256:10daf65c6e8d0ff032323931f3869cd30af23feab90345265ea405b6104a41c7
      lastState: {}
      name: kube-controller-manager
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:33:16Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: Burstable
    startTime: 2018-02-03T22:31:55Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2018-02-03T23:06:36Z
    generateName: kube-proxy-
    labels:
      controller-revision-hash: "588621068"
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-6j2b4
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: d61ef82d-0932-11e8-9940-0800277561f7
    resourceVersion: "2969"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-6j2b4
    uid: e279e689-0936-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-wmgjk
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8node-03
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: "true"
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-wmgjk
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-wmgjk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:06:39Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:10:54Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:08:03Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://6a1d4fb9c76c4750bbf134fd7baa1d5462cca42342e1d47cfc4c967048126c7a
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:10:53Z
    hostIP: 192.168.2.13
    phase: Running
    podIP: 192.168.2.13
    qosClass: BestEffort
    startTime: 2018-02-03T23:06:39Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2018-02-03T22:37:43Z
    generateName: kube-proxy-
    labels:
      controller-revision-hash: "588621068"
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-8wx7q
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: d61ef82d-0932-11e8-9940-0800277561f7
    resourceVersion: "477"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-8wx7q
    uid: d94add08-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-wmgjk
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: "true"
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-wmgjk
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-wmgjk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:37:43Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:39:39Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:39:39Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://b893576cd9a52e57bc66c2d9572c8d677f3c8a619702f911146d09d5ecd5204f
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:39:37Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: BestEffort
    startTime: 2018-02-03T22:37:43Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2018-02-03T22:55:35Z
    generateName: kube-proxy-
    labels:
      controller-revision-hash: "588621068"
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-l9msk
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: d61ef82d-0932-11e8-9940-0800277561f7
    resourceVersion: "2737"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-l9msk
    uid: 58793a23-0935-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-wmgjk
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8node-02
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: "true"
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-wmgjk
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-wmgjk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:55:38Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T23:08:21Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:57:00Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://cac2484e758141295b0cabaf20a15c6d9bac8b8b22a91d7f6362bc23985ff510
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T23:08:19Z
    hostIP: 192.168.2.12
    phase: Running
    podIP: 192.168.2.12
    qosClass: BestEffort
    startTime: 2018-02-03T22:55:38Z
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: 2018-02-03T22:47:42Z
    generateName: kube-proxy-
    labels:
      controller-revision-hash: "588621068"
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-zg92c
    namespace: kube-system
    ownerReferences:
    - apiVersion: extensions/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: d61ef82d-0932-11e8-9940-0800277561f7
    resourceVersion: "1222"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-zg92c
    uid: 3eb6b38a-0934-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-proxy-token-wmgjk
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8node-01
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: "true"
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-proxy-token-wmgjk
      secret:
        defaultMode: 420
        secretName: kube-proxy-token-wmgjk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:47:46Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:50:55Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:50:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c33c70f5a692eb4786b50bc8b136745b04d0ac94529a537bbd35bfdee88f2b5f
      image: gcr.io/google_containers/kube-proxy-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-proxy-amd64@sha256:fe00a6c576afba09255438f5ff01eff6d63ee302294c5450cb19b38404ef62ac
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:50:53Z
    hostIP: 192.168.2.11
    phase: Running
    podIP: 192.168.2.11
    qosClass: BestEffort
    startTime: 2018-02-03T22:47:46Z
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 419e9c2b7c2d4889af65758618bbed88
      kubernetes.io/config.mirror: 419e9c2b7c2d4889af65758618bbed88
      kubernetes.io/config.seen: 2018-02-03T22:31:50.423881438Z
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: 2018-02-03T22:37:37Z
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-k8master
    namespace: kube-system
    resourceVersion: "254"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-scheduler-k8master
    uid: d5d42c35-0932-11e8-9940-0800277561f7
  spec:
    containers:
    - command:
      - kube-scheduler
      - --address=127.0.0.1
      - --leader-elect=true
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      env:
      - name: no_proxy
        value: k8master,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.13,netmaster,localhost,127.0.0.1
      image: gcr.io/google_containers/kube-scheduler-amd64:v1.9.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10251
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    hostNetwork: true
    nodeName: k8master
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:33:47Z
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: 2018-02-03T22:31:55Z
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://75dfd82dae23666b4c39b3d32221913e7e4181323a13b711fdf6121d6d6c672e
      image: gcr.io/google_containers/kube-scheduler-amd64:v1.9.2
      imageID: docker-pullable://gcr.io/google_containers/kube-scheduler-amd64@sha256:082520e24e697f3228046ca13cddf46e4e01ae2982685b4ccc7df8f8e9145abc
      lastState: {}
      name: kube-scheduler
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: 2018-02-03T22:33:45Z
    hostIP: 192.168.2.10
    phase: Running
    podIP: 192.168.2.10
    qosClass: Burstable
    startTime: 2018-02-03T22:31:55Z
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get podsecuritypolicies --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get podtemplates --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get replicasets --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"ReplicaSet","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-netmaster"},"name":"contiv-netmaster","namespace":"kube-system"},"spec":{"replicas":1,"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"contiv-netmaster"},"name":"contiv-netmaster","namespace":"kube-system"},"spec":{"containers":[{"command":["tail","-f","/dev/null"],"env":[{"name":"CONTIV_ROLE","value":"netmaster"},{"name":"CONTIV_NETMASTER_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_NETMASTER_FORWARD_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_fwdmode","name":"contiv-config"}}},{"name":"CONTIV_NETMASTER_NET_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_netmode","name":"contiv-config"}}}],"image":"contiv/netplugin:latest","name":"contiv-netmaster","volumeMounts":[{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false},{"mountPath":"/contiv/bin","name":"contiv-bin-dir","readOnly":true},{"mountPath":"/contiv/scripts/","name":"contiv-scripts-dir","readOnly":true},{"mountPath":"/var/log/contiv","name":"contiv-log-dir","readOnly":false}]}],"hostNetwork":true,"initContainers":[{"env":[{"name":"CONTIV_ROLE","value":"netmaster"},{"name":"CONTIV_MODE","valueFrom":{"configMapKeyRef":{"key":"contiv_mode","name":"contiv-config"}}},{"name":"CONTIV_K8S_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_k8s_config","name":"contiv-config"}}},{"name":"CONTIV_CNI_CONFIG","valueFrom":{"configMapKeyRef":{"key":"contiv_cni_config","name":"contiv-config"}}}],"image":"contiv/netplugin-init:latest","name":"contiv-netplugin-init","volumeMounts":[{"mountPath":"/var/contiv","name":"var-contiv","readOnly":false}]},{"command":["cp","/contiv/bin/netctl","/usr/local/sbin/netctl"],"image":"contiv/netplugin:latest","name":"contiv-netctl","volumeMounts":[{"mountPath":"/usr/local/sbin/","name":"usr-local-sbin","readOnly":false}]}],"nodeSelector":{"node-role.kubernetes.io/master":""},"serviceAccountName":"contiv-netmaster","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"hostPath":{"path":"/var/contiv"},"name":"var-contiv"},{"hostPath":{"path":"/usr/local/sbin/"},"name":"usr-local-sbin"},{"hostPath":{"path":"/opt/gopath/bin"},"name":"contiv-bin-dir"},{"hostPath":{"path":"/opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/"},"name":"contiv-scripts-dir"},{"hostPath":{"path":"/var/log/contiv"},"name":"contiv-log-dir"}]}}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    generation: 1
    labels:
      k8s-app: contiv-netmaster
    name: contiv-netmaster
    namespace: kube-system
    resourceVersion: "777"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/contiv-netmaster
    uid: df1a16b8-0932-11e8-9940-0800277561f7
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: contiv-netmaster
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: contiv-netmaster
        name: contiv-netmaster
        namespace: kube-system
      spec:
        containers:
        - command:
          - tail
          - -f
          - /dev/null
          env:
          - name: CONTIV_ROLE
            value: netmaster
          - name: CONTIV_NETMASTER_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_NETMASTER_FORWARD_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_fwdmode
                name: contiv-config
          - name: CONTIV_NETMASTER_NET_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_netmode
                name: contiv-config
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-netmaster
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/contiv
            name: var-contiv
          - mountPath: /contiv/bin
            name: contiv-bin-dir
            readOnly: true
          - mountPath: /contiv/scripts/
            name: contiv-scripts-dir
            readOnly: true
          - mountPath: /var/log/contiv
            name: contiv-log-dir
        dnsPolicy: ClusterFirst
        hostNetwork: true
        initContainers:
        - env:
          - name: CONTIV_ROLE
            value: netmaster
          - name: CONTIV_MODE
            valueFrom:
              configMapKeyRef:
                key: contiv_mode
                name: contiv-config
          - name: CONTIV_K8S_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_k8s_config
                name: contiv-config
          - name: CONTIV_CNI_CONFIG
            valueFrom:
              configMapKeyRef:
                key: contiv_cni_config
                name: contiv-config
          image: contiv/netplugin-init:latest
          imagePullPolicy: Always
          name: contiv-netplugin-init
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/contiv
            name: var-contiv
        - command:
          - cp
          - /contiv/bin/netctl
          - /usr/local/sbin/netctl
          image: contiv/netplugin:latest
          imagePullPolicy: Always
          name: contiv-netctl
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/sbin/
            name: usr-local-sbin
        nodeSelector:
          node-role.kubernetes.io/master: ""
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: contiv-netmaster
        serviceAccountName: contiv-netmaster
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - hostPath:
            path: /var/contiv
            type: ""
          name: var-contiv
        - hostPath:
            path: /usr/local/sbin/
            type: ""
          name: usr-local-sbin
        - hostPath:
            path: /opt/gopath/bin
            type: ""
          name: contiv-bin-dir
        - hostPath:
            path: /opt/gopath/src/github.com/contiv/netplugin/scripts/netContain/scripts/
            type: ""
          name: contiv-scripts-dir
        - hostPath:
            path: /var/log/contiv
            type: ""
          name: contiv-log-dir
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get replicationcontrollers --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get resourcequotas --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get rolebindings --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: kubeadm:bootstrap-signer-clusterinfo
    namespace: kube-public
    resourceVersion: "189"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-public/rolebindings/kubeadm%3Abootstrap-signer-clusterinfo
    uid: d5ece8e7-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: kubeadm:bootstrap-signer-clusterinfo
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:anonymous
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:36Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:bootstrap-signer
    namespace: kube-public
    resourceVersion: "148"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-public/rolebindings/system%3Acontroller%3Abootstrap-signer
    uid: d5142f75-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system:controller:bootstrap-signer
  subjects:
  - kind: ServiceAccount
    name: bootstrap-signer
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system::leader-locking-kube-controller-manager
    namespace: kube-system
    resourceVersion: "141"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3A%3Aleader-locking-kube-controller-manager
    uid: d4ea4371-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system::leader-locking-kube-controller-manager
  subjects:
  - kind: ServiceAccount
    name: kube-controller-manager
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:36Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system::leader-locking-kube-scheduler
    namespace: kube-system
    resourceVersion: "143"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3A%3Aleader-locking-kube-scheduler
    uid: d4f4771a-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system::leader-locking-kube-scheduler
  subjects:
  - kind: ServiceAccount
    name: kube-scheduler
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:36Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:bootstrap-signer
    namespace: kube-system
    resourceVersion: "144"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3Acontroller%3Abootstrap-signer
    uid: d4fc09f2-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system:controller:bootstrap-signer
  subjects:
  - kind: ServiceAccount
    name: bootstrap-signer
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:36Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:cloud-provider
    namespace: kube-system
    resourceVersion: "145"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3Acontroller%3Acloud-provider
    uid: d50124af-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system:controller:cloud-provider
  subjects:
  - kind: ServiceAccount
    name: cloud-provider
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:36Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:token-cleaner
    namespace: kube-system
    resourceVersion: "147"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3Acontroller%3Atoken-cleaner
    uid: d50cd4b3-0932-11e8-9940-0800277561f7
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system:controller:token-cleaner
  subjects:
  - kind: ServiceAccount
    name: token-cleaner
    namespace: kube-system
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get roles --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: kubeadm:bootstrap-signer-clusterinfo
    namespace: kube-public
    resourceVersion: "186"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-public/roles/kubeadm%3Abootstrap-signer-clusterinfo
    uid: d5d99765-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resourceNames:
    - cluster-info
    resources:
    - configmaps
    verbs:
    - get
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:bootstrap-signer
    namespace: kube-public
    resourceVersion: "140"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-public/roles/system%3Acontroller%3Abootstrap-signer
    uid: d4e3ed42-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resourceNames:
    - cluster-info
    resources:
    - configmaps
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: extension-apiserver-authentication-reader
    namespace: kube-system
    resourceVersion: "124"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/extension-apiserver-authentication-reader
    uid: d498e717-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resourceNames:
    - extension-apiserver-authentication
    resources:
    - configmaps
    verbs:
    - get
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system::leader-locking-kube-controller-manager
    namespace: kube-system
    resourceVersion: "137"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3A%3Aleader-locking-kube-controller-manager
    uid: d4cbcf2c-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - watch
  - apiGroups:
    - ""
    resourceNames:
    - kube-controller-manager
    resources:
    - configmaps
    verbs:
    - get
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system::leader-locking-kube-scheduler
    namespace: kube-system
    resourceVersion: "139"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3A%3Aleader-locking-kube-scheduler
    uid: d4ded106-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - watch
  - apiGroups:
    - ""
    resourceNames:
    - kube-scheduler
    resources:
    - configmaps
    verbs:
    - get
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:bootstrap-signer
    namespace: kube-system
    resourceVersion: "125"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3Acontroller%3Abootstrap-signer
    uid: d4a080d2-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - secrets
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:cloud-provider
    namespace: kube-system
    resourceVersion: "127"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3Acontroller%3Acloud-provider
    uid: d4ae73c8-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - create
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:token-cleaner
    namespace: kube-system
    resourceVersion: "135"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3Acontroller%3Atoken-cleaner
    uid: d4b89d4f-0932-11e8-9940-0800277561f7
  rules:
  - apiGroups:
    - ""
    resources:
    - secrets
    verbs:
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get secrets --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: ZGVmYXVsdA==
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUprWldaaGRXeDBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpXTnlaWFF1Ym1GdFpTSTZJbVJsWm1GMWJIUXRkRzlyWlc0dFpEVnJjR0lpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pWkdWbVlYVnNkQ0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG5WcFpDSTZJbVE1TW1NMU16RTJMVEE1TXpJdE1URmxPQzA1T1RRd0xUQTRNREF5TnpjMU5qRm1OeUlzSW5OMVlpSTZJbk41YzNSbGJUcHpaWEoyYVdObFlXTmpiM1Z1ZERwa1pXWmhkV3gwT21SbFptRjFiSFFpZlEub0lnY0x3THlzN2VuUUxaYkhWNUZ2VTlvNno1QWgxZFhwdk1xZmNDVUlEQXl2RUcySC1VQU5DeWQ3Ymp0TlNsSUVKdDVEXzFwRU5mRDdnLVhYc1JIQ3pyeHFLVkF5MnNJaS1hb0Z4UkxPVDgyVnBoWEFhZmN5YVVWbF80ZERwVXItRzYxZGpvclktQUR3ay1SVmJlSVhsQk9XNXhwMllCUkhMYWpUbWlmSWVlYkpYTXpJNzhDNjdoWFJaWnQzWmY0SnUzVUoyVlhyQ1J4TVgwdng5ckd1UXRWRFlJMzFQbG9iaHU4WWpReGhFUGFSQTk0a2xzUE1zTzFSWW5UUmhPRWlJcGsxdFBsV2t3VjdKTXlXbWg0ZDhkNVF0TU94R0tYakRPTUthZ1ltTGp6MVZPZkJDYWJ0M1pUTVF2Ym13TkxLMDMwa2FMY01zNnFFMWN4Tk9INk1R
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: default
      kubernetes.io/service-account.uid: d92c5316-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:43Z
    name: default-token-d5kpb
    namespace: default
    resourceVersion: "298"
    selfLink: /api/v1/namespaces/default/secrets/default-token-d5kpb
    uid: d9349d2a-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1wdWJsaWM=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYQjFZbXhwWXlJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKa1pXWmhkV3gwTFhSdmEyVnVMWEZvWm01dElpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltUmxabUYxYkhRaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lKa09USTVZVFkxTlMwd09UTXlMVEV4WlRndE9UazBNQzB3T0RBd01qYzNOVFl4WmpjaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxd2RXSnNhV002WkdWbVlYVnNkQ0o5LmRTbmJBcDh5WUtYNHJnV0RlUlhGdHVtRURiQllhamRkN19lRXRlbkdqc2RTX0ZoMGpfVl91Mm0zeTFwTzhsUU56ajBCUUR1WEw2S2cycGExb3dQRnFhTlhyRmRxLU9Za0NBdkhodE03dlR3NUxMdXhfYmJzbFJnbUxFaEZwODlWMEYxWl9IOGxmYi04RnRtelp0eHFTWVBtZGpLenpMRS1rY2hldjV6RjhvQktTT3o3ZnZiYkwyNDk3MUV1V055eDN5TEwyZ1B1d1RYME5kVlYwY0dWMjBWQmxvNHZjVnFiUFllV0EtTjk2elR3U2ZFbHY1a1ZJbGNSYUM2TXBDN2F2aXlUNTRuaFJiLV84a090dnZleVZFeTlnQ0JNRmI3M3NwTjhPWkVWWWs5alRKa2R1T2ZPN2QzNkQ5NjVhSFdyNWNqUFBQbTh4V1M3U3JxcVRKODJFZw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: default
      kubernetes.io/service-account.uid: d929a655-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:43Z
    name: default-token-qhfnm
    namespace: kube-public
    resourceVersion: "295"
    selfLink: /api/v1/namespaces/kube-public/secrets/default-token-qhfnm
    uid: d9311f63-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKaGRIUmhZMmhrWlhSaFkyZ3RZMjl1ZEhKdmJHeGxjaTEwYjJ0bGJpMDNObnByZENJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExtNWhiV1VpT2lKaGRIUmhZMmhrWlhSaFkyZ3RZMjl1ZEhKdmJHeGxjaUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG5WcFpDSTZJbVEyTXprNVpqRTFMVEE1TXpJdE1URmxPQzA1T1RRd0xUQTRNREF5TnpjMU5qRm1OeUlzSW5OMVlpSTZJbk41YzNSbGJUcHpaWEoyYVdObFlXTmpiM1Z1ZERwcmRXSmxMWE41YzNSbGJUcGhkSFJoWTJoa1pYUmhZMmd0WTI5dWRISnZiR3hsY2lKOS5NcmtXbVpjTzMxQVhteWNXZk8yZmRaU3k2RW1QSEZrZEZMelJWYTg1V0N3Y0dlNzFCSi1tazdVZ2diWWlpMWRNcnF5NWxtYnJsNEowMnNLZWZsWHY4NFRsU0E2Q0g4bk1KMzI2elNxYnh4WFVFOUJqelFzbHF4Xzc2M1F5UmwzOHcxdVl0SF9vMnZtYUN2MEdycG5sXzA1RU8tM0lhSWpJTTlvRmxkMVg0MDRWX2g3eHY1MDl4akJqbzNOSmNZQ2pNQWdwcWtFSno2UWVtWkVsSUhQbUpUZzBoeWxsRHN2UjZKdkdZdlozM2J1TUVIOWd2eXY5d1pXS2h6NGxnYXVkUUN6RDRfS3l5bzJwRy1RMVhLclpWOFBlZjVVRFBzbS1HMG5CX055TVV6Vm5UNlpxd3FOMXVDN0J5aFI1S1BWaW9QQ2JnX00wYmdRUTQ4UW0yVjJkbnc=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: attachdetach-controller
      kubernetes.io/service-account.uid: d6399f15-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:38Z
    name: attachdetach-controller-token-76zkt
    namespace: kube-system
    resourceVersion: "218"
    selfLink: /api/v1/namespaces/kube-system/secrets/attachdetach-controller-token-76zkt
    uid: d655d3b4-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKaWIyOTBjM1J5WVhBdGMybG5ibVZ5TFhSdmEyVnVMVEp3YTJobUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltSnZiM1J6ZEhKaGNDMXphV2R1WlhJaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lKa05qSTJZMlpsT1Mwd09UTXlMVEV4WlRndE9UazBNQzB3T0RBd01qYzNOVFl4WmpjaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxemVYTjBaVzA2WW05dmRITjBjbUZ3TFhOcFoyNWxjaUo5LjBtTWEzLUtZUC1lak5adGx5X1piSUhqelZwbVo1U1F6ekJxOWV6NExtenFSUjdJdkZUVkk2eVNrRWpOYUxLTzczbHdVajE3REo1VDJCWTY5czl5S3otZ3JCVWNKRWhHd2xwaC1ER1ZzYUlBdlJJbXBsVklrdW9STWhDWVh0dnAxZ3VoR3FjbWl0dllMbF82LUhLYW5qLTNHWGtEd3l2VmxmX2ZNOUdWNGJhV05MTVRVNE9leDhFVmpkQVg1bHctanAxMGxtLUdvc3FCSWt2Nlg0bW1hT2dCQVJJcjdwYWE3Z2o0RGVsejZHTkg4V1FpdzRuWEN1RXcwQnFSRkRvVnRkUXZKaE1jejFRd2g1OG5VZ294OVgtb2V3MmVaSkNodTRpV1R1TlNSa2M1V1NVU05mMXVPMTlMWnkxR1BtTlNOTi11UGZWOXdubDI2ZVMyQ3JPempjQQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: bootstrap-signer
      kubernetes.io/service-account.uid: d626cfe9-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:38Z
    name: bootstrap-signer-token-2pkhf
    namespace: kube-system
    resourceVersion: "213"
    selfLink: /api/v1/namespaces/kube-system/secrets/bootstrap-signer-token-2pkhf
    uid: d62a2fe2-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKalpYSjBhV1pwWTJGMFpTMWpiMjUwY205c2JHVnlMWFJ2YTJWdUxXSjNhRFJrSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW1ObGNuUnBabWxqWVhSbExXTnZiblJ5YjJ4c1pYSWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzUxYVdRaU9pSmtOVE00WWpJeU9TMHdPVE15TFRFeFpUZ3RPVGswTUMwd09EQXdNamMzTlRZeFpqY2lMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2YTNWaVpTMXplWE4wWlcwNlkyVnlkR2xtYVdOaGRHVXRZMjl1ZEhKdmJHeGxjaUo5LmV0Y0MtejE4ZkQwcUUzZDFYajFHNXFVOGVKemhNR3BNbi03bEhoNjZZNkxpdUdmcWE4SEh2Y2NaRE1obzZEVUJtRUZHMmZMTTVKRFdnazdPbUxIOTZVQS1NdmJKMUhIM2JoUWlyd1dpNTJVNjhEU18tbk9QMzhTNm5iT2VTcXlwSUJFX1ExeUJLVWwxUThNdVI3dHVqYllDSVhRaVRZZzNyMFhwZGM1T1d0bmZ6NkNMcHdfbmJEbkNnT09zUXItcUlTc0JIR0RZNUpnS3NXa0ZETUJtSGdFa1pjTmdLWTlQQXpEQ0JzaENvZXF2bjllVzNoNEF1bkozOU5EblFVd1R1MWFJN0NqeDROU29iOXJ1dDNOVlUxSU53SmlFa2hrUkx5Zmc1QlRHY2VTRVQ4bzVtUDVDeUVESWh6dTZwR0E2eGhyMkxVbmowdHlpaWhkcU9QbmFQQQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: certificate-controller
      kubernetes.io/service-account.uid: d538b229-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:36Z
    name: certificate-controller-token-bwh4d
    namespace: kube-system
    resourceVersion: "152"
    selfLink: /api/v1/namespaces/kube-system/secrets/certificate-controller-token-bwh4d
    uid: d54548c9-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKamJIVnpkR1Z5Y205c1pTMWhaMmR5WldkaGRHbHZiaTFqYjI1MGNtOXNiR1Z5TFhSdmEyVnVMWFJpYXpsb0lpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltTnNkWE4wWlhKeWIyeGxMV0ZuWjNKbFoyRjBhVzl1TFdOdmJuUnliMnhzWlhJaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lKa05tVmhNR05pWVMwd09UTXlMVEV4WlRndE9UazBNQzB3T0RBd01qYzNOVFl4WmpjaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxemVYTjBaVzA2WTJ4MWMzUmxjbkp2YkdVdFlXZG5jbVZuWVhScGIyNHRZMjl1ZEhKdmJHeGxjaUo5LkZTeWVVV2JUNng0LWl3d1pIMW1EYzFNd1NLdzRNUkNrcUFiMGlMNmxfdjhjNlBENE5XcmJCSXRqbkxDQ3hUZFl2eHZLQUFaTm81ZE0xZ3p4ckwzU3c0LUlRMDV2bW1hQzBqYUtQaFE4bFBjUTRLbEdXMW11cmhtUGtwZUxHQUdISTZSVHdLa1hHMk9vV2tFYWtpdkprZ3o1bjh1WHNiNTRKeERkUmpXRWFfa2JsTmpXeEFIbVJlRTEwN3RibWtNZ3lVNmkzSlhWS2xDeHRuMUJycXBOVGRNNDZRSk5QVmwxcTFmcVF4OVIyRjl2S2lMZUh2S0FiYkdkZFVyZFhRRkt1d1hQMGtIWXNHSXdid2dzSXFtUTNGVzhZdEtRWXUzZ21hNHNGZzcxNUY3NG9UWndzX1pYNkdJVl91VWkya1I2d2JwTkNhQzlLU3NWdW5Bckx2OHpvdw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: clusterrole-aggregation-controller
      kubernetes.io/service-account.uid: d6ea0cba-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:39Z
    name: clusterrole-aggregation-controller-token-tbk9h
    namespace: kube-system
    resourceVersion: "236"
    selfLink: /api/v1/namespaces/kube-system/secrets/clusterrole-aggregation-controller-token-tbk9h
    uid: d6eeac26-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKamIyNTBhWFl0Ym1WMGJXRnpkR1Z5TFhSdmEyVnVMVFEzWW5oa0lpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltTnZiblJwZGkxdVpYUnRZWE4wWlhJaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lKa1pXUmtaR1EzWVMwd09UTXlMVEV4WlRndE9UazBNQzB3T0RBd01qYzNOVFl4WmpjaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxemVYTjBaVzA2WTI5dWRHbDJMVzVsZEcxaGMzUmxjaUo5LjB4Qm9MUWtXSF9LR2lSODRIWk9IdlYyaURXTko5c0hrRTBOVW9pd1hqbmRhazdpaDhtLTJvNmIzQVdiaVg0d2tENzMwLWZKZU1ySXEtU1hqVWx3MGpKa2pfRHVHYVprR1U3cnN4cnFzVGN1ZUJnOGJhM3dnZVM5UkY4STVwdFhQN09Eb2Q3eTZuZ1FSVXNDNVFqS21RX19KMEFVQ3BtREg2dkVRc016eWZFNk9ZNWZfdGdUcVRtU2hiSXNSbV9SUklxZGhtXzJ3UUhFVmNGQlpjZ01QbXdnMlpNVFlJQWJ0SlB2anVQd0duWFRKa1ZQZnF5SFZ5dENpSWQxVDNZU3g4eTZnSGFxd2R0aE5MaV80cTlkbFl4aXhEc3RhTUpXT1B2bE9wamNUQ2xfT3RXamEySHBuU3VJRWlrenVTS3ZJZ1JvRHFDa2pTUWFxM3ZaMkw2cTVYZw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: contiv-netmaster
      kubernetes.io/service-account.uid: dedddd7a-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:52Z
    name: contiv-netmaster-token-47bxd
    namespace: kube-system
    resourceVersion: "348"
    selfLink: /api/v1/namespaces/kube-system/secrets/contiv-netmaster-token-47bxd
    uid: def1d1b0-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKamIyNTBhWFl0Ym1WMGNHeDFaMmx1TFhSdmEyVnVMWGh4YzJJMUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltTnZiblJwZGkxdVpYUndiSFZuYVc0aUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lKa1pXUXhOVEprWVMwd09UTXlMVEV4WlRndE9UazBNQzB3T0RBd01qYzNOVFl4WmpjaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxemVYTjBaVzA2WTI5dWRHbDJMVzVsZEhCc2RXZHBiaUo5LmRwc0xTck1vVU9ialI4R2NlNHl1b2E2WVhxQ2psWUNQOUZLa21CZ2tNRFZuN0hIelZuTEZaZmM0YTlsTmdYRlBSRWJUUFVaTmVSQXhIU2JTakROUVZBdVpKWEd4N3U3THVIUTBLZEJZODNMRWNMNGxiNjFpbWNWa1Y3dGg1bk9McFlOaE4xRW91Z05aeG1PV1U1X1FnRFA0dDdjbWJDSkdpSWRoRGMwbUdEN080MkJINEltV282UFFkajB6eFVUV3Y3OUVOVUhGb09Ib1Z5T2NFTGhGV3FzNDFBdUU1eVRPajk3OTlVUmJxUzVBcEM1dDJxVjQ5TTEtOUFSNmRXMEQzamRkdHFnZzhSNjhvZ3VqZWs4dmYySGJMa0lobFp6RHF5NkFWd3lRNjNLLXZpUXhUX0xLVVYtWko4SFdfMWVDWEJ2dEpObkNqcGdZOUJ3MzJQd3JtUQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: contiv-netplugin
      kubernetes.io/service-account.uid: ded152da-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:52Z
    name: contiv-netplugin-token-xqsb5
    namespace: kube-system
    resourceVersion: "343"
    selfLink: /api/v1/namespaces/kube-system/secrets/contiv-netplugin-token-xqsb5
    uid: ded5f856-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKamNtOXVhbTlpTFdOdmJuUnliMnhzWlhJdGRHOXJaVzR0WW5Kc1kzWWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzV1WVcxbElqb2lZM0p2Ym1wdllpMWpiMjUwY205c2JHVnlJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1ZFdsa0lqb2laRGhsT0dGbU56a3RNRGt6TWkweE1XVTRMVGs1TkRBdE1EZ3dNREkzTnpVMk1XWTNJaXdpYzNWaUlqb2ljM2x6ZEdWdE9uTmxjblpwWTJWaFkyTnZkVzUwT210MVltVXRjM2x6ZEdWdE9tTnliMjVxYjJJdFkyOXVkSEp2Ykd4bGNpSjkuMU02MjFkUDFUMnlKbi1DMVVIcW94V3RkSnNrWkdzV3o3MG1GVkxWRTc2QW5CNnBUMWw2X1BCZ09VUGFSVkU5MzFnNXpIdDhRMG5VTkpISnRTekRvWUtqTFdOYnpEakUybmhsNUdVcXBBeURjbFJhcWFQOHowTlA1b0ZjOVNVODBJZUpzbV9sNWU5QkNQV2oxQUtJc29LRDJrOUI1d29ma0I3T2NFbjNLSFpnNVNOSmdNRUdnZXR0QjdYQzVMR1VpdnpqVTZfN25CTkVfbTg4UnN6NmRTWFRJWkRnZGFMOXBYa3ZHOVp4YXNtQlNYdGRNZ05ZRkV2eEFxQ0M5Ym4zblRiRmx3QzR1c2hhSDNtY2hNYlI3MEZyZERuVXluOUxiU2ZjQXpNelZvUWVUSVF5cTl0V2ZobE5vU0VIZUlueVAyaXRncXREUnB2SmFEY21ZbW50VG13
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: cronjob-controller
      kubernetes.io/service-account.uid: d8e8af79-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:42Z
    name: cronjob-controller-token-brlcv
    namespace: kube-system
    resourceVersion: "280"
    selfLink: /api/v1/namespaces/kube-system/secrets/cronjob-controller-token-brlcv
    uid: d8f47d8d-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKa1lXVnRiMjR0YzJWMExXTnZiblJ5YjJ4c1pYSXRkRzlyWlc0dGFIcG1ZalVpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pWkdGbGJXOXVMWE5sZEMxamIyNTBjbTlzYkdWeUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVkV2xrSWpvaVpEVTRaV05tTkdZdE1Ea3pNaTB4TVdVNExUazVOREF0TURnd01ESTNOelUyTVdZM0lpd2ljM1ZpSWpvaWMzbHpkR1Z0T25ObGNuWnBZMlZoWTJOdmRXNTBPbXQxWW1VdGMzbHpkR1Z0T21SaFpXMXZiaTF6WlhRdFkyOXVkSEp2Ykd4bGNpSjkuR3hIUjFXMXBTNGdCc2d3TGxBcURCU0hDQk1ILXFhUHFnWjFoQVROQ1lrUmYyOFJUZ0E1eWQ0OUJWYmcwZnRxSFZXSDlrWEFndmwwTUtZZTAzUDdRaFBFSFBoT2dxaUpFbVhrbEJ4VU96QV9OWXZlUUZEd0F0QXV4TUN6OGExNmZLZkcxNlRkMDRrRnI1eUpvQ3lmUDBFaTBVMmhCdmJCY3JDSXFrcFZ5LThhbFNhNTkyd0N2QXJXZW5CWlBvVUdYT1BBRng1YkJvS1d3RnRzdXJSbWZpQ2JkTUxub3J4VzRyaDh6ZHhLcFZid01INFlWbzFQWUUwa2Y3V0R6QjI4WWhxUXp2Vzc5MXZFd2FaWkJYLW9TTXQ0OVRSOVlIdXNsanhKa2I4Tk82MlF4bGJvUERqWmMzTnpXRTFFVlpKbmtENVJZNjlEUWNIdFRMRzVrUkROU3R3
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: daemon-set-controller
      kubernetes.io/service-account.uid: d58ecf4f-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:37Z
    name: daemon-set-controller-token-hzfb5
    namespace: kube-system
    resourceVersion: "165"
    selfLink: /api/v1/namespaces/kube-system/secrets/daemon-set-controller-token-hzfb5
    uid: d59203c2-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKa1pXWmhkV3gwTFhSdmEyVnVMVGxyZEdabUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltUmxabUYxYkhRaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lKa09USTNOV00wWVMwd09UTXlMVEV4WlRndE9UazBNQzB3T0RBd01qYzNOVFl4WmpjaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxemVYTjBaVzA2WkdWbVlYVnNkQ0o5LlJNREp4TGJ5akxTRXV0VmtJMWc4cWlGOGttd0MzeDFOcVo3a1o2aEhmRDU4MzlyY0lFUVFNMk9ZVUk3RTBmVkFUeFlBTmZHRlU2T24wTzIweURIOEUtVGQtNXVVQ0x2V1U3ZG93NjlqSHBmaEhtSlFGQ1lRUW5YZmVhbi1JM1NGeXBqZnhhSFZnZ01UdV9ael9NbmhaNWR6YW9kTkFtRFdpOWtGX2lnZldKek5uTHdHM3ZycnlNR0Z3OHFwUmpLTFdLT19yZ0x0dmFoTmpFUzZOQlBuLTlwZFFRazB2RmplNS15WldjRi1pRGZ0WDJBMnFzME5zY2RJWlJoamtZZV9OaXFJcUUwc1RuVXRQNEhjRE5DZGFmMmstN0dGZVJ1VFpkOTk5dDJtbFZKc0lTanR4WE9MM01iaGxUb1RmZXZMOFVpdGJxdGVOU2RZNFVWZ25JVHFJQQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: default
      kubernetes.io/service-account.uid: d9275c4a-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:43Z
    name: default-token-9ktff
    namespace: kube-system
    resourceVersion: "293"
    selfLink: /api/v1/namespaces/kube-system/secrets/default-token-9ktff
    uid: d92d7d91-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKa1pYQnNiM2x0Wlc1MExXTnZiblJ5YjJ4c1pYSXRkRzlyWlc0dFpuWmtOR3NpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pWkdWd2JHOTViV1Z1ZEMxamIyNTBjbTlzYkdWeUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVkV2xrSWpvaVpEVTVaVEZrWlRZdE1Ea3pNaTB4TVdVNExUazVOREF0TURnd01ESTNOelUyTVdZM0lpd2ljM1ZpSWpvaWMzbHpkR1Z0T25ObGNuWnBZMlZoWTJOdmRXNTBPbXQxWW1VdGMzbHpkR1Z0T21SbGNHeHZlVzFsYm5RdFkyOXVkSEp2Ykd4bGNpSjkuS09UaXlWNUxaSkMyTXFTSkJqWkxDd2hGZENfS3RzNENremNJd1k0eExQTXZ4cEM1aGNxWVV4RTJPNUVrZVF5QU1FTHo2c2xfeWgxMDBmN2dCUjlTMHpHeER5VEgxQjY4alVSZFVSZ21za0JZTTlodXhwMkFDNkk1a2w4bkhrcGRQazVyZnJNczJJdm1uYU5wanJVbnZKbnBhZVVhRjRqdFpJS2dMdmlLOG9mVG53U0ZlaEhaUGtUbW9lSHBuUnQ5OV84aGpka3d0VlpiaU12NVRURkZaY3hFc0ZvclR2cHcyTkZrSEFMdFhWSjFoa3loR1Q2cWFuaGdaWTl3eXV0ODJmR1lQWEhST2NNRzFyQzFpc1JFdkVqazNnLTlNWE9nMG5adERLS1NNdmdmeEdpaFRTOHBaMmpsV2lWS0Q1OUM0TkRHaFpMMjF4WUoyN3UzQlhnN25R
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: deployment-controller
      kubernetes.io/service-account.uid: d59e1de6-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:37Z
    name: deployment-controller-token-fvd4k
    namespace: kube-system
    resourceVersion: "168"
    selfLink: /api/v1/namespaces/kube-system/secrets/deployment-controller-token-fvd4k
    uid: d5a15c8e-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKa2FYTnlkWEIwYVc5dUxXTnZiblJ5YjJ4c1pYSXRkRzlyWlc0dGJHdHlkRzRpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pWkdsemNuVndkR2x2YmkxamIyNTBjbTlzYkdWeUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVkV2xrSWpvaVpEaGtNbUV3TXpJdE1Ea3pNaTB4TVdVNExUazVOREF0TURnd01ESTNOelUyTVdZM0lpd2ljM1ZpSWpvaWMzbHpkR1Z0T25ObGNuWnBZMlZoWTJOdmRXNTBPbXQxWW1VdGMzbHpkR1Z0T21ScGMzSjFjSFJwYjI0dFkyOXVkSEp2Ykd4bGNpSjkuQkVNcDgweFk1aUNMd0RTTW4yVm1fUTdKblE1S2M0aDE1czlSTTNCRVUxVlBNRWhFMnNQQlYxU1hhajNPOExtbV9mYlBhd0VOd2hXaUVVU3Y1SHNYWlc5REI0OHdVdmhFaGFseV83cVd3bzRUMW9aMVJIdWVFU0tFcU9IRlhOaDVadktqM1FLRXRIb2VWZDc4N2UxV1BoOE9ZMm5XS3FTVU9tcW5GNkRoUklXaWxUaVd3MXl6VGVacG1NbDhhV08wVkVHbFNRNHNlOXUtaG9mUF9YeDdrd0FXQkEyLUdkMHBJS19PbW9VNEJMVXNyS2xXN0ZhYUllY3F6TFBBLWFCWm1tOVhVNUlVdXVIMjd3OFZCelpPTDB0VmpVZVAyWm1sajZCSk5GaWJIUnJGMkRmZFlBNjlCeG5nUHVZc0hhVGJEV3puOF9FN2wxS0FJWkFGVm5HNkFB
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: disruption-controller
      kubernetes.io/service-account.uid: d8d2a032-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:42Z
    name: disruption-controller-token-lkrtn
    namespace: kube-system
    resourceVersion: "277"
    selfLink: /api/v1/namespaces/kube-system/secrets/disruption-controller-token-lkrtn
    uid: d8dac21c-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKbGJtUndiMmx1ZEMxamIyNTBjbTlzYkdWeUxYUnZhMlZ1TFdkelpIcHhJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1Ym1GdFpTSTZJbVZ1WkhCdmFXNTBMV052Ym5SeWIyeHNaWElpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1MWFXUWlPaUprTmpjek9UTmhaQzB3T1RNeUxURXhaVGd0T1RrME1DMHdPREF3TWpjM05UWXhaamNpTENKemRXSWlPaUp6ZVhOMFpXMDZjMlZ5ZG1salpXRmpZMjkxYm5RNmEzVmlaUzF6ZVhOMFpXMDZaVzVrY0c5cGJuUXRZMjl1ZEhKdmJHeGxjaUo5LmY3Wl9mZHZYUndLNzJ0MG8xT0NCaGVZQmdJOTB1OUhUUl9GcXNGcmNOOFJaQXY5ZXFkQ2NuQ3NHamlRM1Vja3RESkJZY1lENEI0elhEbl93cjlwOEpwTzNHckw2MUlSWUdWcXktaGtCdGd3SldGQmNwSVl2UnRTVkR1UTJVRmt4N2hsM0laWGViRDBCVFoyMDRXUXREQll0ZDRQTnpqcC15M09hYmd2Tk05dll0cFY1RXZmclFxdnFBYUVVV2pWTUtvOERNbm1SM2ptNHh2UlpQaER0SzAxc29oNWtOaWVOTUhNTENtS29YeTBOV0RLeUI5XzJaVlh5bmlmTnN1NjJDMEh6RmJ1Rm9mYm84RUJjZnVyMktzSkZtMm8yV3FLcmRJTDF0OVBmbUpHUVFiNGhveENYZkpEUExqUjZVeFBzYWZ2UTlRYUJvR0JBS3FrMGRuZFdPQQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: endpoint-controller
      kubernetes.io/service-account.uid: d67393ad-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:38Z
    name: endpoint-controller-token-gsdzq
    namespace: kube-system
    resourceVersion: "224"
    selfLink: /api/v1/namespaces/kube-system/secrets/endpoint-controller-token-gsdzq
    uid: d6783b5c-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKblpXNWxjbWxqTFdkaGNtSmhaMlV0WTI5c2JHVmpkRzl5TFhSdmEyVnVMVGwwWm1wMElpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltZGxibVZ5YVdNdFoyRnlZbUZuWlMxamIyeHNaV04wYjNJaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lKa09EQmhORFkyTUMwd09UTXlMVEV4WlRndE9UazBNQzB3T0RBd01qYzNOVFl4WmpjaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxemVYTjBaVzA2WjJWdVpYSnBZeTFuWVhKaVlXZGxMV052Ykd4bFkzUnZjaUo5LkJDbHFvWFNBTGw1UHJKWVh3QnZBZkVsUVJKWmd1aGxYX25HSmVTa3Z5Y0t0dXBVUFMzMlRlMnRQcWh3ZFRIaG9GQV8wUHlhaUZVZ2tucU5DbE1BaGhXbDc4TW9OU2trcXdTQkd3SzZTSlViR0hoMjRqTGhCbVJ1c09fazJGbzdvdDR1VmxlMnN3VzBDZ3RMZDNxaHladld3WjhlN00tdWVRX1VLSDUzazI2eDZNMXdsUU1RUVlqMFRsd1g1SjBOV096LU5sT1BtdUQ5ODRKTkRvdmNOSkZ3NXY3MWpSLWpMQmRNRzJhT19NQ3l0SGV4YlZwdUpCTTM0SGZkbTZSVUhJWXg1T3RCS1N4SXZ0eWpWcFh2Y3lsZExRdlhHeEhydGdKbnE3cXVlSmYxMEF4MkJaVVhQS1lzM1Z3WnpUd0tuVG8yWldhNjZrVDA2MlNscExVSW5aUQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: generic-garbage-collector
      kubernetes.io/service-account.uid: d80a4660-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:41Z
    name: generic-garbage-collector-token-9tfjt
    namespace: kube-system
    resourceVersion: "264"
    selfLink: /api/v1/namespaces/kube-system/secrets/generic-garbage-collector-token-9tfjt
    uid: d8146458-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKb2IzSnBlbTl1ZEdGc0xYQnZaQzFoZFhSdmMyTmhiR1Z5TFhSdmEyVnVMWEpuY3pWMElpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltaHZjbWw2YjI1MFlXd3RjRzlrTFdGMWRHOXpZMkZzWlhJaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lKa05qaG1Namd4TWkwd09UTXlMVEV4WlRndE9UazBNQzB3T0RBd01qYzNOVFl4WmpjaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxemVYTjBaVzA2YUc5eWFYcHZiblJoYkMxd2IyUXRZWFYwYjNOallXeGxjaUo5LlRReTZGa2d0OFBGejZybVJGWXdyZklQQXJiMjZySV9IU1BaZ0Y3MkFwTThCdmhkSEdUdHY0emd0WTdDSUlfUGVrcEJ6dG9Sa21LNWZ6VWdhSklVUEZIdEJsVFdFTHRRUVBUSFlsRGt4UkJLbG1BUDlQaG5uZlhsOHo0VURvRjZKVzdyLXREREo3M0tiRElTYUowOHV6SEE0RWNqOVNFazlTZ05tS1NFZVU0VG0xSGcxRjFFWHFVRjd2aVFwV21TTE9aZnRjOUVVYnJGRnlhTElETHZOcnJvWUJwUTVjbDBUcVV2SUxDRzVfeGhQMWVoVml4M3NOWGVxc0xOVTBnZktjOXkyVWhmeXFGQVZZMXdHVEFmVFM3TDdqejd4OWliR1p0R0p6VmZHaGJFNU5Sb0VaNnBEUmNUdjlGNS1ReUVjVEZoa3pKS3NxSFJzTXZJX0tiMWItdw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: horizontal-pod-autoscaler
      kubernetes.io/service-account.uid: d68f2812-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:38Z
    name: horizontal-pod-autoscaler-token-rgs5t
    namespace: kube-system
    resourceVersion: "227"
    selfLink: /api/v1/namespaces/kube-system/secrets/horizontal-pod-autoscaler-token-rgs5t
    uid: d692d112-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKcWIySXRZMjl1ZEhKdmJHeGxjaTEwYjJ0bGJpMXNNbkJ4ZHlJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExtNWhiV1VpT2lKcWIySXRZMjl1ZEhKdmJHeGxjaUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG5WcFpDSTZJbVExWW1Wa05qaGtMVEE1TXpJdE1URmxPQzA1T1RRd0xUQTRNREF5TnpjMU5qRm1OeUlzSW5OMVlpSTZJbk41YzNSbGJUcHpaWEoyYVdObFlXTmpiM1Z1ZERwcmRXSmxMWE41YzNSbGJUcHFiMkl0WTI5dWRISnZiR3hsY2lKOS5MSnM4b2ZKR0U3ZHpnRHg2SEtSeEVCazI1Y3lzc2YyV3oxWkdtUmFTYmtJYkVPdWs2TGlZR2FURzRCSHNNS0hqdVZqU19PVzhnYmR1VlkzR2VjZzUyOFRzV095Tk9vdzZfcThRTHJkbUp1NDJTVXREWThnZm1vQVM3NHNFdUZoQlFUQUlIWGltejJRUzBsQ1U5YmtLUWtrNVFpaFJjX0JFV0kwT3ZaYlVrdDNZOUgxOVBWdkJiME96REZZcDIzTWZuckxxVURvS3BpRk1xS2Y2WXZTQjBfZTVUcWc3YkpjQk5lRXVPY1h1bElMT1dUVlhlNFRDdHRRb25YVG1sTXFVc2lzeWJraTFidWlqenM3TDh5TU1rREVJUjBjdmFocXpJZEZTci1KZ2FnTVFSSjhxdGJhMFhTQkRYSXhlSkFNaG1BT1dpTDdHeVFCc292ekxEbEg3N1E=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: job-controller
      kubernetes.io/service-account.uid: d5bed68d-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:37Z
    name: job-controller-token-l2pqw
    namespace: kube-system
    resourceVersion: "177"
    selfLink: /api/v1/namespaces/kube-system/secrets/job-controller-token-l2pqw
    uid: d5c27a4f-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKcmRXSmxMWEJ5YjNoNUxYUnZhMlZ1TFhkdFoycHJJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1Ym1GdFpTSTZJbXQxWW1VdGNISnZlSGtpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1MWFXUWlPaUprTmpFd05UZzFNaTB3T1RNeUxURXhaVGd0T1RrME1DMHdPREF3TWpjM05UWXhaamNpTENKemRXSWlPaUp6ZVhOMFpXMDZjMlZ5ZG1salpXRmpZMjkxYm5RNmEzVmlaUzF6ZVhOMFpXMDZhM1ZpWlMxd2NtOTRlU0o5Lm5mTnJyQ253SjFXb2J2Y0FZd21qSTJ4T05lWWVJTTRsS0E2ZE5wS1lMZUJTVmRValpIam42VVYyWHVOWS1RVksyR0pUQ0dmVnBlWmlrb2dUZGJ3akR1c1BfQl9GaF9xU1cxNXV0VzJ2V0VZZXZXYmJ0M05XVmY4SFFINVAtTVRLQS14cmpfNmlWazcyMERWN2RobHduT1Item1MMEVVSUFuZVVfUE1ieUQxN3MtZnhsSFJvNW9GUnU5MEExajQ2SWZtb3FadnZNUTdLVzVxdXRpNHRuekpyWF90c0I3aDVHTEhIZ29PNnF5Q2k3cHN2R0NCSFpTbFJBYjl6STduZEVFY1ZsWEVmY1RUamNyZjhDeDViNldvZVoxeVkxdkR4RDBMNHBCUXlPYWFCakJmb3Rub2ZXTU90YzJqOWlBUkl2cXdwd3FTOFlDLWpjSGpEYmtpSVdSdw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: kube-proxy
      kubernetes.io/service-account.uid: d6105852-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:37Z
    name: kube-proxy-token-wmgjk
    namespace: kube-system
    resourceVersion: "205"
    selfLink: /api/v1/namespaces/kube-system/secrets/kube-proxy-token-wmgjk
    uid: d616ae9c-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKdVlXMWxjM0JoWTJVdFkyOXVkSEp2Ykd4bGNpMTBiMnRsYmkxNk9YSTFNaUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG01aGJXVWlPaUp1WVcxbGMzQmhZMlV0WTI5dWRISnZiR3hsY2lJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExuVnBaQ0k2SW1RMU5tWmtOMlJtTFRBNU16SXRNVEZsT0MwNU9UUXdMVEE0TURBeU56YzFOakZtTnlJc0luTjFZaUk2SW5ONWMzUmxiVHB6WlhKMmFXTmxZV05qYjNWdWREcHJkV0psTFhONWMzUmxiVHB1WVcxbGMzQmhZMlV0WTI5dWRISnZiR3hsY2lKOS5Lc01PNHhMbVU4NmxHaDg2S3FwUnlHTHFLUTVmbzhMTWFOSmczQ19hVkM1eVpQalRMenVfLW1fSXBPZVdkeG5jMmlEOS1MeEZ4cnBXb2VhdnlUSHBMd0NzN053SDRqMUNBejRkcnU2cmRUMk5EVjBDMkRmTl9ZbEVMMUpTSTF5cVZsU0I0SXY4U25TUDBjS0RWZXA2czZuVHFNVWdrT1FHLWI1LTdlYWFFOVdCQTlNSGJmUmY1dTRrVmFjc3hpTzROS0xVRkdsYjJXTkpyZ1pKTzhyVkR6SC0tdTloVzZTWVZqd3dURUw1RUVCUTc5Q0x1dEFSRTZNcVowSlBkdUEyRkpZQXpuNXZQNVdySWVlUlJleXcteDZmZmxhcHlTR1RhNWR3MkM5SUtRTDc3cklCZEEyRWJ2SWdDUXYxeGktdXdCTWgycmFnclRBSlBLY3hwNUt1Qnc=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: namespace-controller
      kubernetes.io/service-account.uid: d56fd7df-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:36Z
    name: namespace-controller-token-z9r52
    namespace: kube-system
    resourceVersion: "161"
    selfLink: /api/v1/namespaces/kube-system/secrets/namespace-controller-token-z9r52
    uid: d5738489-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKdWIyUmxMV052Ym5SeWIyeHNaWEl0ZEc5clpXNHROMlExZW0waUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNXVZVzFsSWpvaWJtOWtaUzFqYjI1MGNtOXNiR1Z5SWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWRXbGtJam9pWkRjNE1tRXpaRGt0TURrek1pMHhNV1U0TFRrNU5EQXRNRGd3TURJM056VTJNV1kzSWl3aWMzVmlJam9pYzNsemRHVnRPbk5sY25acFkyVmhZMk52ZFc1ME9tdDFZbVV0YzNsemRHVnRPbTV2WkdVdFkyOXVkSEp2Ykd4bGNpSjkuZEV4VnAwcGJqM1MtMzJmSU51YXFibUJfT1JHMkRDdXBPLWJXYUg3LUFnd0pQaHhoTC1wSzZ4ak80YlAzSmFjLVdtUkdNUUJfWnI0VXdBb3RFZEZxWklaUzZXTTVSZjZRLWZ6MXlWVUw3dUcybkRnNkJYRjM2NFlESlZOaWo5OEhIS1ltQlJOUkVaUUNiT0R1bWFOQ2NDN2xnZ1RtZWlsVnVlX2Z3UHFKVG1lVzhyclZxa3lNUTViMFBFQkdFRHRXaWhESDdmdlo2eWxkZkFNdU9IWVc1MjNzY1B0ampweFlnT24zZEFfNjNSVy1SRE9NcS1ENkF2S1hNTlFIWDRoX2NBdkt5dEgwbDdWamVxdk9OWmNoWTBzQUpFOWJmMFhlczNMUkFsN3AtN2JKRlRtZHBLLTJwTk1LcWk3R3pMVzlWb1N0d0MwdTJtd2ZrLXFiZFVLYzN3
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: node-controller
      kubernetes.io/service-account.uid: d782a3d9-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:40Z
    name: node-controller-token-7d5zm
    namespace: kube-system
    resourceVersion: "251"
    selfLink: /api/v1/namespaces/kube-system/secrets/node-controller-token-7d5zm
    uid: d7899ff4-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKd1pYSnphWE4wWlc1MExYWnZiSFZ0WlMxaWFXNWtaWEl0ZEc5clpXNHRPSFJpY1RJaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNXVZVzFsSWpvaWNHVnljMmx6ZEdWdWRDMTJiMngxYldVdFltbHVaR1Z5SWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWRXbGtJam9pWkRaaVlUZ3dObVF0TURrek1pMHhNV1U0TFRrNU5EQXRNRGd3TURJM056VTJNV1kzSWl3aWMzVmlJam9pYzNsemRHVnRPbk5sY25acFkyVmhZMk52ZFc1ME9tdDFZbVV0YzNsemRHVnRPbkJsY25OcGMzUmxiblF0ZG05c2RXMWxMV0pwYm1SbGNpSjkucDVXekh0M1ljTWMtNkpLa1BRR3RWMk1tVTZDYmNvTDZHODRfYmhoc29DSGNJbTJmWHhEUkFxWGFKSDNwaDBNdlp2cm9lWXlSVlFFX1pmY2RkdkpaU3pSYmdUU3FybDFBN3RVeWdfUUpxRy1tekZCZVpXbXYyYU5Ld3VpUnI5S0VodU5wVmJieHBDbjExX1JfR2R2eEExUkhkZklIcUxydjBRTTJxWWVNbzRSSk90cG1lM1U3dzExTXNtZUlGNXRJV2dSbDJPVHExcXRKZWZYX2syZnV1b1g2Q3dHeHh5ekFXR2ZkRjFJdDQ3RkRsNWRzNHhTU0kxVjdYLUZuWk9oX3BkM1FubXM2MWpGSTR2UWpMaGxLdFdwZUZ2d3llLWl1Q3dnc3kzN0JVYVFOZ3Z5QUI0bUlpNlhVWXV6U0V4MEpuenduN2pNN3BJVWlyb1FtTHZtOFdn
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: persistent-volume-binder
      kubernetes.io/service-account.uid: d6ba806d-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:39Z
    name: persistent-volume-binder-token-8tbq2
    namespace: kube-system
    resourceVersion: "232"
    selfLink: /api/v1/namespaces/kube-system/secrets/persistent-volume-binder-token-8tbq2
    uid: d6ca0242-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKd2IyUXRaMkZ5WW1GblpTMWpiMnhzWldOMGIzSXRkRzlyWlc0dE4zUjNjalFpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pY0c5a0xXZGhjbUpoWjJVdFkyOXNiR1ZqZEc5eUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVkV2xrSWpvaVpEY3dPV0l6TkdFdE1Ea3pNaTB4TVdVNExUazVOREF0TURnd01ESTNOelUyTVdZM0lpd2ljM1ZpSWpvaWMzbHpkR1Z0T25ObGNuWnBZMlZoWTJOdmRXNTBPbXQxWW1VdGMzbHpkR1Z0T25CdlpDMW5ZWEppWVdkbExXTnZiR3hsWTNSdmNpSjkuTWhRWWdsRndTUEY3M1JxLUZ6V0E3bTZ2c2JSaTVqc2VhRFFIYkNpYUJTbTRYdHNMdzdLSEduMzVlbmZqMmtTUEJOODRXX0lUbS1TYzJvMU5FblhNdVdUZ3Q0OEN0UnV3STB5WjBxdUgzZ3dQZE0tRUh0ZlFCQTdrS0hENl83cjFBYThzNEZDMHdkVmdYMDZiamVFUTZBUVVDV3ZVY1BPWnBNRnF2NzRsdHZIVTZmWFBxOEI0bkxWem5laDJjUHMwbExlWVdybmZLQXdBaXRPTmM4SVVxM0I2eEQyb3pfU212dHoxV0VTYVhkNnBnVF9qQlZSa0xld3d5Wm1MNlFRZS1Nai1McGhUN3FCV0dTeF85cFhKNFpxU1c2Y0hMVk9BNklWcXc5WHNESXFTTkN3RmM3d2F4aWVPemZIRG8wWDMwYmJmMmhPVUxQMEVmNWNhN1VROTRB
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: pod-garbage-collector
      kubernetes.io/service-account.uid: d709b34a-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:39Z
    name: pod-garbage-collector-token-7twr4
    namespace: kube-system
    resourceVersion: "242"
    selfLink: /api/v1/namespaces/kube-system/secrets/pod-garbage-collector-token-7twr4
    uid: d720324e-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKeVpYQnNhV05oYzJWMExXTnZiblJ5YjJ4c1pYSXRkRzlyWlc0dE9IZG9lSFFpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pY21Wd2JHbGpZWE5sZEMxamIyNTBjbTlzYkdWeUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVkV2xrSWpvaVpEWXhOVE0zWVdVdE1Ea3pNaTB4TVdVNExUazVOREF0TURnd01ESTNOelUyTVdZM0lpd2ljM1ZpSWpvaWMzbHpkR1Z0T25ObGNuWnBZMlZoWTJOdmRXNTBPbXQxWW1VdGMzbHpkR1Z0T25KbGNHeHBZMkZ6WlhRdFkyOXVkSEp2Ykd4bGNpSjkuT1kyZHdXVnR6cUNyT3BnMDAyeUE5NFBQcGt1N3NRUGFVVkotYWQzbWZEcTdDVG5yT3doaks1YjZRWVBSeVpRaXlTTktFTWM5M1NrT00teVpiZkNueWJpSUF3TURacTVndE1vMVBPLTlhYjZRVzdBZF9IM08wcVV6SWVOemZnZ29La1Y3am9PY2owMTlBZmFRNVZsaldqRjRUdFE5OEJtcWlKOUsyNUhoNC1ZdjhhNU4wTnBWdmkwWnYta01QZ080ZHhnSjdndWZGVG95QWIzWlFZOFRCUlR3VmdiZk1ZbTR2cXlOczRoRGNHSDFLZEdjQ1JCNzBnNnFXNW1ZZlhMRjlaQTB2UDFMbWg5N3dxX2UtY2FDVFZFOFplRXdjRm5wSmxJRkVBSDQ0Z0h1QU9MdHBwNTE3RTNwdFJwNEJ3NGVaYlY5LWV2VGRITnhTZ2loVVFlVGxn
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: replicaset-controller
      kubernetes.io/service-account.uid: d61537ae-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:38Z
    name: replicaset-controller-token-8whxt
    namespace: kube-system
    resourceVersion: "209"
    selfLink: /api/v1/namespaces/kube-system/secrets/replicaset-controller-token-8whxt
    uid: d620e3a3-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKeVpYQnNhV05oZEdsdmJpMWpiMjUwY205c2JHVnlMWFJ2YTJWdUxXUnNkbmhpSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW5KbGNHeHBZMkYwYVc5dUxXTnZiblJ5YjJ4c1pYSWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzUxYVdRaU9pSmtOV1poTTJSak55MHdPVE15TFRFeFpUZ3RPVGswTUMwd09EQXdNamMzTlRZeFpqY2lMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2YTNWaVpTMXplWE4wWlcwNmNtVndiR2xqWVhScGIyNHRZMjl1ZEhKdmJHeGxjaUo5LmlRUGRPY0ZBMEpZTktHMU04WkRWMmYtQTZvSG9STTJnYnZGQm5CbEIxOFhlTV9PTk5NeGxkZ2JfalJLbXBFNDlucE9JNlVvWlZzeVNKZFNsUEJHakVwVTBXXzdlZjVrWks0ODFfcG1FdlpDSFNqaG5KVVViamZmazFZVGUxYm12QW00SlhpM1ViU3kyb0J2TkRrUEVlZWhkOFZ0dldCWE1ZWGtXM3BlbVJtU0U0aWhDVmZ2SnBqTUJWbEpyX1c3RHRaT0VUY3RiOFR4X0VING9qcHVqal80OGFNNmRRT0p2VUZBQTZIc2paVkFGbmhURXUwRHFSR1luN3lOTy1hNV9UM240Zm40cE5RT01McjhlQXJ5VTVudkxOcnlMZUlHZTR4VkJPc2FfZl9xT1J3elBsa0JId2tjeFJPbnRzSUJMTVlrRVdDV2lJTXJ3NUI5cHJhOGc2dw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: replication-controller
      kubernetes.io/service-account.uid: d5fa3dc7-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:37Z
    name: replication-controller-token-dlvxb
    namespace: kube-system
    resourceVersion: "198"
    selfLink: /api/v1/namespaces/kube-system/secrets/replication-controller-token-dlvxb
    uid: d6074057-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKeVpYTnZkWEpqWlhGMWIzUmhMV052Ym5SeWIyeHNaWEl0ZEc5clpXNHRZbXh4ZUhvaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNXVZVzFsSWpvaWNtVnpiM1Z5WTJWeGRXOTBZUzFqYjI1MGNtOXNiR1Z5SWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWRXbGtJam9pWkRjME9XVmtZMlV0TURrek1pMHhNV1U0TFRrNU5EQXRNRGd3TURJM056VTJNV1kzSWl3aWMzVmlJam9pYzNsemRHVnRPbk5sY25acFkyVmhZMk52ZFc1ME9tdDFZbVV0YzNsemRHVnRPbkpsYzI5MWNtTmxjWFZ2ZEdFdFkyOXVkSEp2Ykd4bGNpSjkueDJQaG1nTjV0QXRWWlhLQk9nc2libE9KeWlFVDJkUGI4amxzRDI5LWxDdFVaUXRCbnBTa1dRbTZZc0gwQjd4UzdyRmNoNHFQNDlxaGtOaDBlam5lT0FLazlkNWVkSE0yNDR2RS1Qc2NRTEE2aUdPeVNqTXVLSFZ5TnJXNjVfdk9rUHhaeDhYRFczSjg4ZmxHRy13YTdmbjI1Q05OUTVQZlNaYVp4V3FZejFjMi15WWtpNDlyUEtSNGIzUEQ5aGdvQmV5cTZRRUFxLVYxNEZXSzFTWm5PMGJVR3Zpc3pFLVQ3aXJtTTVZbU5IMW5RNXpLVHNaZGlER2V1Z25vOVhMVmNXdnRhX2ZHNTJtUF90dGhLQTJubHNmeXdfS1d2VXVXV1BpX19vbFhkTGxxSkU1SmJ2Tkk0VGpCRDlHQW9Gd0hrLXJtWXV2ZzcwanE5em1scnlTcTBn
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: resourcequota-controller
      kubernetes.io/service-account.uid: d749edce-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:40Z
    name: resourcequota-controller-token-blqxz
    namespace: kube-system
    resourceVersion: "247"
    selfLink: /api/v1/namespaces/kube-system/secrets/resourcequota-controller-token-blqxz
    uid: d7506535-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKelpYSjJhV05sTFdGalkyOTFiblF0WTI5dWRISnZiR3hsY2kxMGIydGxiaTF3WWpSbWNDSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMbTVoYldVaU9pSnpaWEoyYVdObExXRmpZMjkxYm5RdFkyOXVkSEp2Ykd4bGNpSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMblZwWkNJNkltUTNaRFk0WWpVMExUQTVNekl0TVRGbE9DMDVPVFF3TFRBNE1EQXlOemMxTmpGbU55SXNJbk4xWWlJNkluTjVjM1JsYlRwelpYSjJhV05sWVdOamIzVnVkRHByZFdKbExYTjVjM1JsYlRwelpYSjJhV05sTFdGalkyOTFiblF0WTI5dWRISnZiR3hsY2lKOS4wTzJKX0k3UzMtTlBiOTA2TVlQTk1SMGh6b1VuWXhuNnMxSnU2VWlIV1FqdU5nU0N0a0hKWkhoekxQbFRCTXM0SndaRHkzdVZzQlZ5TWREVVhZRklKTFY0QWZBUGlscFgtUVRuQkpSR0I0YVZQeERnUVhIWG1lS0VubjkxVko2WG4zX3VlcHV6c01zekllNG9jRzNfeUhGNG1YQ1FVN3dIcmtQT3k1dmxPcHEzM21YMWdZbUZfRzBJVEJQdEhDYWEwZ3NMbXhvb3lzMk1iOW9sck84bF8ySEZmTEN3cV9yeEh0UUtLbVhXN3pwY3FLcndLempKcDFQWnQtZVJBMlJXaDNGeGwxTlV1VVlWbXdIenVZLWp1Rms1T1lzRV9jbjdha2JfRDI3TkRoNTl5Tzc4NEJJSzJWd2cwUmh1RXdVc2xreEV5amlDRzJHOG41Mi1SZHprSlE=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: service-account-controller
      kubernetes.io/service-account.uid: d7d68b54-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:41Z
    name: service-account-controller-token-pb4fp
    namespace: kube-system
    resourceVersion: "260"
    selfLink: /api/v1/namespaces/kube-system/secrets/service-account-controller-token-pb4fp
    uid: d7e7da73-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKelpYSjJhV05sTFdOdmJuUnliMnhzWlhJdGRHOXJaVzR0WjJadU5uUWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzV1WVcxbElqb2ljMlZ5ZG1salpTMWpiMjUwY205c2JHVnlJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1ZFdsa0lqb2laRFZrWkRKbE5UQXRNRGt6TWkweE1XVTRMVGs1TkRBdE1EZ3dNREkzTnpVMk1XWTNJaXdpYzNWaUlqb2ljM2x6ZEdWdE9uTmxjblpwWTJWaFkyTnZkVzUwT210MVltVXRjM2x6ZEdWdE9uTmxjblpwWTJVdFkyOXVkSEp2Ykd4bGNpSjkucks0UVdiUmJtNDQyZ1hIMEFLZ2lyRmk0SUozWTRuOG1YZXVUNWE1dy13MW84YVJzeWJIT3FPOTBNUUFHT3BuZXlJZVJ2N0ZMeDAyVXdLRUV4X2plT1Z0WGpCYy10b0ZTb1BTZnAzOWhjdmJ4ZmI3WkNtRTM0Y0lXUWJ3N3R6TkRDTFFUdm5RQ21td3lGODVYZWFFVENxa3dRZU9LZ29oZ0NCNDJ5S29OMlNaODl4bkp5el9aaEFKYXlod0g1amdpYVRsaVlvSmFDMkJWZkVpSThqOGRBY2xSY3RJR3p6MlBaQlF4WEJTa0p1WFNEUmJiczZhbTNPZk9DblJaVHIwSWQ3U0FuQnl5T3BKUWtoV3NrSzJLczNjdFRoNzhkSFBRaE9tSC14U28yVlpPX2FaVTk2NC1CLUxQU3psdmxXUDZyOERzVVNYdzdFa0U2WnJERjRDWjNR
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: service-controller
      kubernetes.io/service-account.uid: d5dd2e50-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:37Z
    name: service-controller-token-gfn6t
    namespace: kube-system
    resourceVersion: "191"
    selfLink: /api/v1/namespaces/kube-system/secrets/service-controller-token-gfn6t
    uid: d5f04759-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKemRHRjBaV1oxYkhObGRDMWpiMjUwY205c2JHVnlMWFJ2YTJWdUxUUjZlblp5SWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW5OMFlYUmxablZzYzJWMExXTnZiblJ5YjJ4c1pYSWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzUxYVdRaU9pSmtOV0ZqWmpRMU1pMHdPVE15TFRFeFpUZ3RPVGswTUMwd09EQXdNamMzTlRZeFpqY2lMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2YTNWaVpTMXplWE4wWlcwNmMzUmhkR1ZtZFd4elpYUXRZMjl1ZEhKdmJHeGxjaUo5LjFfVkpoNHRLUkk1SDM0dTVMbkRMTVZxS3BFd1hYSnFYQ1FKUm9WMmhnOFZESzhwY2llOGhzQ0ZIZmY3NFRlM0hqZE9yRjhsZDFsRjcwU0ROb3VWc1ZIRnk0cDhBc2RCTXFsaVZhbURWdHlwTk9zRzUtLTU0ZnpfNU4wVUtCZG96YXl2clJFYXNIUG1fQ08zdU5KUnJKT0dhU3BmS3FGSHJYLUdEN2pvdlZpVzhJaXVYeFhhUzdRcUN4Vnd5V3JtME5nZXhzLVM5UXMtNVlxcmY4X0loTjdVVnFoc2FsSVI5Vi00dmVMUXJzWEg1S0FHVVRlbzdGZzBNQmpxZU9HMWhDc0hFZFJ3c3E2Qy1iM3VvZDctQktOQ3RzZFhGc1RfSUU5VTdzLWxvU2xQclZJWWh2ZEhMRXpvTG8zS3YyVVRzREZ0a3IwTEVsNGdadHh2WkhfY2ZyZw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: statefulset-controller
      kubernetes.io/service-account.uid: d5acf452-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:37Z
    name: statefulset-controller-token-4zzvr
    namespace: kube-system
    resourceVersion: "172"
    selfLink: /api/v1/namespaces/kube-system/secrets/statefulset-controller-token-4zzvr
    uid: d5b75387-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKMGIydGxiaTFqYkdWaGJtVnlMWFJ2YTJWdUxXNDJlbTFtSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW5SdmEyVnVMV05zWldGdVpYSWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzUxYVdRaU9pSmtOVFUyTnpZeE1TMHdPVE15TFRFeFpUZ3RPVGswTUMwd09EQXdNamMzTlRZeFpqY2lMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2YTNWaVpTMXplWE4wWlcwNmRHOXJaVzR0WTJ4bFlXNWxjaUo5LkdJZ3B6ZDNqVWVYS2pkNEVHV0o0clFVRjNEOHNfZUJZYkk3N09uc1V3Z3BvR1RKalJQWmk1bHk3WTExZ2tzejFrUzV4ZHBlWjIwZlBjbGdxalhtdUhFdVl0RGxDWTAzVmZZUUlMcXBiM19tMXpaWTZSVXM3UWVjSHN0ZGYzVXJPbnc5UnNqelZZdks0VmNlaVZPUlF1cmkzTU8wOENUTGxoeWQwaFdFY1VreEF5Rmp0X3NJRzVzTk5Ba2w0Zm5NWmFNQXNzbWZQSXRfUGY0Ml9WTnIwTmFvZ08ycjE4N05GNEVNTFBkb202S3ZZeEMySGdZU3RhLVFYSlg4eVZrQU5razVsZEQzcWloblpGbWF6MWVuNkFsbGoyd2xMQ2NFMkNwMTdVdHY5UmRXMjM5Yzh4TXE5bW95N2l0TGdmbEtRcU54Q0JudHlVem1aSllabDVZeXlWUQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: token-cleaner
      kubernetes.io/service-account.uid: d5567611-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:36Z
    name: token-cleaner-token-n6zmf
    namespace: kube-system
    resourceVersion: "156"
    selfLink: /api/v1/namespaces/kube-system/secrets/token-cleaner-token-n6zmf
    uid: d55a301c-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNE1ESXdNekl5TXpFek9Gb1hEVEk0TURJd01USXlNekV6T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS1FXCkNDeXplQWk2L3ZtYXRDZHlJQTc3OCtLNjhBck9Wem1NZmpWcVc2RmxRWlI5dHE0QytLbmdNZEsxcmFOVlNsOWcKdUpaWEx2cE80NVpnUFlnckRwU2JET0NMS09ySUhzdmpMTVpXTlVPOUdYZk9ibWxJRFpjb2pycU1UOHdGV2EzdQpGZUo3RVNwdWY4RXVvcE0zRmRMeXRrUVZ6OERvVzlyT1N6VnRtVU1nNnZ1aVREWUxGdy9KWWhDTHZtVmJJUnhRCnNlQVlhdWIrVFBURnQ2R1lLL3R2TW5ZMms5RStDYU54ZUR0WldtWHp5QWprSFZHTDVhWWgvSytoN2M5bVBjemQKK0xqdkRMSTAzUnhwaHdKOTdsZEZQU3J1WVVzWGdHY3oyM3o4cG0raWZ3czBVVkRnSW0rKzBNQVNXaVN1R2FYYwpBVW1FQnNJM0lDSkJqQ2tzUmtFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHdHhuSEJ4UDZoRWtGeFcyODk1b1RCcW1ZNGoKV1VFYjhHa3h6T1JpdVNFeGprRHhlNUM5NFhaYUYrQ2pMM2dkN09CV3JBVlpTNXJqYldKQlBUT3VGTHdEOXBMTwp5UlVKQ0o1Y3pSNTBwL0ZzblBkeXQ1eXpwZFJyRllucmpZdm90ZXd6YklYc05wejN3S2dHNFlFZENQalYzUWdYCkUyVEp4UEYrR1laWHI4S1dkN2pLOTJybjRscVJqclZKSE4vakwreFl3aTF0ZGhDSTlBMEtqSll2c2RNdm51VmwKM1FKbkxJbGM0RVFHSmppY0RtalNJd0dYRDRDbWpOUFd3SnI1ZGZqVUxxNElJR01OSDVFZ2hjWmxoYzNHci9HNAo1RXJjalNpQmlERWRVTERRNFdYdklBNHBVaGY4d20ycENBRE84TC9mWXNMOWp4blR1Q1gwT09ieHMxND0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbExYTjVjM1JsYlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKMGRHd3RZMjl1ZEhKdmJHeGxjaTEwYjJ0bGJpMHlObnBvTmlJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExtNWhiV1VpT2lKMGRHd3RZMjl1ZEhKdmJHeGxjaUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG5WcFpDSTZJbVE1TURFMll6WTBMVEE1TXpJdE1URmxPQzA1T1RRd0xUQTRNREF5TnpjMU5qRm1OeUlzSW5OMVlpSTZJbk41YzNSbGJUcHpaWEoyYVdObFlXTmpiM1Z1ZERwcmRXSmxMWE41YzNSbGJUcDBkR3d0WTI5dWRISnZiR3hsY2lKOS5VQ0xUT2JXbGR3dXJpMUpRbElWd0FYd3FJN2JqVTVHdE96SFc4aDUyQjBWMWg0SDFiMzR0OTdKQUVCLTFtUng1Q1JoLTVkUFdVLTY1V0xXWkN1NDhVRmFjQzQ4b2ZlRHAyRHVQUmlpUFNIek1MNkVEMzI2VTJ5bmVaem8xb3VVengxWEl6bDJhTTVyZVBHd01kUm1qX0lTRkdfTWEwbDdsRHkzTmcwUWdYc3ZhMzRlMVBMQnFPbVJVMWpWVGt1Vk8yNFVUX0JBcEl0UF9ISGhYdjdRNGFMWlBnWkRCMkRNU2RZbmFUU2EwZXZhQWwyS2QxdnFWbG1VTTVLWWttdmNLa0N0UEdjSmQ2WVlmeVRBN0JTaTdvaUxSdVNJQXQycjBmSlFjX2VJNC1rVzYyTXZUSDI2V2ZqSkppYk1uOXdIYXJvQWtadUdjYWhTOWlfRUw5dXptN0E=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: ttl-controller
      kubernetes.io/service-account.uid: d9016c64-0932-11e8-9940-0800277561f7
    creationTimestamp: 2018-02-03T22:37:42Z
    name: ttl-controller-token-26zh6
    namespace: kube-system
    resourceVersion: "285"
    selfLink: /api/v1/namespaces/kube-system/secrets/ttl-controller-token-26zh6
    uid: d90caf2f-0932-11e8-9940-0800277561f7
  type: kubernetes.io/service-account-token
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get serviceaccounts --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:43Z
    name: default
    namespace: default
    resourceVersion: "299"
    selfLink: /api/v1/namespaces/default/serviceaccounts/default
    uid: d92c5316-0932-11e8-9940-0800277561f7
  secrets:
  - name: default-token-d5kpb
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:43Z
    name: default
    namespace: kube-public
    resourceVersion: "297"
    selfLink: /api/v1/namespaces/kube-public/serviceaccounts/default
    uid: d929a655-0932-11e8-9940-0800277561f7
  secrets:
  - name: default-token-qhfnm
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:38Z
    name: attachdetach-controller
    namespace: kube-system
    resourceVersion: "219"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/attachdetach-controller
    uid: d6399f15-0932-11e8-9940-0800277561f7
  secrets:
  - name: attachdetach-controller-token-76zkt
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:38Z
    name: bootstrap-signer
    namespace: kube-system
    resourceVersion: "214"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/bootstrap-signer
    uid: d626cfe9-0932-11e8-9940-0800277561f7
  secrets:
  - name: bootstrap-signer-token-2pkhf
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:36Z
    name: certificate-controller
    namespace: kube-system
    resourceVersion: "153"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/certificate-controller
    uid: d538b229-0932-11e8-9940-0800277561f7
  secrets:
  - name: certificate-controller-token-bwh4d
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:39Z
    name: clusterrole-aggregation-controller
    namespace: kube-system
    resourceVersion: "238"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/clusterrole-aggregation-controller
    uid: d6ea0cba-0932-11e8-9940-0800277561f7
  secrets:
  - name: clusterrole-aggregation-controller-token-tbk9h
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"kubernetes.io/cluster-service":"true"},"name":"contiv-netmaster","namespace":"kube-system"}}
    creationTimestamp: 2018-02-03T22:37:52Z
    labels:
      kubernetes.io/cluster-service: "true"
    name: contiv-netmaster
    namespace: kube-system
    resourceVersion: "349"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/contiv-netmaster
    uid: dedddd7a-0932-11e8-9940-0800277561f7
  secrets:
  - name: contiv-netmaster-token-47bxd
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"kubernetes.io/cluster-service":"true"},"name":"contiv-netplugin","namespace":"kube-system"}}
    creationTimestamp: 2018-02-03T22:37:52Z
    labels:
      kubernetes.io/cluster-service: "true"
    name: contiv-netplugin
    namespace: kube-system
    resourceVersion: "345"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/contiv-netplugin
    uid: ded152da-0932-11e8-9940-0800277561f7
  secrets:
  - name: contiv-netplugin-token-xqsb5
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:42Z
    name: cronjob-controller
    namespace: kube-system
    resourceVersion: "281"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/cronjob-controller
    uid: d8e8af79-0932-11e8-9940-0800277561f7
  secrets:
  - name: cronjob-controller-token-brlcv
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: daemon-set-controller
    namespace: kube-system
    resourceVersion: "166"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/daemon-set-controller
    uid: d58ecf4f-0932-11e8-9940-0800277561f7
  secrets:
  - name: daemon-set-controller-token-hzfb5
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:43Z
    name: default
    namespace: kube-system
    resourceVersion: "294"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/default
    uid: d9275c4a-0932-11e8-9940-0800277561f7
  secrets:
  - name: default-token-9ktff
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: deployment-controller
    namespace: kube-system
    resourceVersion: "169"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/deployment-controller
    uid: d59e1de6-0932-11e8-9940-0800277561f7
  secrets:
  - name: deployment-controller-token-fvd4k
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:42Z
    name: disruption-controller
    namespace: kube-system
    resourceVersion: "278"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/disruption-controller
    uid: d8d2a032-0932-11e8-9940-0800277561f7
  secrets:
  - name: disruption-controller-token-lkrtn
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:38Z
    name: endpoint-controller
    namespace: kube-system
    resourceVersion: "225"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/endpoint-controller
    uid: d67393ad-0932-11e8-9940-0800277561f7
  secrets:
  - name: endpoint-controller-token-gsdzq
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:41Z
    name: generic-garbage-collector
    namespace: kube-system
    resourceVersion: "265"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/generic-garbage-collector
    uid: d80a4660-0932-11e8-9940-0800277561f7
  secrets:
  - name: generic-garbage-collector-token-9tfjt
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:38Z
    name: horizontal-pod-autoscaler
    namespace: kube-system
    resourceVersion: "228"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/horizontal-pod-autoscaler
    uid: d68f2812-0932-11e8-9940-0800277561f7
  secrets:
  - name: horizontal-pod-autoscaler-token-rgs5t
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: job-controller
    namespace: kube-system
    resourceVersion: "178"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/job-controller
    uid: d5bed68d-0932-11e8-9940-0800277561f7
  secrets:
  - name: job-controller-token-l2pqw
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "206"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/kube-proxy
    uid: d6105852-0932-11e8-9940-0800277561f7
  secrets:
  - name: kube-proxy-token-wmgjk
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:36Z
    name: namespace-controller
    namespace: kube-system
    resourceVersion: "162"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/namespace-controller
    uid: d56fd7df-0932-11e8-9940-0800277561f7
  secrets:
  - name: namespace-controller-token-z9r52
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:40Z
    name: node-controller
    namespace: kube-system
    resourceVersion: "252"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/node-controller
    uid: d782a3d9-0932-11e8-9940-0800277561f7
  secrets:
  - name: node-controller-token-7d5zm
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:39Z
    name: persistent-volume-binder
    namespace: kube-system
    resourceVersion: "233"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/persistent-volume-binder
    uid: d6ba806d-0932-11e8-9940-0800277561f7
  secrets:
  - name: persistent-volume-binder-token-8tbq2
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:39Z
    name: pod-garbage-collector
    namespace: kube-system
    resourceVersion: "243"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/pod-garbage-collector
    uid: d709b34a-0932-11e8-9940-0800277561f7
  secrets:
  - name: pod-garbage-collector-token-7twr4
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: replicaset-controller
    namespace: kube-system
    resourceVersion: "211"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/replicaset-controller
    uid: d61537ae-0932-11e8-9940-0800277561f7
  secrets:
  - name: replicaset-controller-token-8whxt
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: replication-controller
    namespace: kube-system
    resourceVersion: "199"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/replication-controller
    uid: d5fa3dc7-0932-11e8-9940-0800277561f7
  secrets:
  - name: replication-controller-token-dlvxb
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:39Z
    name: resourcequota-controller
    namespace: kube-system
    resourceVersion: "248"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/resourcequota-controller
    uid: d749edce-0932-11e8-9940-0800277561f7
  secrets:
  - name: resourcequota-controller-token-blqxz
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:40Z
    name: service-account-controller
    namespace: kube-system
    resourceVersion: "261"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/service-account-controller
    uid: d7d68b54-0932-11e8-9940-0800277561f7
  secrets:
  - name: service-account-controller-token-pb4fp
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: service-controller
    namespace: kube-system
    resourceVersion: "192"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/service-controller
    uid: d5dd2e50-0932-11e8-9940-0800277561f7
  secrets:
  - name: service-controller-token-gfn6t
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:37Z
    name: statefulset-controller
    namespace: kube-system
    resourceVersion: "173"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/statefulset-controller
    uid: d5acf452-0932-11e8-9940-0800277561f7
  secrets:
  - name: statefulset-controller-token-4zzvr
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:36Z
    name: token-cleaner
    namespace: kube-system
    resourceVersion: "157"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/token-cleaner
    uid: d5567611-0932-11e8-9940-0800277561f7
  secrets:
  - name: token-cleaner-token-n6zmf
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: 2018-02-03T22:37:42Z
    name: ttl-controller
    namespace: kube-system
    resourceVersion: "286"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/ttl-controller
    uid: d9016c64-0932-11e8-9940-0800277561f7
  secrets:
  - name: ttl-controller-token-26zh6
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get services --all-namespaces -o yaml
================\n
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: 2018-02-03T22:37:35Z
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "129"
    selfLink: /api/v1/namespaces/default/services/kubernetes
    uid: d4ae84b1-0932-11e8-9940-0800277561f7
  spec:
    clusterIP: 10.96.0.1
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 6443
    sessionAffinity: ClientIP
    sessionAffinityConfig:
      clientIP:
        timeoutSeconds: 10800
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"k8s-app":"contiv-etcd"},"name":"contiv-etcd","namespace":"kube-system"},"spec":{"clusterIP":"10.96.232.136","ports":[{"port":6666}],"selector":{"k8s-app":"contiv-etcd"}}}
    creationTimestamp: 2018-02-03T22:37:53Z
    labels:
      k8s-app: contiv-etcd
    name: contiv-etcd
    namespace: kube-system
    resourceVersion: "373"
    selfLink: /api/v1/namespaces/kube-system/services/contiv-etcd
    uid: df57476f-0932-11e8-9940-0800277561f7
  spec:
    clusterIP: 10.96.232.136
    ports:
    - port: 6666
      protocol: TCP
      targetPort: 6666
    selector:
      k8s-app: contiv-etcd
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get statefulsets --all-namespaces -o yaml
================\n
apiVersion: v1
items: []
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
\n================
kubectl get kubectl --all-namespaces -o yaml && echo ================n && kubectl get kubectl --all-namespaces -o yaml
